{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":120126,"databundleVersionId":14369730,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade transformers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/CodeVault-girish/SFM-models.git\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/SFM-models\")  \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sfm_extractor.extractor import model_list, extract_from\nmodel_list()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:42:13.711153Z","iopub.execute_input":"2025-12-16T08:42:13.711981Z","iopub.status.idle":"2025-12-16T08:42:13.716214Z","shell.execute_reply.started":"2025-12-16T08:42:13.711954Z","shell.execute_reply":"2025-12-16T08:42:13.715320Z"}},"outputs":[{"name":"stdout","text":"Available models:\n1. Trillsson\n2. YAMNet\n3. Facebook MMS-1B\n4. SpeechBrain x-vector\n5. Facebook HuBERT-base-ls960\n6. Microsoft WavLM-base\n7. Facebook Wav2Vec2-XLS-R-1B\n8. Facebook Wav2Vec2-base\n9. OpenAI Whisper-base\n10. Microsoft UniSpeech-SAT-base-100h-Libri-ft\n11. speechbrain/spkrec-ecapa-voxceleb\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"!touch audio_whisper_train_embeddings.csv\n!touch audio_whisper_test_embeddings.csv\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"extract_from(\"9\", \"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/audios/test\", output_file=\"/kaggle/working/audio_whisper_test_embeddings.csv\", device=\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\naudio_df = pd.read_csv(\"/kaggle/working/audio_wavlm_train_embeddings.csv\")\nlabel_df = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/csvs/train.csv\")\n\naudio_df.rename(columns={audio_df.columns[0]: \"filename\"}, inplace=True)\nlabel_df.rename(columns={label_df.columns[0]: \"filename\"}, inplace=True)\n\naudio_df[\"filename\"] = audio_df[\"filename\"].str.replace(\".wav\", \"\", regex=False)\n\ndf = pd.merge(audio_df, label_df, on=\"filename\", how=\"inner\")\n\nprint(\"Total aligned samples:\", len(df))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = df.iloc[:, 1:-1].values.astype(np.float32)\n\ny = df[\"label\"].values.astype(np.float32)\n\nprint(\"X shape:\", X.shape)\nprint(\"y shape:\", y.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(768,)),\n    tf.keras.layers.Dense(256, activation=\"relu\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(128, activation=\"relu\"),\n    tf.keras.layers.Dense(64, activation=\"relu\"),\n    tf.keras.layers.Dense(1)  # regression output\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n    loss=\"mse\",\n    metrics=[\"mae\"]\n)\n\nmodel.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=50,\n    batch_size=32,\n    verbose=1\n)\n\n\ntrain_loss, train_mae = model.evaluate(X_train, y_train, verbose=0)\ntest_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n\nprint(\"\\n=== LOSS & MAE ===\")\nprint(f\"Train Loss (MSE): {train_loss:.4f}\")\nprint(f\"Train MAE       : {train_mae:.4f}\")\nprint(f\"Test Loss (MSE) : {test_loss:.4f}\")\nprint(f\"Test MAE        : {test_mae:.4f}\")\n\n\ny_train_pred = model.predict(X_train).squeeze()\ny_test_pred = model.predict(X_test).squeeze()\n\ny_train_pred = np.clip(y_train_pred, 0.0, 5.0)\ny_test_pred = np.clip(y_test_pred, 0.0, 5.0)\n\ndef tolerance_accuracy(y_true, y_pred, tol=0.5):\n    return np.mean(np.abs(y_true - y_pred) <= tol)\n\ntrain_acc = tolerance_accuracy(y_train, y_train_pred)\ntest_acc = tolerance_accuracy(y_test, y_test_pred)\n\nprint(\"\\n=== REGRESSION ACCURACY (±0.5) ===\")\nprint(f\"Train Accuracy: {train_acc * 100:.2f}%\")\nprint(f\"Test Accuracy : {test_acc * 100:.2f}%\")\n\n\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\n\nprint(\"\\n=== R² SCORE ===\")\nprint(f\"Train R²: {train_r2:.4f}\")\nprint(f\"Test R² : {test_r2:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\n\n\naudio_df = pd.read_csv(\"/kaggle/working/audio_whisper_train_embeddings.csv\")\nlabel_df = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/csvs/train.csv\")\n\naudio_df.rename(columns={audio_df.columns[0]: \"filename\"}, inplace=True)\nlabel_df.rename(columns={label_df.columns[0]: \"filename\"}, inplace=True)\n\naudio_df[\"filename\"] = audio_df[\"filename\"].str.replace(\".wav\", \"\", regex=False)\n\ndf = pd.merge(audio_df, label_df, on=\"filename\", how=\"inner\")\nprint(\"Total aligned samples:\", len(df))\n\nX = df.iloc[:, 1:-1].values.astype(np.float32)\ny = df.iloc[:, -1].values.astype(np.float32)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(512,)),\n\n    tf.keras.layers.Dense(256, activation=\"tanh\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.25),\n\n    tf.keras.layers.Dense(128, activation=\"tanh\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.15),\n\n    tf.keras.layers.Dense(64, activation=\"tanh\"),\n    tf.keras.layers.Dense(8, activation=\"relu\"),\n\n    tf.keras.layers.Dense(1)\n])\n\n\n\n \n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),\n    loss=\"mse\",\n    metrics=[\"mae\"]\n)\n\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=500,\n    batch_size=24,\n    verbose=1\n)\n\n\ntrain_loss, train_mae = model.evaluate(X_train, y_train, verbose=0)\ntest_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n\ntrain_rmse = np.sqrt(train_loss)\ntest_rmse = np.sqrt(test_loss)\n\nprint(\"\\n=== LOSS / MAE / RMSE ===\")\nprint(f\"Train MSE  : {train_loss:.4f}\")\nprint(f\"Train RMSE : {train_rmse:.4f}\")\nprint(f\"Train MAE  : {train_mae:.4f}\")\nprint()\nprint(f\"Test MSE   : {test_loss:.4f}\")\nprint(f\"Test RMSE  : {test_rmse:.4f}\")\nprint(f\"Test MAE   : {test_mae:.4f}\")\n\n\ny_train_pred = model.predict(X_train).squeeze()\ny_test_pred = model.predict(X_test).squeeze()\n\ny_train_pred = np.clip(y_train_pred, 0.0, 5.0)\ny_test_pred = np.clip(y_test_pred, 0.0, 5.0)\n\ndef tolerance_accuracy(y_true, y_pred, tol=0.5):\n    return np.mean(np.abs(y_true - y_pred) <= tol)\n\ntrain_acc = tolerance_accuracy(y_train, y_train_pred)\ntest_acc = tolerance_accuracy(y_test, y_test_pred)\n\nprint(\"\\n=== REGRESSION ACCURACY (±0.5) ===\")\nprint(f\"Train Accuracy: {train_acc * 100:.2f}%\")\nprint(f\"Test Accuracy : {test_acc * 100:.2f}%\")\n\n\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\n\nprint(\"\\n=== R² SCORE ===\")\nprint(f\"Train R²: {train_r2:.4f}\")\nprint(f\"Test R² : {test_r2:.4f}\")\nMODEL_PATH = \"/kaggle/working/whisper_regression_model.keras\"\n\nmodel.save(MODEL_PATH)\nprint(\"Model saved at:\", MODEL_PATH)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport joblib\n\n\nTEST_META_PATH = \"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/csvs/test.csv\"\nDEBERTA_TEST_EMB_PATH = \"/kaggle/working/deberta_large_embeddings_test.csv\"\n\nXGB_MODEL_PATH = \"/kaggle/working/xgb_deberta_grammar_model.pkl\"\nSUBMISSION_PATH = \"/kaggle/working/submission.csv\"\n\n\ntest_meta_df = pd.read_csv(TEST_META_PATH)\ntest_emb_df = pd.read_csv(DEBERTA_TEST_EMB_PATH)\n\ntest_meta_df.rename(\n    columns={test_meta_df.columns[0]: \"filename\"}, inplace=True\n)\ntest_emb_df.rename(\n    columns={test_emb_df.columns[0]: \"filename\"}, inplace=True\n)\n\ntest_meta_df[\"filename\"] = test_meta_df[\"filename\"].astype(str)\ntest_emb_df[\"filename\"] = test_emb_df[\"filename\"].astype(str)\n\ntest_df = pd.merge(\n    test_meta_df,\n    test_emb_df,\n    on=\"filename\",\n    how=\"inner\"\n)\n\nprint(\"Total aligned test samples:\", len(test_df))\nprint(test_df.head())\n\n\nX_test = test_df.iloc[:, 1:].values.astype(np.float32)\nprint(\"Test feature shape:\", X_test.shape)\n\nxgb_model = joblib.load(XGB_MODEL_PATH)\nprint(\"Loaded XGBoost model from:\", XGB_MODEL_PATH)\n\ny_test_pred = xgb_model.predict(X_test)\n\ny_test_pred = np.clip(y_test_pred, 0.0, 5.0)\n\ny_test_pred = np.round(y_test_pred * 2) / 2\n\nsubmission_df = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": y_test_pred\n})\n\nsubmission_df.to_csv(SUBMISSION_PATH, index=False)\n\nprint(\"Submission saved at:\", SUBMISSION_PATH)\nsubmission_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:51:59.719754Z","iopub.execute_input":"2025-12-16T10:51:59.720460Z","iopub.status.idle":"2025-12-16T10:51:59.812718Z","shell.execute_reply.started":"2025-12-16T10:51:59.720434Z","shell.execute_reply":"2025-12-16T10:51:59.812104Z"}},"outputs":[{"name":"stdout","text":"Total aligned test samples: 197\n    filename        e0        e1        e2        e3        e4        e5  \\\n0  audio_141  0.099782 -0.205726 -0.112622 -0.078250  0.039959 -0.126085   \n1  audio_114  0.103830 -0.134755  0.084457 -0.375298  0.066531  0.172808   \n2   audio_17  0.350971 -0.368010  0.342656 -0.326491 -0.043754 -0.135610   \n3   audio_76  0.009247 -0.307182  0.152034 -0.256583 -0.034348  0.111848   \n4  audio_156  0.344951 -0.338885  0.458355 -0.212554  0.345985 -0.039210   \n\n         e6        e7        e8  ...     e1014     e1015     e1016     e1017  \\\n0 -0.042891 -0.070192  0.095617  ...  0.000471 -0.426584  0.532851  0.185651   \n1 -0.017575  0.014542 -0.073765  ...  0.076440 -0.126993  0.037520  0.398466   \n2  0.119590 -0.076224 -0.032101  ... -0.350288 -0.345638  0.217359  0.514474   \n3 -0.296002  0.021410 -0.087357  ... -0.173768 -0.363479  0.276646  0.292233   \n4  0.080353 -0.010777 -0.035325  ... -0.307831 -0.081907  0.108643  0.190455   \n\n      e1018     e1019     e1020     e1021     e1022     e1023  \n0 -0.325133 -0.597734 -0.167319  0.035787 -1.089549 -0.131467  \n1 -0.376767 -0.067966  0.004974  0.032921 -0.155951  0.187089  \n2 -0.160688 -0.205467  0.012607  0.061503 -0.750322  0.152489  \n3 -0.002478 -0.072302  0.167044 -0.035520 -0.045989  0.074686  \n4 -0.518719 -0.210445 -0.232458  0.254069 -1.089615 -0.389325  \n\n[5 rows x 1025 columns]\nTest feature shape: (197, 1024)\nLoaded XGBoost model from: /kaggle/working/xgb_deberta_grammar_model.pkl\nSubmission saved at: /kaggle/working/submission.csv\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"    filename  label\n0  audio_141    2.5\n1  audio_114    4.0\n2   audio_17    2.5\n3   audio_76    4.5\n4  audio_156    2.5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_141</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_114</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_17</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_76</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_156</td>\n      <td>2.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\n\nTEST_META_PATH = \"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/csvs/test.csv\"\nDEBERTA_TEST_EMB_PATH = \"/kaggle/working/deberta_large_embeddings_test.csv\"\n\nBEST_MODEL_PATH = \"/kaggle/working/best_doberta_transcript_regression_model.keras\"\nSUBMISSION_PATH = \"/kaggle/working/submission.csv\"\n\n\ntest_meta_df = pd.read_csv(TEST_META_PATH)\ntest_emb_df = pd.read_csv(DEBERTA_TEST_EMB_PATH)\n\ntest_meta_df.rename(\n    columns={test_meta_df.columns[0]: \"filename\"}, inplace=True\n)\ntest_emb_df.rename(\n    columns={test_emb_df.columns[0]: \"filename\"}, inplace=True\n)\n\ntest_meta_df[\"filename\"] = test_meta_df[\"filename\"].astype(str)\ntest_emb_df[\"filename\"] = test_emb_df[\"filename\"].astype(str)\n\n\ntest_df = pd.merge(\n    test_meta_df,\n    test_emb_df,\n    on=\"filename\",\n    how=\"inner\"\n)\n\nprint(\"Total aligned test samples:\", len(test_df))\nprint(test_df.head())\n\n\nX_test_final = test_df.iloc[:, 1:].values.astype(np.float32)\n\nprint(\"Test feature shape:\", X_test_final.shape)\n\n\nmodel = tf.keras.models.load_model(BEST_MODEL_PATH)\nprint(\"Loaded best model from:\", BEST_MODEL_PATH)\n\n\ny_test_pred = model.predict(X_test_final).squeeze()\n\ny_test_pred = np.clip(y_test_pred, 0.0, 5.0)\n\n\nsubmission_df = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": y_test_pred\n})\n\nsubmission_df.to_csv(SUBMISSION_PATH, index=False)\n\nprint(\"Submission saved at:\", SUBMISSION_PATH)\nsubmission_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:01:07.250886Z","iopub.execute_input":"2025-12-16T11:01:07.251187Z","iopub.status.idle":"2025-12-16T11:01:08.239744Z","shell.execute_reply.started":"2025-12-16T11:01:07.251164Z","shell.execute_reply":"2025-12-16T11:01:08.239123Z"}},"outputs":[{"name":"stdout","text":"Total aligned test samples: 197\n    filename        e0        e1        e2        e3        e4        e5  \\\n0  audio_141  0.099782 -0.205726 -0.112622 -0.078250  0.039959 -0.126085   \n1  audio_114  0.103830 -0.134755  0.084457 -0.375298  0.066531  0.172808   \n2   audio_17  0.350971 -0.368010  0.342656 -0.326491 -0.043754 -0.135610   \n3   audio_76  0.009247 -0.307182  0.152034 -0.256583 -0.034348  0.111848   \n4  audio_156  0.344951 -0.338885  0.458355 -0.212554  0.345985 -0.039210   \n\n         e6        e7        e8  ...     e1014     e1015     e1016     e1017  \\\n0 -0.042891 -0.070192  0.095617  ...  0.000471 -0.426584  0.532851  0.185651   \n1 -0.017575  0.014542 -0.073765  ...  0.076440 -0.126993  0.037520  0.398466   \n2  0.119590 -0.076224 -0.032101  ... -0.350288 -0.345638  0.217359  0.514474   \n3 -0.296002  0.021410 -0.087357  ... -0.173768 -0.363479  0.276646  0.292233   \n4  0.080353 -0.010777 -0.035325  ... -0.307831 -0.081907  0.108643  0.190455   \n\n      e1018     e1019     e1020     e1021     e1022     e1023  \n0 -0.325133 -0.597734 -0.167319  0.035787 -1.089549 -0.131467  \n1 -0.376767 -0.067966  0.004974  0.032921 -0.155951  0.187089  \n2 -0.160688 -0.205467  0.012607  0.061503 -0.750322  0.152489  \n3 -0.002478 -0.072302  0.167044 -0.035520 -0.045989  0.074686  \n4 -0.518719 -0.210445 -0.232458  0.254069 -1.089615 -0.389325  \n\n[5 rows x 1025 columns]\nTest feature shape: (197, 1024)\nLoaded best model from: /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step\nSubmission saved at: /kaggle/working/submission.csv\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"    filename     label\n0  audio_141  1.934675\n1  audio_114  3.885600\n2   audio_17  2.486921\n3   audio_76  5.000000\n4  audio_156  3.454105","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_141</td>\n      <td>1.934675</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_114</td>\n      <td>3.885600</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_17</td>\n      <td>2.486921</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_76</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_156</td>\n      <td>3.454105</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"import whisper\nimport os\nimport pandas as pd\nfrom tqdm import tqdm\n\n\nAUDIO_DIR = \"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/audios/test\"\nOUTPUT_CSV = \"/kaggle/working/audio_test_transcripts.csv\"\n\nWHISPER_MODEL_SIZE = \"base\"   # tiny | base | small | medium | large\nLANGUAGE = \"en\"\n\n\nprint(\"Loading Whisper model...\")\nmodel = whisper.load_model(WHISPER_MODEL_SIZE)\nprint(\"Whisper model loaded\")\n\n\nrows = []\n\naudio_files = sorted([\n    f for f in os.listdir(AUDIO_DIR)\n    if f.lower().endswith(\".wav\")\n])\n\nprint(f\"Found {len(audio_files)} audio files\")\n\nfor fname in tqdm(audio_files):\n    audio_path = os.path.join(AUDIO_DIR, fname)\n\n    try:\n        result = model.transcribe(\n            audio_path,\n            language=LANGUAGE,\n            fp16=False   \n        )\n\n        transcript = result[\"text\"].strip()\n\n    except Exception as e:\n        print(f\"Error processing {fname}: {e}\")\n        transcript = \"\"\n\n    rows.append({\n        \"filename\": fname.replace(\".wav\", \"\"),  # audio_1.wav → audio_1\n        \"transcript\": transcript\n    })\n\ndf = pd.DataFrame(rows)\ndf.to_csv(OUTPUT_CSV, index=False)\n\nprint(\"\\nSaved transcripts to:\", OUTPUT_CSV)\ndf.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U openai-whisper\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\nfrom tqdm import tqdm\n\n\nINPUT_CSV = \"/kaggle/working/audio_train_transcripts.csv\"\nOUTPUT_CSV = \"/kaggle/working/bert_embeddings.csv\"\n\nMODEL_NAME = \"bert-base-uncased\"\nMAX_LEN = 128\nBATCH_SIZE = 16\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\ndf = pd.read_csv(INPUT_CSV)\ndf[\"transcript\"] = df[\"transcript\"].fillna(\"\")\n\nprint(\"Total transcripts:\", len(df))\n\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModel.from_pretrained(MODEL_NAME).to(device)\nmodel.eval()\n\n\ndef get_bert_embeddings(texts):\n    inputs = tokenizer(\n        texts,\n        padding=True,\n        truncation=True,\n        max_length=MAX_LEN,\n        return_tensors=\"pt\"\n    )\n\n    with torch.no_grad():\n        outputs = model(\n            input_ids=inputs[\"input_ids\"].to(device),\n            attention_mask=inputs[\"attention_mask\"].to(device)\n        )\n\n    # CLS token embedding → (B, 768)\n    cls_embeddings = outputs.last_hidden_state[:, 0, :]\n\n    return cls_embeddings.cpu().numpy()\n\n\nall_embeddings = []\n\nfor i in tqdm(range(0, len(df), BATCH_SIZE)):\n    batch_texts = df[\"transcript\"].iloc[i:i + BATCH_SIZE].tolist()\n    emb = get_bert_embeddings(batch_texts)\n    all_embeddings.append(emb)\n\nX = np.vstack(all_embeddings)\n\nprint(\"Embedding shape:\", X.shape)  # (N, 768)\n\nembedding_df = pd.DataFrame(\n    X,\n    columns=[f\"e{i}\" for i in range(X.shape[1])]\n)\n\nfinal_df = pd.concat(\n    [df[[\"filename\"]].reset_index(drop=True), embedding_df],\n    axis=1\n)\n\nfinal_df.to_csv(OUTPUT_CSV, index=False)\n\nprint(\"Saved BERT embeddings to:\", OUTPUT_CSV)\nfinal_df.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\nfrom tqdm import tqdm\n\n\nINPUT_CSV = \"/kaggle/working/audio_test_transcripts.csv\"\nOUTPUT_CSV = \"/kaggle/working/deberta_large_embeddings_test.csv\"\n\nMODEL_NAME = \"microsoft/deberta-v3-large\"\nMAX_LEN = 256         \nBATCH_SIZE = 16\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndf = pd.read_csv(INPUT_CSV)\ndf[\"transcript\"] = df[\"transcript\"].fillna(\"\").astype(str)\n\nprint(\"Total transcripts:\", len(df))\n\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModel.from_pretrained(MODEL_NAME).to(device)\nmodel.eval()\n\n\ndef mean_pooling(last_hidden_state, attention_mask):\n    \"\"\"\n    last_hidden_state: (B, T, H)\n    attention_mask:   (B, T)\n    \"\"\"\n    mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n    summed = torch.sum(last_hidden_state * mask, dim=1)\n    counts = torch.clamp(mask.sum(dim=1), min=1e-9)\n    return summed / counts\n\n\ndef get_deberta_embeddings(texts):\n    inputs = tokenizer(\n        texts,\n        padding=True,\n        truncation=True,\n        max_length=MAX_LEN,\n        return_tensors=\"pt\"\n    )\n\n    with torch.no_grad():\n        outputs = model(\n            input_ids=inputs[\"input_ids\"].to(device),\n            attention_mask=inputs[\"attention_mask\"].to(device)\n        )\n\n    embeddings = mean_pooling(\n        outputs.last_hidden_state,\n        inputs[\"attention_mask\"].to(device)\n    )\n\n    return embeddings.cpu().numpy()\n\n\nall_embeddings = []\n\nfor i in tqdm(range(0, len(df), BATCH_SIZE)):\n    batch_texts = df[\"transcript\"].iloc[i:i + BATCH_SIZE].tolist()\n    emb = get_deberta_embeddings(batch_texts)\n    all_embeddings.append(emb)\n\nX = np.vstack(all_embeddings)\n\nprint(\"Embedding shape:\", X.shape)  # (N, 768)\n\n\nembedding_df = pd.DataFrame(\n    X,\n    columns=[f\"e{i}\" for i in range(X.shape[1])]\n)\n\nfinal_df = pd.concat(\n    [df[[\"filename\"]].reset_index(drop=True), embedding_df],\n    axis=1\n)\n\nfinal_df.to_csv(OUTPUT_CSV, index=False)\n\nprint(\"Saved DeBERTa embeddings to:\", OUTPUT_CSV)\nfinal_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:02:41.833938Z","iopub.execute_input":"2025-12-16T10:02:41.834537Z","iopub.status.idle":"2025-12-16T10:02:49.737960Z","shell.execute_reply.started":"2025-12-16T10:02:41.834507Z","shell.execute_reply":"2025-12-16T10:02:49.737406Z"}},"outputs":[{"name":"stdout","text":"Total transcripts: 197\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n100%|██████████| 13/13 [00:04<00:00,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Embedding shape: (197, 1024)\nSaved DeBERTa embeddings to: /kaggle/working/deberta_large_embeddings_test.csv\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"    filename        e0        e1        e2        e3        e4        e5  \\\n0    audio_1  0.224947 -0.405848  0.573340 -0.407065  0.052722 -0.113580   \n1   audio_10  0.098477 -0.245417  0.524971 -0.221284  0.003748  0.163754   \n2  audio_100  0.447721  0.059997  0.664966 -0.545253  0.117874 -0.034652   \n3  audio_101  0.369042 -0.323718  0.553655 -0.178902  0.304813 -0.024624   \n4  audio_102  0.142880 -0.199646  0.271711 -0.457679 -0.004549  0.331301   \n\n         e6        e7        e8  ...     e1014     e1015     e1016     e1017  \\\n0 -0.011057  0.003411  0.022139  ... -0.308698 -0.184177 -0.005291  0.221239   \n1 -0.007403 -0.059899 -0.021320  ... -0.375762 -0.400642  0.059986  0.240107   \n2  0.106867  0.088440 -0.086432  ... -0.334274 -0.098004 -0.278957  0.342436   \n3  0.211365 -0.026503  0.096263  ... -0.178587 -0.203587 -0.109451  0.452220   \n4  0.008655  0.123272  0.190292  ... -0.089540 -0.228065 -0.062575  0.403322   \n\n      e1018     e1019     e1020     e1021     e1022     e1023  \n0  0.046818 -0.147100 -0.068861  0.028528 -0.366116  0.035095  \n1 -0.457293 -0.104484 -0.158275 -0.001369 -0.580557 -0.011623  \n2 -0.229205 -0.052819 -0.075702  0.044247 -0.004279  0.133923  \n3 -0.259855 -0.051301 -0.259910  0.026615 -0.409907 -0.110399  \n4 -0.185059 -0.184725 -0.050202 -0.076124 -0.008634  0.359956  \n\n[5 rows x 1025 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>e0</th>\n      <th>e1</th>\n      <th>e2</th>\n      <th>e3</th>\n      <th>e4</th>\n      <th>e5</th>\n      <th>e6</th>\n      <th>e7</th>\n      <th>e8</th>\n      <th>...</th>\n      <th>e1014</th>\n      <th>e1015</th>\n      <th>e1016</th>\n      <th>e1017</th>\n      <th>e1018</th>\n      <th>e1019</th>\n      <th>e1020</th>\n      <th>e1021</th>\n      <th>e1022</th>\n      <th>e1023</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_1</td>\n      <td>0.224947</td>\n      <td>-0.405848</td>\n      <td>0.573340</td>\n      <td>-0.407065</td>\n      <td>0.052722</td>\n      <td>-0.113580</td>\n      <td>-0.011057</td>\n      <td>0.003411</td>\n      <td>0.022139</td>\n      <td>...</td>\n      <td>-0.308698</td>\n      <td>-0.184177</td>\n      <td>-0.005291</td>\n      <td>0.221239</td>\n      <td>0.046818</td>\n      <td>-0.147100</td>\n      <td>-0.068861</td>\n      <td>0.028528</td>\n      <td>-0.366116</td>\n      <td>0.035095</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_10</td>\n      <td>0.098477</td>\n      <td>-0.245417</td>\n      <td>0.524971</td>\n      <td>-0.221284</td>\n      <td>0.003748</td>\n      <td>0.163754</td>\n      <td>-0.007403</td>\n      <td>-0.059899</td>\n      <td>-0.021320</td>\n      <td>...</td>\n      <td>-0.375762</td>\n      <td>-0.400642</td>\n      <td>0.059986</td>\n      <td>0.240107</td>\n      <td>-0.457293</td>\n      <td>-0.104484</td>\n      <td>-0.158275</td>\n      <td>-0.001369</td>\n      <td>-0.580557</td>\n      <td>-0.011623</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_100</td>\n      <td>0.447721</td>\n      <td>0.059997</td>\n      <td>0.664966</td>\n      <td>-0.545253</td>\n      <td>0.117874</td>\n      <td>-0.034652</td>\n      <td>0.106867</td>\n      <td>0.088440</td>\n      <td>-0.086432</td>\n      <td>...</td>\n      <td>-0.334274</td>\n      <td>-0.098004</td>\n      <td>-0.278957</td>\n      <td>0.342436</td>\n      <td>-0.229205</td>\n      <td>-0.052819</td>\n      <td>-0.075702</td>\n      <td>0.044247</td>\n      <td>-0.004279</td>\n      <td>0.133923</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_101</td>\n      <td>0.369042</td>\n      <td>-0.323718</td>\n      <td>0.553655</td>\n      <td>-0.178902</td>\n      <td>0.304813</td>\n      <td>-0.024624</td>\n      <td>0.211365</td>\n      <td>-0.026503</td>\n      <td>0.096263</td>\n      <td>...</td>\n      <td>-0.178587</td>\n      <td>-0.203587</td>\n      <td>-0.109451</td>\n      <td>0.452220</td>\n      <td>-0.259855</td>\n      <td>-0.051301</td>\n      <td>-0.259910</td>\n      <td>0.026615</td>\n      <td>-0.409907</td>\n      <td>-0.110399</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_102</td>\n      <td>0.142880</td>\n      <td>-0.199646</td>\n      <td>0.271711</td>\n      <td>-0.457679</td>\n      <td>-0.004549</td>\n      <td>0.331301</td>\n      <td>0.008655</td>\n      <td>0.123272</td>\n      <td>0.190292</td>\n      <td>...</td>\n      <td>-0.089540</td>\n      <td>-0.228065</td>\n      <td>-0.062575</td>\n      <td>0.403322</td>\n      <td>-0.185059</td>\n      <td>-0.184725</td>\n      <td>-0.050202</td>\n      <td>-0.076124</td>\n      <td>-0.008634</td>\n      <td>0.359956</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1025 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n\nbert_df = pd.read_csv(\"/kaggle/working/deberta_large_embeddings.csv\")\nlabel_df = pd.read_csv(\n    \"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/csvs/train.csv\"\n)\n\nbert_df.rename(columns={bert_df.columns[0]: \"filename\"}, inplace=True)\nlabel_df.rename(columns={label_df.columns[0]: \"filename\"}, inplace=True)\n\nbert_df[\"filename\"] = bert_df[\"filename\"].astype(str)\n\ndf = pd.merge(bert_df, label_df, on=\"filename\", how=\"inner\")\nprint(\"Total aligned samples:\", len(df))\n\n\nX = df.iloc[:, 1:-1].values.astype(np.float32)   \ny = df.iloc[:, -1].values.astype(np.float32)    \n\nprint(\"X shape:\", X.shape) \n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n\n# model = tf.keras.Sequential([\n#     tf.keras.layers.Input(shape=(1024,)),\n\n#     tf.keras.layers.Dense(256, activation=\"relu\"),\n#     tf.keras.layers.BatchNormalization(),\n#     tf.keras.layers.Dropout(0.25),\n\n#     tf.keras.layers.Dense(128, activation=\"relu\"),\n#     tf.keras.layers.BatchNormalization(),\n#     tf.keras.layers.Dropout(0.15),\n\n#     tf.keras.layers.Dense(64, activation=\"relu\"),\n#     tf.keras.layers.Dense(8, activation=\"relu\"),\n\n#     tf.keras.layers.Dense(1)\n# ])\n\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(1024,)),\n\n    tf.keras.layers.Reshape((1024, 1)),\n\n    # Conv Block 1\n    # tf.keras.layers.Conv1D(\n    #     filters=256,\n    #     kernel_size=5,\n    #     activation=\"relu\",\n    #     padding=\"same\"\n    # ),\n    # tf.keras.layers.BatchNormalization(),\n    # tf.keras.layers.MaxPooling1D(pool_size=2),\n\n    # Conv Block 2\n    tf.keras.layers.Conv1D(\n        filters=512,\n        kernel_size=5,\n        activation=\"swish\",\n        padding=\"same\"\n    ),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n\n    tf.keras.layers.Flatten(),\n    # tf.keras.layers.Dense(512, activation=\"relu\"),\n    # tf.keras.layers.Dense(256, activation=\"relu\"),\n    # tf.keras.layers.Dense(128, activation=\"relu\"),\n    tf.keras.layers.Dense(256, activation=\"relu\"),\n    tf.keras.layers.Dense(8, activation=\"relu\"),\n\n    tf.keras.layers.Dense(1)\n])\n\nmodel.summary()\n\n\n\nBEST_MODEL_PATH = \"/kaggle/working/best_doberta_transcript_regression_model.keras\"\n\ncheckpoint_cb = ModelCheckpoint(\n    filepath=BEST_MODEL_PATH,\n    monitor=\"val_loss\",        # use validation loss\n    mode=\"min\",\n    save_best_only=True,       # only save best epoch\n    save_weights_only=False,   # save full model\n    verbose=1\n)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(0.005),\n    loss=\"mse\",\n    metrics=[\"mae\"]\n)\n\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=100,\n    batch_size=8,\n    callbacks=[checkpoint_cb],  \n    verbose=1\n)\n\nbest_model = tf.keras.models.load_model(BEST_MODEL_PATH)\nprint(\"Loaded best model from:\", BEST_MODEL_PATH)\n\ntrain_loss, train_mae = best_model.evaluate(X_train, y_train, verbose=0)\ntest_loss, test_mae = best_model.evaluate(X_test, y_test, verbose=0)\n\ntrain_rmse = np.sqrt(train_loss)\ntest_rmse = np.sqrt(test_loss)\n\nprint(\"\\n=== LOSS / MAE / RMSE ===\")\nprint(f\"Train MSE  : {train_loss:.4f}\")\nprint(f\"Train RMSE : {train_rmse:.4f}\")\nprint(f\"Train MAE  : {train_mae:.4f}\")\nprint()\nprint(f\"Test MSE   : {test_loss:.4f}\")\nprint(f\"Test RMSE  : {test_rmse:.4f}\")\nprint(f\"Test MAE   : {test_mae:.4f}\")\n\n\ny_train_pred = best_model.predict(X_train).squeeze()\ny_test_pred = best_model.predict(X_test).squeeze()\n\ny_train_pred = np.clip(y_train_pred, 0.0, 5.0)\ny_test_pred = np.clip(y_test_pred, 0.0, 5.0)\n\ndef tolerance_accuracy(y_true, y_pred, tol=0.5):\n    return np.mean(np.abs(y_true - y_pred) <= tol)\n\ntrain_acc = tolerance_accuracy(y_train, y_train_pred)\ntest_acc = tolerance_accuracy(y_test, y_test_pred)\n\nprint(\"\\n=== REGRESSION ACCURACY (±0.5) ===\")\nprint(f\"Train Accuracy: {train_acc * 100:.2f}%\")\nprint(f\"Test Accuracy : {test_acc * 100:.2f}%\")\n\n\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\n\nprint(\"\\n=== R² SCORE ===\")\nprint(f\"Train R²: {train_r2:.4f}\")\nprint(f\"Test R² : {test_r2:.4f}\")\n\n\nMODEL_PATH = \"/kaggle/working/bert_transcript_regression_model.keras\"\nmodel.save(MODEL_PATH)\n\nprint(\"Model saved at:\", MODEL_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:07:07.974194Z","iopub.execute_input":"2025-12-16T11:07:07.974513Z","iopub.status.idle":"2025-12-16T11:12:49.396284Z","shell.execute_reply.started":"2025-12-16T11:07:07.974488Z","shell.execute_reply":"2025-12-16T11:12:49.395482Z"}},"outputs":[{"name":"stdout","text":"Total aligned samples: 409\nX shape: (409, 1024)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_16\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ reshape_12 (\u001b[38;5;33mReshape\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m3,072\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_35          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling1d_21 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_12 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_81 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m67,109,120\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_82 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m2,056\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_83 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ reshape_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_35          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">67,109,120</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,116,305\u001b[0m (256.03 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,116,305</span> (256.03 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,115,281\u001b[0m (256.02 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,115,281</span> (256.02 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1726.9971 - mae: 18.3049\nEpoch 1: val_loss improved from inf to 21487.07812, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 1699.1874 - mae: 18.0573 - val_loss: 21487.0781 - val_mae: 146.5798\nEpoch 2/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 33.3819 - mae: 4.2469\nEpoch 2: val_loss improved from 21487.07812 to 12094.14941, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - loss: 31.5903 - mae: 4.1491 - val_loss: 12094.1494 - val_mae: 109.9452\nEpoch 3/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.9636 - mae: 2.8877\nEpoch 3: val_loss improved from 12094.14941 to 9118.83398, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 8.9634 - mae: 2.8881 - val_loss: 9118.8340 - val_mae: 95.4459\nEpoch 4/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.3492 - mae: 2.7981\nEpoch 4: val_loss improved from 9118.83398 to 6059.99951, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 8.3645 - mae: 2.8002 - val_loss: 6059.9995 - val_mae: 77.7234\nEpoch 5/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.5711 - mae: 2.8171\nEpoch 5: val_loss improved from 6059.99951 to 3167.40137, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 8.5508 - mae: 2.8144 - val_loss: 3167.4014 - val_mae: 55.9571\nEpoch 6/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.1735 - mae: 2.7622\nEpoch 6: val_loss improved from 3167.40137 to 830.43195, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 8.1715 - mae: 2.7617 - val_loss: 830.4319 - val_mae: 27.5336\nEpoch 7/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.5597 - mae: 2.6358\nEpoch 7: val_loss improved from 830.43195 to 125.99091, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 7.5799 - mae: 2.6399 - val_loss: 125.9909 - val_mae: 8.7066\nEpoch 8/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.1064 - mae: 2.5523\nEpoch 8: val_loss did not improve from 125.99091\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.1385 - mae: 2.5584 - val_loss: 773.0118 - val_mae: 27.3688\nEpoch 9/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.2058 - mae: 2.5732\nEpoch 9: val_loss did not improve from 125.99091\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.2007 - mae: 2.5722 - val_loss: 331.4015 - val_mae: 16.9471\nEpoch 10/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.0407 - mae: 2.5153\nEpoch 10: val_loss improved from 125.99091 to 23.29037, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 7.0272 - mae: 2.5137 - val_loss: 23.2904 - val_mae: 3.9091\nEpoch 11/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.1681 - mae: 2.3799\nEpoch 11: val_loss improved from 23.29037 to 6.12989, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 6.1923 - mae: 2.3831 - val_loss: 6.1299 - val_mae: 2.3589\nEpoch 12/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.9052 - mae: 2.3002\nEpoch 12: val_loss improved from 6.12989 to 5.79451, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - loss: 5.9264 - mae: 2.3053 - val_loss: 5.7945 - val_mae: 2.2867\nEpoch 13/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.6851 - mae: 2.2645\nEpoch 13: val_loss improved from 5.79451 to 5.46627, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 5.6877 - mae: 2.2647 - val_loss: 5.4663 - val_mae: 2.2138\nEpoch 14/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6960 - mae: 2.2469\nEpoch 14: val_loss improved from 5.46627 to 5.13950, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 5.6825 - mae: 2.2444 - val_loss: 5.1395 - val_mae: 2.1387\nEpoch 15/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.0529 - mae: 2.1106\nEpoch 15: val_loss improved from 5.13950 to 4.82901, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 5.0565 - mae: 2.1115 - val_loss: 4.8290 - val_mae: 2.0648\nEpoch 16/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.0741 - mae: 2.1139\nEpoch 16: val_loss improved from 4.82901 to 4.52375, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 5.0402 - mae: 2.1065 - val_loss: 4.5237 - val_mae: 1.9895\nEpoch 17/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.3393 - mae: 1.9514\nEpoch 17: val_loss improved from 4.52375 to 4.23556, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 4.3426 - mae: 1.9519 - val_loss: 4.2356 - val_mae: 1.9157\nEpoch 18/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.2603 - mae: 1.9322\nEpoch 18: val_loss improved from 4.23556 to 3.95355, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 4.2555 - mae: 1.9297 - val_loss: 3.9536 - val_mae: 1.8407\nEpoch 19/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.9822 - mae: 1.8497\nEpoch 19: val_loss improved from 3.95355 to 3.68838, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 3.9717 - mae: 1.8466 - val_loss: 3.6884 - val_mae: 1.7672\nEpoch 20/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.9067 - mae: 1.8040\nEpoch 20: val_loss improved from 3.68838 to 3.43052, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 3.8945 - mae: 1.8014 - val_loss: 3.4305 - val_mae: 1.6926\nEpoch 21/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.1728 - mae: 1.6204\nEpoch 21: val_loss improved from 3.43052 to 3.19053, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 3.1888 - mae: 1.6245 - val_loss: 3.1905 - val_mae: 1.6202\nEpoch 22/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.2764 - mae: 1.6315\nEpoch 22: val_loss improved from 3.19053 to 2.96062, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 3.2710 - mae: 1.6302 - val_loss: 2.9606 - val_mae: 1.5476\nEpoch 23/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.8199 - mae: 1.5032\nEpoch 23: val_loss improved from 2.96062 to 2.74923, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - loss: 2.8255 - mae: 1.5047 - val_loss: 2.7492 - val_mae: 1.4778\nEpoch 24/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.2559 - mae: 1.5981\nEpoch 24: val_loss improved from 2.74923 to 2.54761, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 3.2054 - mae: 1.5851 - val_loss: 2.5476 - val_mae: 1.4079\nEpoch 25/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.4893 - mae: 1.3937\nEpoch 25: val_loss improved from 2.54761 to 2.36044, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 2.4913 - mae: 1.3938 - val_loss: 2.3604 - val_mae: 1.3398\nEpoch 26/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7722 - mae: 1.4476\nEpoch 26: val_loss improved from 2.36044 to 2.18248, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 2.7258 - mae: 1.4347 - val_loss: 2.1825 - val_mae: 1.2716\nEpoch 27/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.4314 - mae: 1.3561\nEpoch 27: val_loss improved from 2.18248 to 2.02017, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 2.4052 - mae: 1.3463 - val_loss: 2.0202 - val_mae: 1.2061\nEpoch 28/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9846 - mae: 1.2130\nEpoch 28: val_loss improved from 2.02017 to 1.87534, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 1.9875 - mae: 1.2122 - val_loss: 1.8753 - val_mae: 1.1445\nEpoch 29/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9242 - mae: 1.1609\nEpoch 29: val_loss improved from 1.87534 to 1.73664, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 1.9205 - mae: 1.1593 - val_loss: 1.7366 - val_mae: 1.0822\nEpoch 30/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7276 - mae: 1.0688\nEpoch 30: val_loss improved from 1.73664 to 1.60920, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 1.7290 - mae: 1.0701 - val_loss: 1.6092 - val_mae: 1.0216\nEpoch 31/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7215 - mae: 1.0651\nEpoch 31: val_loss improved from 1.60920 to 1.49187, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 1.7139 - mae: 1.0619 - val_loss: 1.4919 - val_mae: 0.9625\nEpoch 32/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4398 - mae: 0.9498\nEpoch 32: val_loss improved from 1.49187 to 1.38855, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 1.4444 - mae: 0.9508 - val_loss: 1.3885 - val_mae: 0.9072\nEpoch 33/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5204 - mae: 0.9691\nEpoch 33: val_loss improved from 1.38855 to 1.28977, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 1.5146 - mae: 0.9666 - val_loss: 1.2898 - val_mae: 0.8709\nEpoch 34/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2997 - mae: 0.8870\nEpoch 34: val_loss improved from 1.28977 to 1.20324, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 1.2998 - mae: 0.8870 - val_loss: 1.2032 - val_mae: 0.8415\nEpoch 35/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2203 - mae: 0.8571\nEpoch 35: val_loss improved from 1.20324 to 1.12504, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 1.2208 - mae: 0.8571 - val_loss: 1.1250 - val_mae: 0.8131\nEpoch 36/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2168 - mae: 0.8491\nEpoch 36: val_loss improved from 1.12504 to 1.05428, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 1.2095 - mae: 0.8472 - val_loss: 1.0543 - val_mae: 0.7857\nEpoch 37/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0515 - mae: 0.7998\nEpoch 37: val_loss improved from 1.05428 to 0.99095, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 1.0543 - mae: 0.8001 - val_loss: 0.9909 - val_mae: 0.7594\nEpoch 38/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7692 - mae: 0.6951\nEpoch 38: val_loss improved from 0.99095 to 0.93692, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.7808 - mae: 0.6991 - val_loss: 0.9369 - val_mae: 0.7354\nEpoch 39/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0088 - mae: 0.7564\nEpoch 39: val_loss improved from 0.93692 to 0.88504, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 1.0053 - mae: 0.7562 - val_loss: 0.8850 - val_mae: 0.7106\nEpoch 40/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7909 - mae: 0.6877\nEpoch 40: val_loss improved from 0.88504 to 0.83860, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.8067 - mae: 0.6936 - val_loss: 0.8386 - val_mae: 0.6867\nEpoch 41/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8948 - mae: 0.7218\nEpoch 41: val_loss improved from 0.83860 to 0.79981, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.8930 - mae: 0.7210 - val_loss: 0.7998 - val_mae: 0.6651\nEpoch 42/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7764 - mae: 0.6658\nEpoch 42: val_loss improved from 0.79981 to 0.76612, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.7803 - mae: 0.6679 - val_loss: 0.7661 - val_mae: 0.6448\nEpoch 43/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7651 - mae: 0.6510\nEpoch 43: val_loss improved from 0.76612 to 0.73597, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.7670 - mae: 0.6524 - val_loss: 0.7360 - val_mae: 0.6251\nEpoch 44/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8622 - mae: 0.6941\nEpoch 44: val_loss improved from 0.73597 to 0.70774, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.8575 - mae: 0.6921 - val_loss: 0.7077 - val_mae: 0.6121\nEpoch 45/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6981 - mae: 0.6201\nEpoch 45: val_loss improved from 0.70774 to 0.68541, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.7023 - mae: 0.6225 - val_loss: 0.6854 - val_mae: 0.6061\nEpoch 46/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7041 - mae: 0.6364\nEpoch 46: val_loss improved from 0.68541 to 0.66674, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.7046 - mae: 0.6364 - val_loss: 0.6667 - val_mae: 0.6006\nEpoch 47/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8482 - mae: 0.6846\nEpoch 47: val_loss improved from 0.66674 to 0.64973, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.8344 - mae: 0.6798 - val_loss: 0.6497 - val_mae: 0.5952\nEpoch 48/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6058 - mae: 0.5805\nEpoch 48: val_loss improved from 0.64973 to 0.63519, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.6075 - mae: 0.5816 - val_loss: 0.6352 - val_mae: 0.5900\nEpoch 49/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6343 - mae: 0.6168\nEpoch 49: val_loss improved from 0.63519 to 0.62238, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.6358 - mae: 0.6171 - val_loss: 0.6224 - val_mae: 0.5851\nEpoch 50/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6536 - mae: 0.6400\nEpoch 50: val_loss improved from 0.62238 to 0.61239, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.6536 - mae: 0.6394 - val_loss: 0.6124 - val_mae: 0.5808\nEpoch 51/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5703 - mae: 0.5808\nEpoch 51: val_loss improved from 0.61239 to 0.60378, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.5721 - mae: 0.5816 - val_loss: 0.6038 - val_mae: 0.5767\nEpoch 52/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6370 - mae: 0.6140\nEpoch 52: val_loss improved from 0.60378 to 0.59606, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.6376 - mae: 0.6137 - val_loss: 0.5961 - val_mae: 0.5726\nEpoch 53/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5256 - mae: 0.5609\nEpoch 53: val_loss improved from 0.59606 to 0.59022, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.5304 - mae: 0.5630 - val_loss: 0.5902 - val_mae: 0.5692\nEpoch 54/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5051 - mae: 0.5626\nEpoch 54: val_loss improved from 0.59022 to 0.58565, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 182ms/step - loss: 0.5078 - mae: 0.5635 - val_loss: 0.5857 - val_mae: 0.5662\nEpoch 55/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5905 - mae: 0.5957\nEpoch 55: val_loss improved from 0.58565 to 0.58104, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.5921 - mae: 0.5957 - val_loss: 0.5810 - val_mae: 0.5629\nEpoch 56/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6188 - mae: 0.5911\nEpoch 56: val_loss improved from 0.58104 to 0.57711, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.6182 - mae: 0.5913 - val_loss: 0.5771 - val_mae: 0.5596\nEpoch 57/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6418 - mae: 0.6069\nEpoch 57: val_loss improved from 0.57711 to 0.57468, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.6377 - mae: 0.6050 - val_loss: 0.5747 - val_mae: 0.5572\nEpoch 58/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5303 - mae: 0.5720\nEpoch 58: val_loss improved from 0.57468 to 0.57251, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.5358 - mae: 0.5733 - val_loss: 0.5725 - val_mae: 0.5549\nEpoch 59/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6036 - mae: 0.5912\nEpoch 59: val_loss improved from 0.57251 to 0.57087, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.6035 - mae: 0.5910 - val_loss: 0.5709 - val_mae: 0.5528\nEpoch 60/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6575 - mae: 0.5992\nEpoch 60: val_loss improved from 0.57087 to 0.56966, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.6521 - mae: 0.5979 - val_loss: 0.5697 - val_mae: 0.5511\nEpoch 61/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5837 - mae: 0.5825\nEpoch 61: val_loss improved from 0.56966 to 0.56836, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.5841 - mae: 0.5825 - val_loss: 0.5684 - val_mae: 0.5490\nEpoch 62/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6501 - mae: 0.6103\nEpoch 62: val_loss improved from 0.56836 to 0.56748, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 200ms/step - loss: 0.6488 - mae: 0.6096 - val_loss: 0.5675 - val_mae: 0.5473\nEpoch 63/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6568 - mae: 0.6261\nEpoch 63: val_loss improved from 0.56748 to 0.56695, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.6514 - mae: 0.6218 - val_loss: 0.5670 - val_mae: 0.5460\nEpoch 64/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5228 - mae: 0.5408\nEpoch 64: val_loss improved from 0.56695 to 0.56660, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.5245 - mae: 0.5417 - val_loss: 0.5666 - val_mae: 0.5451\nEpoch 65/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5600 - mae: 0.5821\nEpoch 65: val_loss improved from 0.56660 to 0.56616, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 0.5617 - mae: 0.5819 - val_loss: 0.5662 - val_mae: 0.5436\nEpoch 66/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4995 - mae: 0.5312\nEpoch 66: val_loss improved from 0.56616 to 0.56584, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.5105 - mae: 0.5364 - val_loss: 0.5658 - val_mae: 0.5423\nEpoch 67/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6226 - mae: 0.5771\nEpoch 67: val_loss improved from 0.56584 to 0.56570, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.6206 - mae: 0.5770 - val_loss: 0.5657 - val_mae: 0.5414\nEpoch 68/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5795 - mae: 0.5639\nEpoch 68: val_loss improved from 0.56570 to 0.56559, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.5803 - mae: 0.5644 - val_loss: 0.5656 - val_mae: 0.5406\nEpoch 69/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6844 - mae: 0.6161\nEpoch 69: val_loss improved from 0.56559 to 0.56551, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 185ms/step - loss: 0.6778 - mae: 0.6131 - val_loss: 0.5655 - val_mae: 0.5397\nEpoch 70/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5664 - mae: 0.5535\nEpoch 70: val_loss improved from 0.56551 to 0.56549, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.5670 - mae: 0.5540 - val_loss: 0.5655 - val_mae: 0.5394\nEpoch 71/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5420 - mae: 0.5448\nEpoch 71: val_loss improved from 0.56549 to 0.56548, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.5433 - mae: 0.5454 - val_loss: 0.5655 - val_mae: 0.5387\nEpoch 72/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6430 - mae: 0.5955\nEpoch 72: val_loss improved from 0.56548 to 0.56547, saving model to /kaggle/working/best_doberta_transcript_regression_model.keras\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.6396 - mae: 0.5939 - val_loss: 0.5655 - val_mae: 0.5384\nEpoch 73/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5932 - mae: 0.5842\nEpoch 73: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.5932 - mae: 0.5835 - val_loss: 0.5655 - val_mae: 0.5381\nEpoch 74/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5162 - mae: 0.5425\nEpoch 74: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5230 - mae: 0.5450 - val_loss: 0.5655 - val_mae: 0.5373\nEpoch 75/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5740 - mae: 0.5518\nEpoch 75: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5748 - mae: 0.5527 - val_loss: 0.5656 - val_mae: 0.5363\nEpoch 76/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6158 - mae: 0.6025\nEpoch 76: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.6140 - mae: 0.6002 - val_loss: 0.5656 - val_mae: 0.5367\nEpoch 77/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6394 - mae: 0.5870\nEpoch 77: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.6345 - mae: 0.5852 - val_loss: 0.5656 - val_mae: 0.5365\nEpoch 78/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5322 - mae: 0.5446\nEpoch 78: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.5364 - mae: 0.5463 - val_loss: 0.5656 - val_mae: 0.5364\nEpoch 79/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5291 - mae: 0.5464\nEpoch 79: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.5306 - mae: 0.5469 - val_loss: 0.5657 - val_mae: 0.5359\nEpoch 80/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6297 - mae: 0.5933\nEpoch 80: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.6272 - mae: 0.5915 - val_loss: 0.5657 - val_mae: 0.5357\nEpoch 81/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5852 - mae: 0.5647\nEpoch 81: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5862 - mae: 0.5652 - val_loss: 0.5658 - val_mae: 0.5352\nEpoch 82/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6692 - mae: 0.6164\nEpoch 82: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.6637 - mae: 0.6130 - val_loss: 0.5657 - val_mae: 0.5356\nEpoch 83/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6434 - mae: 0.5932\nEpoch 83: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.6399 - mae: 0.5915 - val_loss: 0.5657 - val_mae: 0.5356\nEpoch 84/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5583 - mae: 0.5539\nEpoch 84: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5609 - mae: 0.5549 - val_loss: 0.5658 - val_mae: 0.5351\nEpoch 85/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5573 - mae: 0.5507\nEpoch 85: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5590 - mae: 0.5515 - val_loss: 0.5657 - val_mae: 0.5354\nEpoch 86/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5934 - mae: 0.5784\nEpoch 86: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5936 - mae: 0.5777 - val_loss: 0.5658 - val_mae: 0.5352\nEpoch 87/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5789 - mae: 0.5606\nEpoch 87: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5807 - mae: 0.5616 - val_loss: 0.5657 - val_mae: 0.5356\nEpoch 88/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7302 - mae: 0.6308\nEpoch 88: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.7237 - mae: 0.6278 - val_loss: 0.5659 - val_mae: 0.5346\nEpoch 89/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6365 - mae: 0.6078\nEpoch 89: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.6323 - mae: 0.6042 - val_loss: 0.5657 - val_mae: 0.5356\nEpoch 90/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5763 - mae: 0.5634\nEpoch 90: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5771 - mae: 0.5636 - val_loss: 0.5657 - val_mae: 0.5355\nEpoch 91/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6178 - mae: 0.5859\nEpoch 91: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.6158 - mae: 0.5843 - val_loss: 0.5658 - val_mae: 0.5349\nEpoch 92/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5683 - mae: 0.5790\nEpoch 92: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5689 - mae: 0.5787 - val_loss: 0.5657 - val_mae: 0.5355\nEpoch 93/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5536 - mae: 0.5319\nEpoch 93: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5567 - mae: 0.5346 - val_loss: 0.5659 - val_mae: 0.5346\nEpoch 94/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5336 - mae: 0.5353\nEpoch 94: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5385 - mae: 0.5382 - val_loss: 0.5657 - val_mae: 0.5356\nEpoch 95/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6052 - mae: 0.5668\nEpoch 95: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.6045 - mae: 0.5671 - val_loss: 0.5659 - val_mae: 0.5343\nEpoch 96/100\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5360 - mae: 0.5430\nEpoch 96: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5374 - mae: 0.5436 - val_loss: 0.5657 - val_mae: 0.5358\nEpoch 97/100\n\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5188 - mae: 0.5411\nEpoch 97: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5255 - mae: 0.5436 - val_loss: 0.5657 - val_mae: 0.5357\nEpoch 98/100\n\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6302 - mae: 0.5665\nEpoch 98: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.6284 - mae: 0.5665 - val_loss: 0.5659 - val_mae: 0.5344\nEpoch 99/100\n\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5731 - mae: 0.5491\nEpoch 99: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5757 - mae: 0.5514 - val_loss: 0.5657 - val_mae: 0.5353\nEpoch 100/100\n\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6538 - mae: 0.6055\nEpoch 100: val_loss did not improve from 0.56547\n\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.6492 - mae: 0.6027 - val_loss: 0.5658 - val_mae: 0.5353\nLoaded best model from: /kaggle/working/best_doberta_transcript_regression_model.keras\n\n=== LOSS / MAE / RMSE ===\nTrain MSE  : 0.5924\nTrain RMSE : 0.7696\nTrain MAE  : 0.5709\n\nTest MSE   : 0.5655\nTest RMSE  : 0.7520\nTest MAE   : 0.5384\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n\n=== REGRESSION ACCURACY (±0.5) ===\nTrain Accuracy: 54.13%\nTest Accuracy : 59.76%\n\n=== R² SCORE ===\nTrain R²: -0.0005\nTest R² : -0.0000\nModel saved at: /kaggle/working/bert_transcript_regression_model.keras\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport joblib\n\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\nEMB_PATH = \"/kaggle/working/deberta_large_embeddings.csv\"\nLABEL_PATH = \"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/csvs/train.csv\"\n\nMODEL_PATH = \"/kaggle/working/xgb_deberta_grammar_model.pkl\"\n\nRANDOM_STATE = 42\n\nemb_df = pd.read_csv(EMB_PATH)\nlabel_df = pd.read_csv(LABEL_PATH)\n\nemb_df.rename(columns={emb_df.columns[0]: \"filename\"}, inplace=True)\nlabel_df.rename(columns={label_df.columns[0]: \"filename\"}, inplace=True)\n\nemb_df[\"filename\"] = emb_df[\"filename\"].astype(str)\n\ndf = pd.merge(emb_df, label_df, on=\"filename\", how=\"inner\")\nprint(\"Total aligned samples:\", len(df))\n\n\nX = df.iloc[:, 1:-1].values.astype(np.float32)   # DeBERTa embeddings\ny = df.iloc[:, -1].values.astype(np.float32)    # Grammar scores (0–5)\n\nprint(\"X shape:\", X.shape)\n\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X,\n    y,\n    test_size=0.2,\n    random_state=RANDOM_STATE\n)\n\n\ndef tolerance_accuracy(y_true, y_pred, tol=0.5):\n    return np.mean(np.abs(y_true - y_pred) <= tol)\n\n\nxgb_model = XGBRegressor(\n    n_estimators=1500,\n    max_depth=8,              \n    learning_rate=0.01,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    min_child_weight=5,       \n    gamma=0.2,               \n    reg_alpha=0.1,           \n    objective=\"reg:squarederror\",\n    random_state=42,\n    n_jobs=-1\n)\n\nxgb_model.fit(\n    X_train,\n    y_train,\n    eval_set=[(X_val, y_val)],\n    early_stopping_rounds=40,\n    verbose=True\n)\n\n\ny_train_pred = xgb_model.predict(X_train)\ny_val_pred = xgb_model.predict(X_val)\n\ny_train_pred = np.clip(y_train_pred, 0.0, 5.0)\ny_val_pred = np.clip(y_val_pred, 0.0, 5.0)\n\n# RMSE\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\nval_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n\ntrain_r2 = r2_score(y_train, y_train_pred)\nval_r2 = r2_score(y_val, y_val_pred)\n\ntrain_acc = tolerance_accuracy(y_train, y_train_pred)\nval_acc = tolerance_accuracy(y_val, y_val_pred)\n\nprint(\"\\n=== XGBOOST PERFORMANCE ===\")\nprint(f\"Train RMSE           : {train_rmse:.4f}\")\nprint(f\"Validation RMSE      : {val_rmse:.4f}\")\nprint(f\"Train R²             : {train_r2:.4f}\")\nprint(f\"Validation R²        : {val_r2:.4f}\")\nprint(f\"Train Accuracy (±0.5): {train_acc * 100:.2f}%\")\nprint(f\"Val Accuracy (±0.5)  : {val_acc * 100:.2f}%\")\n\n\njoblib.dump(xgb_model, MODEL_PATH)\nprint(\"\\nXGBoost model saved at:\", MODEL_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:48:51.990065Z","iopub.execute_input":"2025-12-16T10:48:51.990631Z","iopub.status.idle":"2025-12-16T10:49:20.086823Z","shell.execute_reply.started":"2025-12-16T10:48:51.990604Z","shell.execute_reply":"2025-12-16T10:49:20.086026Z"}},"outputs":[{"name":"stdout","text":"Total aligned samples: 409\nX shape: (409, 1024)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-rmse:0.74968\n[1]\tvalidation_0-rmse:0.74585\n[2]\tvalidation_0-rmse:0.74254\n[3]\tvalidation_0-rmse:0.73916\n[4]\tvalidation_0-rmse:0.73576\n[5]\tvalidation_0-rmse:0.73203\n[6]\tvalidation_0-rmse:0.72815\n[7]\tvalidation_0-rmse:0.72495\n[8]\tvalidation_0-rmse:0.72090\n[9]\tvalidation_0-rmse:0.71834\n[10]\tvalidation_0-rmse:0.71419\n[11]\tvalidation_0-rmse:0.71078\n[12]\tvalidation_0-rmse:0.70740\n[13]\tvalidation_0-rmse:0.70404\n[14]\tvalidation_0-rmse:0.70052\n[15]\tvalidation_0-rmse:0.69676\n[16]\tvalidation_0-rmse:0.69441\n[17]\tvalidation_0-rmse:0.69079\n[18]\tvalidation_0-rmse:0.68804\n[19]\tvalidation_0-rmse:0.68510\n[20]\tvalidation_0-rmse:0.68140\n[21]\tvalidation_0-rmse:0.67810\n[22]\tvalidation_0-rmse:0.67528\n[23]\tvalidation_0-rmse:0.67210\n[24]\tvalidation_0-rmse:0.66890\n[25]\tvalidation_0-rmse:0.66520\n[26]\tvalidation_0-rmse:0.66220\n[27]\tvalidation_0-rmse:0.66012\n[28]\tvalidation_0-rmse:0.65761\n[29]\tvalidation_0-rmse:0.65534\n[30]\tvalidation_0-rmse:0.65261\n[31]\tvalidation_0-rmse:0.65039\n[32]\tvalidation_0-rmse:0.64727\n[33]\tvalidation_0-rmse:0.64466\n[34]\tvalidation_0-rmse:0.64172\n[35]\tvalidation_0-rmse:0.63896\n[36]\tvalidation_0-rmse:0.63595\n[37]\tvalidation_0-rmse:0.63371\n[38]\tvalidation_0-rmse:0.63055\n[39]\tvalidation_0-rmse:0.62896\n[40]\tvalidation_0-rmse:0.62652\n[41]\tvalidation_0-rmse:0.62444\n[42]\tvalidation_0-rmse:0.62271\n[43]\tvalidation_0-rmse:0.62055\n[44]\tvalidation_0-rmse:0.61816\n[45]\tvalidation_0-rmse:0.61606\n[46]\tvalidation_0-rmse:0.61278\n[47]\tvalidation_0-rmse:0.61038\n[48]\tvalidation_0-rmse:0.60865\n[49]\tvalidation_0-rmse:0.60669\n[50]\tvalidation_0-rmse:0.60487\n[51]\tvalidation_0-rmse:0.60307\n[52]\tvalidation_0-rmse:0.60137\n[53]\tvalidation_0-rmse:0.59887\n[54]\tvalidation_0-rmse:0.59629\n[55]\tvalidation_0-rmse:0.59447\n[56]\tvalidation_0-rmse:0.59259\n[57]\tvalidation_0-rmse:0.59035\n[58]\tvalidation_0-rmse:0.58829\n[59]\tvalidation_0-rmse:0.58619\n[60]\tvalidation_0-rmse:0.58456\n[61]\tvalidation_0-rmse:0.58269\n[62]\tvalidation_0-rmse:0.58130\n[63]\tvalidation_0-rmse:0.57968\n[64]\tvalidation_0-rmse:0.57737\n[65]\tvalidation_0-rmse:0.57637\n[66]\tvalidation_0-rmse:0.57519\n[67]\tvalidation_0-rmse:0.57326\n[68]\tvalidation_0-rmse:0.57181\n[69]\tvalidation_0-rmse:0.56988\n[70]\tvalidation_0-rmse:0.56822\n[71]\tvalidation_0-rmse:0.56632\n[72]\tvalidation_0-rmse:0.56469\n[73]\tvalidation_0-rmse:0.56262\n[74]\tvalidation_0-rmse:0.56099\n[75]\tvalidation_0-rmse:0.55966\n[76]\tvalidation_0-rmse:0.55854\n[77]\tvalidation_0-rmse:0.55709\n[78]\tvalidation_0-rmse:0.55550\n[79]\tvalidation_0-rmse:0.55403\n[80]\tvalidation_0-rmse:0.55251\n[81]\tvalidation_0-rmse:0.55112\n[82]\tvalidation_0-rmse:0.54952\n[83]\tvalidation_0-rmse:0.54881\n[84]\tvalidation_0-rmse:0.54742\n[85]\tvalidation_0-rmse:0.54626\n[86]\tvalidation_0-rmse:0.54540\n[87]\tvalidation_0-rmse:0.54337\n[88]\tvalidation_0-rmse:0.54167\n[89]\tvalidation_0-rmse:0.54003\n[90]\tvalidation_0-rmse:0.53912\n[91]\tvalidation_0-rmse:0.53776\n[92]\tvalidation_0-rmse:0.53714\n[93]\tvalidation_0-rmse:0.53596\n[94]\tvalidation_0-rmse:0.53435\n[95]\tvalidation_0-rmse:0.53312\n[96]\tvalidation_0-rmse:0.53176\n[97]\tvalidation_0-rmse:0.53063\n[98]\tvalidation_0-rmse:0.52961\n[99]\tvalidation_0-rmse:0.52874\n[100]\tvalidation_0-rmse:0.52742\n[101]\tvalidation_0-rmse:0.52661\n[102]\tvalidation_0-rmse:0.52538\n[103]\tvalidation_0-rmse:0.52408\n[104]\tvalidation_0-rmse:0.52264\n[105]\tvalidation_0-rmse:0.52188\n[106]\tvalidation_0-rmse:0.52028\n[107]\tvalidation_0-rmse:0.51908\n[108]\tvalidation_0-rmse:0.51818\n[109]\tvalidation_0-rmse:0.51709\n[110]\tvalidation_0-rmse:0.51608\n[111]\tvalidation_0-rmse:0.51502\n[112]\tvalidation_0-rmse:0.51379\n[113]\tvalidation_0-rmse:0.51273\n[114]\tvalidation_0-rmse:0.51183\n[115]\tvalidation_0-rmse:0.51084\n[116]\tvalidation_0-rmse:0.51029\n[117]\tvalidation_0-rmse:0.50920\n[118]\tvalidation_0-rmse:0.50803\n[119]\tvalidation_0-rmse:0.50731\n[120]\tvalidation_0-rmse:0.50631\n[121]\tvalidation_0-rmse:0.50552\n[122]\tvalidation_0-rmse:0.50432\n[123]\tvalidation_0-rmse:0.50353\n[124]\tvalidation_0-rmse:0.50236\n[125]\tvalidation_0-rmse:0.50185\n[126]\tvalidation_0-rmse:0.50091\n[127]\tvalidation_0-rmse:0.49974\n[128]\tvalidation_0-rmse:0.49908\n[129]\tvalidation_0-rmse:0.49864\n[130]\tvalidation_0-rmse:0.49757\n[131]\tvalidation_0-rmse:0.49639\n[132]\tvalidation_0-rmse:0.49553\n[133]\tvalidation_0-rmse:0.49509\n[134]\tvalidation_0-rmse:0.49434\n[135]\tvalidation_0-rmse:0.49333\n[136]\tvalidation_0-rmse:0.49272\n[137]\tvalidation_0-rmse:0.49176\n[138]\tvalidation_0-rmse:0.49086\n[139]\tvalidation_0-rmse:0.49028\n[140]\tvalidation_0-rmse:0.48983\n[141]\tvalidation_0-rmse:0.48923\n[142]\tvalidation_0-rmse:0.48842\n[143]\tvalidation_0-rmse:0.48769\n[144]\tvalidation_0-rmse:0.48691\n[145]\tvalidation_0-rmse:0.48623\n[146]\tvalidation_0-rmse:0.48566\n[147]\tvalidation_0-rmse:0.48511\n[148]\tvalidation_0-rmse:0.48440\n[149]\tvalidation_0-rmse:0.48380\n[150]\tvalidation_0-rmse:0.48298\n[151]\tvalidation_0-rmse:0.48243\n[152]\tvalidation_0-rmse:0.48200\n[153]\tvalidation_0-rmse:0.48157\n[154]\tvalidation_0-rmse:0.48101\n[155]\tvalidation_0-rmse:0.48082\n[156]\tvalidation_0-rmse:0.48021\n[157]\tvalidation_0-rmse:0.47977\n[158]\tvalidation_0-rmse:0.47924\n[159]\tvalidation_0-rmse:0.47895\n[160]\tvalidation_0-rmse:0.47848\n[161]\tvalidation_0-rmse:0.47813\n[162]\tvalidation_0-rmse:0.47753\n[163]\tvalidation_0-rmse:0.47684\n[164]\tvalidation_0-rmse:0.47610\n[165]\tvalidation_0-rmse:0.47549\n[166]\tvalidation_0-rmse:0.47543\n[167]\tvalidation_0-rmse:0.47479\n[168]\tvalidation_0-rmse:0.47442\n[169]\tvalidation_0-rmse:0.47385\n[170]\tvalidation_0-rmse:0.47336\n[171]\tvalidation_0-rmse:0.47301\n[172]\tvalidation_0-rmse:0.47268\n[173]\tvalidation_0-rmse:0.47219\n[174]\tvalidation_0-rmse:0.47154\n[175]\tvalidation_0-rmse:0.47101\n[176]\tvalidation_0-rmse:0.47029\n[177]\tvalidation_0-rmse:0.46997\n[178]\tvalidation_0-rmse:0.46973\n[179]\tvalidation_0-rmse:0.46930\n[180]\tvalidation_0-rmse:0.46852\n[181]\tvalidation_0-rmse:0.46805\n[182]\tvalidation_0-rmse:0.46776\n[183]\tvalidation_0-rmse:0.46725\n[184]\tvalidation_0-rmse:0.46695\n[185]\tvalidation_0-rmse:0.46699\n[186]\tvalidation_0-rmse:0.46665\n[187]\tvalidation_0-rmse:0.46639\n[188]\tvalidation_0-rmse:0.46616\n[189]\tvalidation_0-rmse:0.46564\n[190]\tvalidation_0-rmse:0.46518\n[191]\tvalidation_0-rmse:0.46474\n[192]\tvalidation_0-rmse:0.46464\n[193]\tvalidation_0-rmse:0.46432\n[194]\tvalidation_0-rmse:0.46403\n[195]\tvalidation_0-rmse:0.46378\n[196]\tvalidation_0-rmse:0.46335\n[197]\tvalidation_0-rmse:0.46285\n[198]\tvalidation_0-rmse:0.46261\n[199]\tvalidation_0-rmse:0.46212\n[200]\tvalidation_0-rmse:0.46192\n[201]\tvalidation_0-rmse:0.46157\n[202]\tvalidation_0-rmse:0.46133\n[203]\tvalidation_0-rmse:0.46104\n[204]\tvalidation_0-rmse:0.46055\n[205]\tvalidation_0-rmse:0.46026\n[206]\tvalidation_0-rmse:0.45990\n[207]\tvalidation_0-rmse:0.45982\n[208]\tvalidation_0-rmse:0.45948\n[209]\tvalidation_0-rmse:0.45923\n[210]\tvalidation_0-rmse:0.45909\n[211]\tvalidation_0-rmse:0.45875\n[212]\tvalidation_0-rmse:0.45861\n[213]\tvalidation_0-rmse:0.45849\n[214]\tvalidation_0-rmse:0.45815\n[215]\tvalidation_0-rmse:0.45803\n[216]\tvalidation_0-rmse:0.45767\n[217]\tvalidation_0-rmse:0.45743\n[218]\tvalidation_0-rmse:0.45736\n[219]\tvalidation_0-rmse:0.45718\n[220]\tvalidation_0-rmse:0.45684\n[221]\tvalidation_0-rmse:0.45642\n[222]\tvalidation_0-rmse:0.45621\n[223]\tvalidation_0-rmse:0.45601\n[224]\tvalidation_0-rmse:0.45608\n[225]\tvalidation_0-rmse:0.45587\n[226]\tvalidation_0-rmse:0.45559\n[227]\tvalidation_0-rmse:0.45533\n[228]\tvalidation_0-rmse:0.45523\n[229]\tvalidation_0-rmse:0.45493\n[230]\tvalidation_0-rmse:0.45492\n[231]\tvalidation_0-rmse:0.45466\n[232]\tvalidation_0-rmse:0.45444\n[233]\tvalidation_0-rmse:0.45429\n[234]\tvalidation_0-rmse:0.45412\n[235]\tvalidation_0-rmse:0.45406\n[236]\tvalidation_0-rmse:0.45381\n[237]\tvalidation_0-rmse:0.45378\n[238]\tvalidation_0-rmse:0.45357\n[239]\tvalidation_0-rmse:0.45341\n[240]\tvalidation_0-rmse:0.45322\n[241]\tvalidation_0-rmse:0.45308\n[242]\tvalidation_0-rmse:0.45298\n[243]\tvalidation_0-rmse:0.45270\n[244]\tvalidation_0-rmse:0.45269\n[245]\tvalidation_0-rmse:0.45243\n[246]\tvalidation_0-rmse:0.45199\n[247]\tvalidation_0-rmse:0.45194\n[248]\tvalidation_0-rmse:0.45171\n[249]\tvalidation_0-rmse:0.45148\n[250]\tvalidation_0-rmse:0.45143\n[251]\tvalidation_0-rmse:0.45128\n[252]\tvalidation_0-rmse:0.45117\n[253]\tvalidation_0-rmse:0.45098\n[254]\tvalidation_0-rmse:0.45091\n[255]\tvalidation_0-rmse:0.45083\n[256]\tvalidation_0-rmse:0.45065\n[257]\tvalidation_0-rmse:0.45058\n[258]\tvalidation_0-rmse:0.45048\n[259]\tvalidation_0-rmse:0.45042\n[260]\tvalidation_0-rmse:0.45024\n[261]\tvalidation_0-rmse:0.45001\n[262]\tvalidation_0-rmse:0.44990\n[263]\tvalidation_0-rmse:0.44987\n[264]\tvalidation_0-rmse:0.44968\n[265]\tvalidation_0-rmse:0.44948\n[266]\tvalidation_0-rmse:0.44935\n[267]\tvalidation_0-rmse:0.44910\n[268]\tvalidation_0-rmse:0.44912\n[269]\tvalidation_0-rmse:0.44877\n[270]\tvalidation_0-rmse:0.44884\n[271]\tvalidation_0-rmse:0.44870\n[272]\tvalidation_0-rmse:0.44849\n[273]\tvalidation_0-rmse:0.44834\n[274]\tvalidation_0-rmse:0.44824\n[275]\tvalidation_0-rmse:0.44815\n[276]\tvalidation_0-rmse:0.44803\n[277]\tvalidation_0-rmse:0.44794\n[278]\tvalidation_0-rmse:0.44791\n[279]\tvalidation_0-rmse:0.44769\n[280]\tvalidation_0-rmse:0.44757\n[281]\tvalidation_0-rmse:0.44756\n[282]\tvalidation_0-rmse:0.44742\n[283]\tvalidation_0-rmse:0.44733\n[284]\tvalidation_0-rmse:0.44708\n[285]\tvalidation_0-rmse:0.44692\n[286]\tvalidation_0-rmse:0.44689\n[287]\tvalidation_0-rmse:0.44662\n[288]\tvalidation_0-rmse:0.44634\n[289]\tvalidation_0-rmse:0.44618\n[290]\tvalidation_0-rmse:0.44600\n[291]\tvalidation_0-rmse:0.44608\n[292]\tvalidation_0-rmse:0.44598\n[293]\tvalidation_0-rmse:0.44592\n[294]\tvalidation_0-rmse:0.44580\n[295]\tvalidation_0-rmse:0.44570\n[296]\tvalidation_0-rmse:0.44550\n[297]\tvalidation_0-rmse:0.44531\n[298]\tvalidation_0-rmse:0.44519\n[299]\tvalidation_0-rmse:0.44508\n[300]\tvalidation_0-rmse:0.44496\n[301]\tvalidation_0-rmse:0.44499\n[302]\tvalidation_0-rmse:0.44484\n[303]\tvalidation_0-rmse:0.44467\n[304]\tvalidation_0-rmse:0.44460\n[305]\tvalidation_0-rmse:0.44446\n[306]\tvalidation_0-rmse:0.44439\n[307]\tvalidation_0-rmse:0.44430\n[308]\tvalidation_0-rmse:0.44430\n[309]\tvalidation_0-rmse:0.44419\n[310]\tvalidation_0-rmse:0.44415\n[311]\tvalidation_0-rmse:0.44405\n[312]\tvalidation_0-rmse:0.44408\n[313]\tvalidation_0-rmse:0.44415\n[314]\tvalidation_0-rmse:0.44400\n[315]\tvalidation_0-rmse:0.44392\n[316]\tvalidation_0-rmse:0.44377\n[317]\tvalidation_0-rmse:0.44368\n[318]\tvalidation_0-rmse:0.44357\n[319]\tvalidation_0-rmse:0.44345\n[320]\tvalidation_0-rmse:0.44335\n[321]\tvalidation_0-rmse:0.44334\n[322]\tvalidation_0-rmse:0.44326\n[323]\tvalidation_0-rmse:0.44322\n[324]\tvalidation_0-rmse:0.44305\n[325]\tvalidation_0-rmse:0.44291\n[326]\tvalidation_0-rmse:0.44289\n[327]\tvalidation_0-rmse:0.44275\n[328]\tvalidation_0-rmse:0.44266\n[329]\tvalidation_0-rmse:0.44267\n[330]\tvalidation_0-rmse:0.44258\n[331]\tvalidation_0-rmse:0.44251\n[332]\tvalidation_0-rmse:0.44239\n[333]\tvalidation_0-rmse:0.44224\n[334]\tvalidation_0-rmse:0.44215\n[335]\tvalidation_0-rmse:0.44207\n[336]\tvalidation_0-rmse:0.44208\n[337]\tvalidation_0-rmse:0.44195\n[338]\tvalidation_0-rmse:0.44196\n[339]\tvalidation_0-rmse:0.44197\n[340]\tvalidation_0-rmse:0.44190\n[341]\tvalidation_0-rmse:0.44186\n[342]\tvalidation_0-rmse:0.44181\n[343]\tvalidation_0-rmse:0.44189\n[344]\tvalidation_0-rmse:0.44188\n[345]\tvalidation_0-rmse:0.44182\n[346]\tvalidation_0-rmse:0.44184\n[347]\tvalidation_0-rmse:0.44178\n[348]\tvalidation_0-rmse:0.44171\n[349]\tvalidation_0-rmse:0.44175\n[350]\tvalidation_0-rmse:0.44172\n[351]\tvalidation_0-rmse:0.44165\n[352]\tvalidation_0-rmse:0.44164\n[353]\tvalidation_0-rmse:0.44162\n[354]\tvalidation_0-rmse:0.44167\n[355]\tvalidation_0-rmse:0.44169\n[356]\tvalidation_0-rmse:0.44166\n[357]\tvalidation_0-rmse:0.44166\n[358]\tvalidation_0-rmse:0.44147\n[359]\tvalidation_0-rmse:0.44151\n[360]\tvalidation_0-rmse:0.44144\n[361]\tvalidation_0-rmse:0.44145\n[362]\tvalidation_0-rmse:0.44145\n[363]\tvalidation_0-rmse:0.44144\n[364]\tvalidation_0-rmse:0.44135\n[365]\tvalidation_0-rmse:0.44131\n[366]\tvalidation_0-rmse:0.44125\n[367]\tvalidation_0-rmse:0.44123\n[368]\tvalidation_0-rmse:0.44110\n[369]\tvalidation_0-rmse:0.44110\n[370]\tvalidation_0-rmse:0.44102\n[371]\tvalidation_0-rmse:0.44088\n[372]\tvalidation_0-rmse:0.44076\n[373]\tvalidation_0-rmse:0.44076\n[374]\tvalidation_0-rmse:0.44077\n[375]\tvalidation_0-rmse:0.44076\n[376]\tvalidation_0-rmse:0.44081\n[377]\tvalidation_0-rmse:0.44082\n[378]\tvalidation_0-rmse:0.44084\n[379]\tvalidation_0-rmse:0.44079\n[380]\tvalidation_0-rmse:0.44067\n[381]\tvalidation_0-rmse:0.44067\n[382]\tvalidation_0-rmse:0.44068\n[383]\tvalidation_0-rmse:0.44055\n[384]\tvalidation_0-rmse:0.44054\n[385]\tvalidation_0-rmse:0.44044\n[386]\tvalidation_0-rmse:0.44026\n[387]\tvalidation_0-rmse:0.44026\n[388]\tvalidation_0-rmse:0.44017\n[389]\tvalidation_0-rmse:0.44011\n[390]\tvalidation_0-rmse:0.44011\n[391]\tvalidation_0-rmse:0.44019\n[392]\tvalidation_0-rmse:0.44018\n[393]\tvalidation_0-rmse:0.44018\n[394]\tvalidation_0-rmse:0.44012\n[395]\tvalidation_0-rmse:0.44015\n[396]\tvalidation_0-rmse:0.44018\n[397]\tvalidation_0-rmse:0.44017\n[398]\tvalidation_0-rmse:0.44017\n[399]\tvalidation_0-rmse:0.44019\n[400]\tvalidation_0-rmse:0.44019\n[401]\tvalidation_0-rmse:0.44013\n[402]\tvalidation_0-rmse:0.44013\n[403]\tvalidation_0-rmse:0.44006\n[404]\tvalidation_0-rmse:0.44006\n[405]\tvalidation_0-rmse:0.44006\n[406]\tvalidation_0-rmse:0.44006\n[407]\tvalidation_0-rmse:0.44006\n[408]\tvalidation_0-rmse:0.44007\n[409]\tvalidation_0-rmse:0.44007\n[410]\tvalidation_0-rmse:0.44007\n[411]\tvalidation_0-rmse:0.44008\n[412]\tvalidation_0-rmse:0.43995\n[413]\tvalidation_0-rmse:0.43990\n[414]\tvalidation_0-rmse:0.43990\n[415]\tvalidation_0-rmse:0.43989\n[416]\tvalidation_0-rmse:0.43992\n[417]\tvalidation_0-rmse:0.43993\n[418]\tvalidation_0-rmse:0.43992\n[419]\tvalidation_0-rmse:0.43992\n[420]\tvalidation_0-rmse:0.43993\n[421]\tvalidation_0-rmse:0.43993\n[422]\tvalidation_0-rmse:0.43984\n[423]\tvalidation_0-rmse:0.43980\n[424]\tvalidation_0-rmse:0.43977\n[425]\tvalidation_0-rmse:0.43977\n[426]\tvalidation_0-rmse:0.43968\n[427]\tvalidation_0-rmse:0.43971\n[428]\tvalidation_0-rmse:0.43971\n[429]\tvalidation_0-rmse:0.43971\n[430]\tvalidation_0-rmse:0.43966\n[431]\tvalidation_0-rmse:0.43966\n[432]\tvalidation_0-rmse:0.43966\n[433]\tvalidation_0-rmse:0.43966\n[434]\tvalidation_0-rmse:0.43956\n[435]\tvalidation_0-rmse:0.43947\n[436]\tvalidation_0-rmse:0.43947\n[437]\tvalidation_0-rmse:0.43949\n[438]\tvalidation_0-rmse:0.43949\n[439]\tvalidation_0-rmse:0.43958\n[440]\tvalidation_0-rmse:0.43946\n[441]\tvalidation_0-rmse:0.43946\n[442]\tvalidation_0-rmse:0.43940\n[443]\tvalidation_0-rmse:0.43940\n[444]\tvalidation_0-rmse:0.43940\n[445]\tvalidation_0-rmse:0.43940\n[446]\tvalidation_0-rmse:0.43933\n[447]\tvalidation_0-rmse:0.43933\n[448]\tvalidation_0-rmse:0.43932\n[449]\tvalidation_0-rmse:0.43927\n[450]\tvalidation_0-rmse:0.43927\n[451]\tvalidation_0-rmse:0.43927\n[452]\tvalidation_0-rmse:0.43928\n[453]\tvalidation_0-rmse:0.43927\n[454]\tvalidation_0-rmse:0.43927\n[455]\tvalidation_0-rmse:0.43927\n[456]\tvalidation_0-rmse:0.43926\n[457]\tvalidation_0-rmse:0.43926\n[458]\tvalidation_0-rmse:0.43926\n[459]\tvalidation_0-rmse:0.43913\n[460]\tvalidation_0-rmse:0.43913\n[461]\tvalidation_0-rmse:0.43910\n[462]\tvalidation_0-rmse:0.43910\n[463]\tvalidation_0-rmse:0.43910\n[464]\tvalidation_0-rmse:0.43910\n[465]\tvalidation_0-rmse:0.43908\n[466]\tvalidation_0-rmse:0.43906\n[467]\tvalidation_0-rmse:0.43906\n[468]\tvalidation_0-rmse:0.43906\n[469]\tvalidation_0-rmse:0.43911\n[470]\tvalidation_0-rmse:0.43911\n[471]\tvalidation_0-rmse:0.43911\n[472]\tvalidation_0-rmse:0.43911\n[473]\tvalidation_0-rmse:0.43905\n[474]\tvalidation_0-rmse:0.43907\n[475]\tvalidation_0-rmse:0.43907\n[476]\tvalidation_0-rmse:0.43905\n[477]\tvalidation_0-rmse:0.43906\n[478]\tvalidation_0-rmse:0.43906\n[479]\tvalidation_0-rmse:0.43906\n[480]\tvalidation_0-rmse:0.43906\n[481]\tvalidation_0-rmse:0.43905\n[482]\tvalidation_0-rmse:0.43906\n[483]\tvalidation_0-rmse:0.43906\n[484]\tvalidation_0-rmse:0.43906\n[485]\tvalidation_0-rmse:0.43906\n[486]\tvalidation_0-rmse:0.43906\n[487]\tvalidation_0-rmse:0.43906\n[488]\tvalidation_0-rmse:0.43906\n[489]\tvalidation_0-rmse:0.43906\n[490]\tvalidation_0-rmse:0.43905\n[491]\tvalidation_0-rmse:0.43905\n[492]\tvalidation_0-rmse:0.43904\n[493]\tvalidation_0-rmse:0.43904\n[494]\tvalidation_0-rmse:0.43904\n[495]\tvalidation_0-rmse:0.43904\n[496]\tvalidation_0-rmse:0.43904\n[497]\tvalidation_0-rmse:0.43904\n[498]\tvalidation_0-rmse:0.43904\n[499]\tvalidation_0-rmse:0.43906\n[500]\tvalidation_0-rmse:0.43906\n[501]\tvalidation_0-rmse:0.43905\n[502]\tvalidation_0-rmse:0.43905\n[503]\tvalidation_0-rmse:0.43905\n[504]\tvalidation_0-rmse:0.43905\n[505]\tvalidation_0-rmse:0.43905\n[506]\tvalidation_0-rmse:0.43905\n[507]\tvalidation_0-rmse:0.43905\n[508]\tvalidation_0-rmse:0.43905\n[509]\tvalidation_0-rmse:0.43896\n[510]\tvalidation_0-rmse:0.43897\n[511]\tvalidation_0-rmse:0.43897\n[512]\tvalidation_0-rmse:0.43897\n[513]\tvalidation_0-rmse:0.43897\n[514]\tvalidation_0-rmse:0.43897\n[515]\tvalidation_0-rmse:0.43897\n[516]\tvalidation_0-rmse:0.43897\n[517]\tvalidation_0-rmse:0.43892\n[518]\tvalidation_0-rmse:0.43884\n[519]\tvalidation_0-rmse:0.43884\n[520]\tvalidation_0-rmse:0.43884\n[521]\tvalidation_0-rmse:0.43884\n[522]\tvalidation_0-rmse:0.43884\n[523]\tvalidation_0-rmse:0.43883\n[524]\tvalidation_0-rmse:0.43883\n[525]\tvalidation_0-rmse:0.43883\n[526]\tvalidation_0-rmse:0.43883\n[527]\tvalidation_0-rmse:0.43883\n[528]\tvalidation_0-rmse:0.43883\n[529]\tvalidation_0-rmse:0.43883\n[530]\tvalidation_0-rmse:0.43883\n[531]\tvalidation_0-rmse:0.43884\n[532]\tvalidation_0-rmse:0.43884\n[533]\tvalidation_0-rmse:0.43884\n[534]\tvalidation_0-rmse:0.43884\n[535]\tvalidation_0-rmse:0.43884\n[536]\tvalidation_0-rmse:0.43884\n[537]\tvalidation_0-rmse:0.43883\n[538]\tvalidation_0-rmse:0.43885\n[539]\tvalidation_0-rmse:0.43885\n[540]\tvalidation_0-rmse:0.43885\n[541]\tvalidation_0-rmse:0.43885\n[542]\tvalidation_0-rmse:0.43885\n[543]\tvalidation_0-rmse:0.43885\n[544]\tvalidation_0-rmse:0.43885\n[545]\tvalidation_0-rmse:0.43885\n[546]\tvalidation_0-rmse:0.43885\n[547]\tvalidation_0-rmse:0.43885\n[548]\tvalidation_0-rmse:0.43885\n[549]\tvalidation_0-rmse:0.43885\n[550]\tvalidation_0-rmse:0.43885\n[551]\tvalidation_0-rmse:0.43885\n[552]\tvalidation_0-rmse:0.43885\n[553]\tvalidation_0-rmse:0.43885\n[554]\tvalidation_0-rmse:0.43885\n[555]\tvalidation_0-rmse:0.43888\n[556]\tvalidation_0-rmse:0.43888\n[557]\tvalidation_0-rmse:0.43888\n[558]\tvalidation_0-rmse:0.43888\n[559]\tvalidation_0-rmse:0.43888\n[560]\tvalidation_0-rmse:0.43888\n[561]\tvalidation_0-rmse:0.43888\n[562]\tvalidation_0-rmse:0.43888\n[563]\tvalidation_0-rmse:0.43889\n[564]\tvalidation_0-rmse:0.43889\n[565]\tvalidation_0-rmse:0.43888\n[566]\tvalidation_0-rmse:0.43889\n[567]\tvalidation_0-rmse:0.43885\n[568]\tvalidation_0-rmse:0.43885\n[569]\tvalidation_0-rmse:0.43885\n[570]\tvalidation_0-rmse:0.43885\n[571]\tvalidation_0-rmse:0.43885\n[572]\tvalidation_0-rmse:0.43885\n[573]\tvalidation_0-rmse:0.43885\n[574]\tvalidation_0-rmse:0.43885\n[575]\tvalidation_0-rmse:0.43886\n[576]\tvalidation_0-rmse:0.43886\n\n=== XGBOOST PERFORMANCE ===\nTrain RMSE           : 0.1208\nValidation RMSE      : 0.4388\nTrain R²             : 0.9754\nValidation R²        : 0.6595\nTrain Accuracy (±0.5): 99.69%\nVal Accuracy (±0.5)  : 69.51%\n\nXGBoost model saved at: /kaggle/working/xgb_deberta_grammar_model.pkl\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\nfrom tqdm import tqdm\n\n\nINPUT_CSV = \"/kaggle/working/audio_train_transcripts.csv\"\n\nOUT_MPNet = \"/kaggle/working/audio_sbert_mpnet_embeddings.csv\"\nOUT_MiniLM = \"/kaggle/working/audio_sbert_minilm_embeddings.csv\"\nOUT_FUSED = \"/kaggle/working/audio_sbert_fused_embeddings.csv\"\n\nBATCH_SIZE = 32\n\n\ndf = pd.read_csv(INPUT_CSV)\ndf[\"transcript\"] = df[\"transcript\"].fillna(\"\")\n\nsentences = df[\"transcript\"].tolist()\nfilenames = df[\"filename\"].tolist()\n\nprint(\"Total transcripts:\", len(sentences))\n\nprint(\"Loading MPNet model...\")\nmpnet_model = SentenceTransformer(\n    \"sentence-transformers/all-mpnet-base-v2\"\n)\n\nprint(\"Loading MiniLM model...\")\nminilm_model = SentenceTransformer(\n    \"sentence-transformers/all-MiniLM-L6-v2\"\n)\n\n\nprint(\"Extracting MPNet embeddings...\")\nmpnet_embeddings = mpnet_model.encode(\n    sentences,\n    batch_size=BATCH_SIZE,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True\n)\n\nprint(\"Extracting MiniLM embeddings...\")\nminilm_embeddings = minilm_model.encode(\n    sentences,\n    batch_size=BATCH_SIZE,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True\n)\n\nprint(\"MPNet shape :\", mpnet_embeddings.shape)   # (N, 768)\nprint(\"MiniLM shape:\", minilm_embeddings.shape)  # (N, 384)\n\n\nmpnet_df = pd.DataFrame(\n    mpnet_embeddings,\n    columns=[f\"mpnet_{i}\" for i in range(mpnet_embeddings.shape[1])]\n)\n\nmpnet_out = pd.concat(\n    [pd.Series(filenames, name=\"filename\"), mpnet_df],\n    axis=1\n)\n\nmpnet_out.to_csv(OUT_MPNet, index=False)\nprint(\"Saved MPNet embeddings →\", OUT_MPNet)\n\n\nminilm_df = pd.DataFrame(\n    minilm_embeddings,\n    columns=[f\"minilm_{i}\" for i in range(minilm_embeddings.shape[1])]\n)\n\nminilm_out = pd.concat(\n    [pd.Series(filenames, name=\"filename\"), minilm_df],\n    axis=1\n)\n\nminilm_out.to_csv(OUT_MiniLM, index=False)\nprint(\"Saved MiniLM embeddings →\", OUT_MiniLM)\n\nfused_embeddings = np.concatenate(\n    [mpnet_embeddings, minilm_embeddings],\n    axis=1\n)\n\nfused_df = pd.DataFrame(\n    fused_embeddings,\n    columns=[f\"fused_{i}\" for i in range(fused_embeddings.shape[1])]\n)\n\nfused_out = pd.concat(\n    [pd.Series(filenames, name=\"filename\"), fused_df],\n    axis=1\n)\n\nfused_out.to_csv(OUT_FUSED, index=False)\nprint(\"Saved FUSED embeddings →\", OUT_FUSED)\n\nprint(\"\\nFinal fused embedding dimension:\", fused_embeddings.shape[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:23:07.198757Z","iopub.execute_input":"2025-12-16T08:23:07.199395Z","iopub.status.idle":"2025-12-16T08:23:22.220018Z","shell.execute_reply.started":"2025-12-16T08:23:07.199372Z","shell.execute_reply":"2025-12-16T08:23:22.219205Z"}},"outputs":[{"name":"stdout","text":"Total transcripts: 409\nLoading MPNet model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"751c4804d1b04377b7619cb4b0bfc1ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57a14a73e5a94a0db794ef73a7d3d7ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87453adc78b7409f9e374e38b501b3d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f54fcdfbaae347a39ddfa74e3dbd1861"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de6d02099b454442881f309f1f5ba957"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cecdf98833444a9b62c7ea457168ef2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79f7088b4864412496db43c99b142780"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a5ec24ee544b3286016c76e543ba19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3ac615b382d4ed6a72b720b6e0afebd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6f0134036af454080aac40145d38378"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2192b0aee802471a97fb6807293b3673"}},"metadata":{}},{"name":"stdout","text":"Loading MiniLM model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67ff57635add40a788f93664436442d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccd3759029f447079febb3fed688305f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c940d5ff05341ef8fbe3c530631ebf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05cc69963d724e38a2ae262475159bcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e37d4ea1d344ec59b1022168a6cd001"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a0bf95af9544ef5b0472d5d90a359d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b84e19eee994c9a8520616df31f41db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9ff8186dedf482da3051813c94a37cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"130baea0f5e644ff9d6f42418727ebc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fedfeb8a9cca41bc88319cc51aa5de33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211022b33ff6411ebe793d3643ca621f"}},"metadata":{}},{"name":"stdout","text":"Extracting MPNet embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4a5068af1c745b7a79b8b9d14ab1825"}},"metadata":{}},{"name":"stdout","text":"Extracting MiniLM embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bc363711cff44da9d8ef98e439103d9"}},"metadata":{}},{"name":"stdout","text":"MPNet shape : (409, 768)\nMiniLM shape: (409, 384)\nSaved MPNet embeddings → /kaggle/working/audio_sbert_mpnet_embeddings.csv\nSaved MiniLM embeddings → /kaggle/working/audio_sbert_minilm_embeddings.csv\nSaved FUSED embeddings → /kaggle/working/audio_sbert_fused_embeddings.csv\n\nFinal fused embedding dimension: 1152\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\n\ndef load_and_align_data(\n    whisper_path,\n    mpnet_path,\n    label_path\n):\n    whisper_df = pd.read_csv(whisper_path)\n    mpnet_df   = pd.read_csv(mpnet_path)\n    label_df  = pd.read_csv(label_path)\n\n    whisper_df.rename(columns={whisper_df.columns[0]: \"filename\"}, inplace=True)\n    mpnet_df.rename(columns={mpnet_df.columns[0]: \"filename\"}, inplace=True)\n    label_df.rename(columns={label_df.columns[0]: \"filename\"}, inplace=True)\n\n    whisper_df[\"filename\"] = whisper_df[\"filename\"].str.replace(\".wav\", \"\", regex=False)\n\n    df = (\n        whisper_df\n        .merge(mpnet_df, on=\"filename\", how=\"inner\")\n        .merge(label_df, on=\"filename\", how=\"inner\")\n    )\n\n    return df\n\n\ndef build_whisper_branch(input_dim):\n    inp = tf.keras.layers.Input(shape=(input_dim,), name=\"whisper_input\")\n\n    x = tf.keras.layers.Dense(256, activation=\"relu\")(inp)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n\n    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n\n    return inp, x\n\n\ndef build_mpnet_branch(input_dim):\n    inp = tf.keras.layers.Input(shape=(input_dim,), name=\"mpnet_input\")\n\n    x = tf.keras.layers.Dense(256, activation=\"relu\")(inp)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n\n    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n\n    return inp, x\n\n\ndef build_fusion_model(whisper_dim, mpnet_dim):\n    w_inp, w_feat = build_whisper_branch(whisper_dim)\n    m_inp, m_feat = build_mpnet_branch(mpnet_dim)\n\n    fused = tf.keras.layers.Concatenate()([w_feat, m_feat])\n\n    fused = tf.keras.layers.Dense(128, activation=\"relu\")(fused)\n    fused = tf.keras.layers.BatchNormalization()(fused)\n    fused = tf.keras.layers.Dropout(0.3)(fused)\n\n    fused = tf.keras.layers.Dense(64, activation=\"relu\")(fused)\n\n    output = tf.keras.layers.Dense(1)(fused)\n\n    model = tf.keras.Model(\n        inputs=[w_inp, m_inp],\n        outputs=output\n    )\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-3),\n        loss=\"mse\",\n        metrics=[\"mae\"]\n    )\n\n    return model\n\n\nWHISPER_EMB = \"/kaggle/working/audio_whisper_train_embeddings.csv\"\nMPNET_EMB   = \"/kaggle/working/deberta_large_embeddings.csv\"\nLABELS     = \"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/csvs/train.csv\"\n\ndf = load_and_align_data(WHISPER_EMB, MPNET_EMB, LABELS)\nprint(\"Total aligned samples:\", len(df))\n\nX_whisper = df.iloc[:, 1:513].values.astype(np.float32)   # 512-d\nX_mpnet   = df.iloc[:, 513:-1].values.astype(np.float32) # 768-d\ny         = df.iloc[:, -1].values.astype(np.float32)\n\nXw_tr, Xw_te, Xm_tr, Xm_te, y_tr, y_te = train_test_split(\n    X_whisper, X_mpnet, y,\n    test_size=0.2,\n    random_state=42\n)\n\nmodel = build_fusion_model(\n    whisper_dim=Xw_tr.shape[1],\n    mpnet_dim=Xm_tr.shape[1]\n)\n\nmodel.summary()\n\n\nhistory = model.fit(\n    {\"whisper_input\": Xw_tr, \"mpnet_input\": Xm_tr},\n    y_tr,\n    validation_data=(\n        {\"whisper_input\": Xw_te, \"mpnet_input\": Xm_te},\n        y_te\n    ),\n    epochs=300,\n    batch_size=24,\n    verbose=1\n)\n\n\ndef evaluate_regression(model, Xw, Xm, y_true, split=\"\"):\n    y_pred = model.predict(\n        {\"whisper_input\": Xw, \"mpnet_input\": Xm}\n    ).squeeze()\n\n    y_pred = np.clip(y_pred, 0.0, 5.0)\n\n    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n    mae  = np.mean(np.abs(y_true - y_pred))\n    r2   = r2_score(y_true, y_pred)\n\n    print(f\"\\n=== {split} METRICS ===\")\n    print(f\"RMSE: {rmse:.4f}\")\n    print(f\"MAE : {mae:.4f}\")\n    print(f\"R²  : {r2:.4f}\")\n\n    return y_pred\n\n\n_ = evaluate_regression(model, Xw_tr, Xm_tr, y_tr, \"TRAIN\")\n_ = evaluate_regression(model, Xw_te, Xm_te, y_te, \"TEST\")\n\n\nMODEL_PATH = \"/kaggle/working/whisper_mpnet_fusion_model.keras\"\nmodel.save(MODEL_PATH)\n\nprint(\"\\nModel saved at:\", MODEL_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:32:29.516674Z","iopub.execute_input":"2025-12-16T08:32:29.517661Z","iopub.status.idle":"2025-12-16T08:33:17.185002Z","shell.execute_reply.started":"2025-12-16T08:32:29.517632Z","shell.execute_reply":"2025-12-16T08:33:17.184313Z"}},"outputs":[{"name":"stdout","text":"Total aligned samples: 409\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_52\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_52\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ whisper_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ mpnet_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_80 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ whisper_input[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_82 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m196,864\u001b[0m │ mpnet_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_81 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_83 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_84 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_85 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_86 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ whisper_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ mpnet_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ whisper_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ mpnet_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m437,761\u001b[0m (1.67 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">437,761</span> (1.67 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m436,481\u001b[0m (1.67 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">436,481</span> (1.67 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 231ms/step - loss: 4.9239 - mae: 1.9272 - val_loss: 8.2273 - val_mae: 2.7658\nEpoch 2/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7016 - mae: 1.0627 - val_loss: 6.6659 - val_mae: 2.4670\nEpoch 3/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0863 - mae: 0.7878 - val_loss: 4.9313 - val_mae: 2.0738\nEpoch 4/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8968 - mae: 0.7304 - val_loss: 5.5142 - val_mae: 2.2153\nEpoch 5/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7518 - mae: 0.6791 - val_loss: 4.4876 - val_mae: 1.9706\nEpoch 6/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5926 - mae: 0.6067 - val_loss: 3.6441 - val_mae: 1.7473\nEpoch 7/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6538 - mae: 0.6478 - val_loss: 3.1169 - val_mae: 1.5880\nEpoch 8/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5520 - mae: 0.6026 - val_loss: 2.5046 - val_mae: 1.3888\nEpoch 9/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5331 - mae: 0.5641 - val_loss: 1.9600 - val_mae: 1.1921\nEpoch 10/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5519 - mae: 0.5590 - val_loss: 1.7381 - val_mae: 1.0934\nEpoch 11/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4636 - mae: 0.5350 - val_loss: 1.3849 - val_mae: 0.9260\nEpoch 12/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4481 - mae: 0.5291 - val_loss: 1.1088 - val_mae: 0.8054\nEpoch 13/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3771 - mae: 0.4822 - val_loss: 0.9623 - val_mae: 0.7448\nEpoch 14/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4416 - mae: 0.5148 - val_loss: 0.8354 - val_mae: 0.6972\nEpoch 15/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3838 - mae: 0.4961 - val_loss: 0.7827 - val_mae: 0.6729\nEpoch 16/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4729 - mae: 0.5377 - val_loss: 0.6581 - val_mae: 0.6118\nEpoch 17/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4405 - mae: 0.5272 - val_loss: 0.7314 - val_mae: 0.6572\nEpoch 18/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3842 - mae: 0.4901 - val_loss: 0.6940 - val_mae: 0.6398\nEpoch 19/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4786 - mae: 0.5523 - val_loss: 0.5556 - val_mae: 0.5612\nEpoch 20/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3821 - mae: 0.4873 - val_loss: 0.5579 - val_mae: 0.5703\nEpoch 21/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3825 - mae: 0.4909 - val_loss: 0.6129 - val_mae: 0.6001\nEpoch 22/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3222 - mae: 0.4500 - val_loss: 0.5737 - val_mae: 0.5797\nEpoch 23/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2928 - mae: 0.4399 - val_loss: 0.5366 - val_mae: 0.5634\nEpoch 24/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3406 - mae: 0.4568 - val_loss: 0.5282 - val_mae: 0.5645\nEpoch 25/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3366 - mae: 0.4642 - val_loss: 0.4622 - val_mae: 0.5420\nEpoch 26/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2490 - mae: 0.3880 - val_loss: 0.4954 - val_mae: 0.5547\nEpoch 27/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3128 - mae: 0.4361 - val_loss: 0.4802 - val_mae: 0.5394\nEpoch 28/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3072 - mae: 0.4426 - val_loss: 0.4812 - val_mae: 0.5463\nEpoch 29/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2680 - mae: 0.4201 - val_loss: 0.4239 - val_mae: 0.5186\nEpoch 30/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2837 - mae: 0.4194 - val_loss: 0.4287 - val_mae: 0.5204\nEpoch 31/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3143 - mae: 0.4307 - val_loss: 0.4240 - val_mae: 0.5103\nEpoch 32/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2975 - mae: 0.4260 - val_loss: 0.5001 - val_mae: 0.5657\nEpoch 33/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2945 - mae: 0.4188 - val_loss: 0.5194 - val_mae: 0.5749\nEpoch 34/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3133 - mae: 0.4350 - val_loss: 0.4077 - val_mae: 0.5210\nEpoch 35/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2660 - mae: 0.4113 - val_loss: 0.4371 - val_mae: 0.5404\nEpoch 36/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2209 - mae: 0.3719 - val_loss: 0.4278 - val_mae: 0.5356\nEpoch 37/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3097 - mae: 0.4342 - val_loss: 0.4250 - val_mae: 0.5409\nEpoch 38/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2251 - mae: 0.3785 - val_loss: 0.4041 - val_mae: 0.5258\nEpoch 39/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2663 - mae: 0.3939 - val_loss: 0.4114 - val_mae: 0.5188\nEpoch 40/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2498 - mae: 0.3780 - val_loss: 0.4767 - val_mae: 0.5616\nEpoch 41/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2921 - mae: 0.4169 - val_loss: 0.4273 - val_mae: 0.5353\nEpoch 42/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1959 - mae: 0.3621 - val_loss: 0.3820 - val_mae: 0.4965\nEpoch 43/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2295 - mae: 0.3758 - val_loss: 0.3406 - val_mae: 0.4681\nEpoch 44/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2176 - mae: 0.3763 - val_loss: 0.3503 - val_mae: 0.4747\nEpoch 45/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2360 - mae: 0.3737 - val_loss: 0.4418 - val_mae: 0.5455\nEpoch 46/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2617 - mae: 0.4176 - val_loss: 0.4361 - val_mae: 0.5497\nEpoch 47/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2088 - mae: 0.3591 - val_loss: 0.3578 - val_mae: 0.4832\nEpoch 48/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2036 - mae: 0.3563 - val_loss: 0.3850 - val_mae: 0.5167\nEpoch 49/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2365 - mae: 0.3779 - val_loss: 0.3281 - val_mae: 0.4612\nEpoch 50/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2343 - mae: 0.3803 - val_loss: 0.3619 - val_mae: 0.4897\nEpoch 51/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1964 - mae: 0.3462 - val_loss: 0.3953 - val_mae: 0.5221\nEpoch 52/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1868 - mae: 0.3503 - val_loss: 0.3381 - val_mae: 0.4752\nEpoch 53/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2402 - mae: 0.3963 - val_loss: 0.3585 - val_mae: 0.5007\nEpoch 54/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1921 - mae: 0.3529 - val_loss: 0.3197 - val_mae: 0.4728\nEpoch 55/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1959 - mae: 0.3486 - val_loss: 0.3577 - val_mae: 0.4957\nEpoch 56/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2030 - mae: 0.3679 - val_loss: 0.3344 - val_mae: 0.4670\nEpoch 57/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1953 - mae: 0.3405 - val_loss: 0.3331 - val_mae: 0.4731\nEpoch 58/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1976 - mae: 0.3649 - val_loss: 0.3151 - val_mae: 0.4447\nEpoch 59/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2022 - mae: 0.3527 - val_loss: 0.2961 - val_mae: 0.4416\nEpoch 60/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1905 - mae: 0.3554 - val_loss: 0.3003 - val_mae: 0.4339\nEpoch 61/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1895 - mae: 0.3450 - val_loss: 0.3121 - val_mae: 0.4518\nEpoch 62/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2128 - mae: 0.3711 - val_loss: 0.3149 - val_mae: 0.4553\nEpoch 63/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1871 - mae: 0.3413 - val_loss: 0.3061 - val_mae: 0.4480\nEpoch 64/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1795 - mae: 0.3355 - val_loss: 0.3494 - val_mae: 0.4748\nEpoch 65/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1552 - mae: 0.3064 - val_loss: 0.3457 - val_mae: 0.4729\nEpoch 66/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1598 - mae: 0.3036 - val_loss: 0.3482 - val_mae: 0.4863\nEpoch 67/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1647 - mae: 0.3232 - val_loss: 0.3212 - val_mae: 0.4753\nEpoch 68/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1569 - mae: 0.3134 - val_loss: 0.2742 - val_mae: 0.4276\nEpoch 69/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1639 - mae: 0.3258 - val_loss: 0.3294 - val_mae: 0.4816\nEpoch 70/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1630 - mae: 0.3202 - val_loss: 0.2856 - val_mae: 0.4466\nEpoch 71/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1739 - mae: 0.3415 - val_loss: 0.2877 - val_mae: 0.4395\nEpoch 72/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1578 - mae: 0.3256 - val_loss: 0.3136 - val_mae: 0.4611\nEpoch 73/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1846 - mae: 0.3413 - val_loss: 0.3107 - val_mae: 0.4584\nEpoch 74/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1812 - mae: 0.3387 - val_loss: 0.3069 - val_mae: 0.4453\nEpoch 75/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1725 - mae: 0.3299 - val_loss: 0.3655 - val_mae: 0.4916\nEpoch 76/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1781 - mae: 0.3391 - val_loss: 0.3272 - val_mae: 0.4596\nEpoch 77/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1611 - mae: 0.3126 - val_loss: 0.3495 - val_mae: 0.4770\nEpoch 78/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1486 - mae: 0.2981 - val_loss: 0.3231 - val_mae: 0.4587\nEpoch 79/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1595 - mae: 0.3192 - val_loss: 0.6257 - val_mae: 0.5258\nEpoch 80/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1772 - mae: 0.3190 - val_loss: 0.4100 - val_mae: 0.4744\nEpoch 81/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1777 - mae: 0.3416 - val_loss: 0.3820 - val_mae: 0.4920\nEpoch 82/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1874 - mae: 0.3474 - val_loss: 0.4144 - val_mae: 0.5297\nEpoch 83/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1833 - mae: 0.3410 - val_loss: 0.3513 - val_mae: 0.4879\nEpoch 84/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1546 - mae: 0.3162 - val_loss: 0.3311 - val_mae: 0.4787\nEpoch 85/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1401 - mae: 0.2876 - val_loss: 0.3365 - val_mae: 0.4812\nEpoch 86/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1345 - mae: 0.2838 - val_loss: 0.3264 - val_mae: 0.4733\nEpoch 87/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1833 - mae: 0.3439 - val_loss: 0.3060 - val_mae: 0.4326\nEpoch 88/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1407 - mae: 0.2921 - val_loss: 0.3222 - val_mae: 0.4692\nEpoch 89/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1632 - mae: 0.3242 - val_loss: 0.3012 - val_mae: 0.4426\nEpoch 90/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1544 - mae: 0.3103 - val_loss: 0.3053 - val_mae: 0.4411\nEpoch 91/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1332 - mae: 0.3033 - val_loss: 0.3145 - val_mae: 0.4383\nEpoch 92/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1468 - mae: 0.3008 - val_loss: 0.3605 - val_mae: 0.4773\nEpoch 93/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1405 - mae: 0.2958 - val_loss: 0.2835 - val_mae: 0.4357\nEpoch 94/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1312 - mae: 0.2836 - val_loss: 0.2745 - val_mae: 0.4312\nEpoch 95/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1661 - mae: 0.3291 - val_loss: 0.2755 - val_mae: 0.4349\nEpoch 96/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1726 - mae: 0.3255 - val_loss: 0.2746 - val_mae: 0.4238\nEpoch 97/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1239 - mae: 0.2741 - val_loss: 0.2991 - val_mae: 0.4276\nEpoch 98/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1574 - mae: 0.3020 - val_loss: 0.2791 - val_mae: 0.4237\nEpoch 99/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1244 - mae: 0.2740 - val_loss: 0.2810 - val_mae: 0.4220\nEpoch 100/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1346 - mae: 0.2956 - val_loss: 0.2806 - val_mae: 0.4218\nEpoch 101/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1317 - mae: 0.2796 - val_loss: 0.2792 - val_mae: 0.4328\nEpoch 102/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1177 - mae: 0.2752 - val_loss: 0.2903 - val_mae: 0.4309\nEpoch 103/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1378 - mae: 0.3007 - val_loss: 0.2734 - val_mae: 0.4258\nEpoch 104/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1177 - mae: 0.2696 - val_loss: 0.3292 - val_mae: 0.4596\nEpoch 105/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1381 - mae: 0.2978 - val_loss: 0.3053 - val_mae: 0.4291\nEpoch 106/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1217 - mae: 0.2836 - val_loss: 0.3072 - val_mae: 0.4431\nEpoch 107/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1183 - mae: 0.2784 - val_loss: 0.2719 - val_mae: 0.4161\nEpoch 108/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1427 - mae: 0.2887 - val_loss: 0.2596 - val_mae: 0.4137\nEpoch 109/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1577 - mae: 0.3078 - val_loss: 0.2824 - val_mae: 0.4364\nEpoch 110/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1288 - mae: 0.2723 - val_loss: 0.2916 - val_mae: 0.4419\nEpoch 111/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0960 - mae: 0.2428 - val_loss: 0.2731 - val_mae: 0.4300\nEpoch 112/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1440 - mae: 0.3056 - val_loss: 0.2723 - val_mae: 0.4182\nEpoch 113/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1122 - mae: 0.2609 - val_loss: 0.2607 - val_mae: 0.4138\nEpoch 114/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1152 - mae: 0.2659 - val_loss: 0.2450 - val_mae: 0.4009\nEpoch 115/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1333 - mae: 0.2882 - val_loss: 0.2510 - val_mae: 0.4006\nEpoch 116/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1060 - mae: 0.2624 - val_loss: 0.2482 - val_mae: 0.3956\nEpoch 117/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1016 - mae: 0.2517 - val_loss: 0.2809 - val_mae: 0.4328\nEpoch 118/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1170 - mae: 0.2641 - val_loss: 0.2525 - val_mae: 0.4032\nEpoch 119/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1183 - mae: 0.2600 - val_loss: 0.2366 - val_mae: 0.3886\nEpoch 120/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0939 - mae: 0.2467 - val_loss: 0.2930 - val_mae: 0.4310\nEpoch 121/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1118 - mae: 0.2642 - val_loss: 0.2651 - val_mae: 0.3931\nEpoch 122/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1136 - mae: 0.2639 - val_loss: 0.2622 - val_mae: 0.3913\nEpoch 123/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1339 - mae: 0.2855 - val_loss: 0.2463 - val_mae: 0.3853\nEpoch 124/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0904 - mae: 0.2348 - val_loss: 0.2751 - val_mae: 0.4101\nEpoch 125/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1149 - mae: 0.2619 - val_loss: 0.2782 - val_mae: 0.4249\nEpoch 126/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1020 - mae: 0.2490 - val_loss: 0.2562 - val_mae: 0.4054\nEpoch 127/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1209 - mae: 0.2661 - val_loss: 0.2525 - val_mae: 0.4056\nEpoch 128/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1255 - mae: 0.2835 - val_loss: 0.3039 - val_mae: 0.4334\nEpoch 129/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1145 - mae: 0.2681 - val_loss: 0.2732 - val_mae: 0.4116\nEpoch 130/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0960 - mae: 0.2315 - val_loss: 0.2692 - val_mae: 0.4103\nEpoch 131/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1017 - mae: 0.2523 - val_loss: 0.2835 - val_mae: 0.4277\nEpoch 132/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0931 - mae: 0.2351 - val_loss: 0.2495 - val_mae: 0.3923\nEpoch 133/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1143 - mae: 0.2661 - val_loss: 0.2532 - val_mae: 0.3885\nEpoch 134/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0945 - mae: 0.2504 - val_loss: 0.2506 - val_mae: 0.4000\nEpoch 135/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0871 - mae: 0.2226 - val_loss: 0.2513 - val_mae: 0.4025\nEpoch 136/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1273 - mae: 0.2881 - val_loss: 0.3004 - val_mae: 0.4415\nEpoch 137/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1015 - mae: 0.2543 - val_loss: 0.2905 - val_mae: 0.4333\nEpoch 138/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1170 - mae: 0.2666 - val_loss: 0.2840 - val_mae: 0.4304\nEpoch 139/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1007 - mae: 0.2494 - val_loss: 0.2640 - val_mae: 0.4141\nEpoch 140/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1210 - mae: 0.2791 - val_loss: 0.2738 - val_mae: 0.4209\nEpoch 141/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0943 - mae: 0.2350 - val_loss: 0.3213 - val_mae: 0.4637\nEpoch 142/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0976 - mae: 0.2487 - val_loss: 0.2668 - val_mae: 0.4298\nEpoch 143/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0862 - mae: 0.2387 - val_loss: 0.2471 - val_mae: 0.4015\nEpoch 144/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0998 - mae: 0.2512 - val_loss: 0.2521 - val_mae: 0.4218\nEpoch 145/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0847 - mae: 0.2300 - val_loss: 0.2469 - val_mae: 0.4143\nEpoch 146/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0845 - mae: 0.2238 - val_loss: 0.2446 - val_mae: 0.4010\nEpoch 147/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1073 - mae: 0.2559 - val_loss: 0.2553 - val_mae: 0.4082\nEpoch 148/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1107 - mae: 0.2642 - val_loss: 0.2824 - val_mae: 0.4093\nEpoch 149/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0935 - mae: 0.2378 - val_loss: 0.2614 - val_mae: 0.4025\nEpoch 150/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0868 - mae: 0.2292 - val_loss: 0.2774 - val_mae: 0.4090\nEpoch 151/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1033 - mae: 0.2558 - val_loss: 0.2764 - val_mae: 0.4065\nEpoch 152/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0924 - mae: 0.2362 - val_loss: 0.2449 - val_mae: 0.3874\nEpoch 153/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0949 - mae: 0.2410 - val_loss: 0.2515 - val_mae: 0.4002\nEpoch 154/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0776 - mae: 0.2244 - val_loss: 0.2523 - val_mae: 0.3982\nEpoch 155/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0845 - mae: 0.2244 - val_loss: 0.2695 - val_mae: 0.4141\nEpoch 156/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1038 - mae: 0.2512 - val_loss: 0.2591 - val_mae: 0.4097\nEpoch 157/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0863 - mae: 0.2355 - val_loss: 0.2615 - val_mae: 0.4038\nEpoch 158/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0885 - mae: 0.2336 - val_loss: 0.2680 - val_mae: 0.4152\nEpoch 159/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1058 - mae: 0.2530 - val_loss: 0.2648 - val_mae: 0.4069\nEpoch 160/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0963 - mae: 0.2362 - val_loss: 0.2655 - val_mae: 0.4231\nEpoch 161/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0861 - mae: 0.2379 - val_loss: 0.2380 - val_mae: 0.3922\nEpoch 162/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0941 - mae: 0.2323 - val_loss: 0.2795 - val_mae: 0.4257\nEpoch 163/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0919 - mae: 0.2440 - val_loss: 0.3453 - val_mae: 0.4490\nEpoch 164/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0755 - mae: 0.2116 - val_loss: 0.3190 - val_mae: 0.4428\nEpoch 165/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1026 - mae: 0.2356 - val_loss: 0.3098 - val_mae: 0.4249\nEpoch 166/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0984 - mae: 0.2381 - val_loss: 0.3091 - val_mae: 0.4411\nEpoch 167/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0850 - mae: 0.2278 - val_loss: 0.2822 - val_mae: 0.4309\nEpoch 168/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0964 - mae: 0.2563 - val_loss: 0.2801 - val_mae: 0.4329\nEpoch 169/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0929 - mae: 0.2409 - val_loss: 0.2685 - val_mae: 0.4138\nEpoch 170/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1027 - mae: 0.2477 - val_loss: 0.2707 - val_mae: 0.4269\nEpoch 171/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0922 - mae: 0.2416 - val_loss: 0.2700 - val_mae: 0.4239\nEpoch 172/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0789 - mae: 0.2211 - val_loss: 0.2458 - val_mae: 0.4062\nEpoch 173/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1052 - mae: 0.2443 - val_loss: 0.2500 - val_mae: 0.3997\nEpoch 174/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0743 - mae: 0.2126 - val_loss: 0.2477 - val_mae: 0.4070\nEpoch 175/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0914 - mae: 0.2354 - val_loss: 0.2666 - val_mae: 0.4206\nEpoch 176/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0691 - mae: 0.2104 - val_loss: 0.2853 - val_mae: 0.4401\nEpoch 177/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1180 - mae: 0.2688 - val_loss: 0.2567 - val_mae: 0.4222\nEpoch 178/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0867 - mae: 0.2297 - val_loss: 0.2849 - val_mae: 0.4355\nEpoch 179/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0840 - mae: 0.2332 - val_loss: 0.2738 - val_mae: 0.4242\nEpoch 180/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0739 - mae: 0.2171 - val_loss: 0.2835 - val_mae: 0.4257\nEpoch 181/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0738 - mae: 0.2107 - val_loss: 0.2885 - val_mae: 0.4357\nEpoch 182/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0766 - mae: 0.2190 - val_loss: 0.2766 - val_mae: 0.4248\nEpoch 183/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0748 - mae: 0.2108 - val_loss: 0.2990 - val_mae: 0.4386\nEpoch 184/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0742 - mae: 0.2124 - val_loss: 0.3051 - val_mae: 0.4450\nEpoch 185/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0900 - mae: 0.2419 - val_loss: 0.2767 - val_mae: 0.4222\nEpoch 186/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0944 - mae: 0.2425 - val_loss: 0.2791 - val_mae: 0.4280\nEpoch 187/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0826 - mae: 0.2282 - val_loss: 0.2979 - val_mae: 0.4444\nEpoch 188/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0742 - mae: 0.2146 - val_loss: 0.2791 - val_mae: 0.4341\nEpoch 189/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0688 - mae: 0.2056 - val_loss: 0.2694 - val_mae: 0.4191\nEpoch 190/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0704 - mae: 0.2023 - val_loss: 0.2899 - val_mae: 0.4371\nEpoch 191/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0968 - mae: 0.2428 - val_loss: 0.2626 - val_mae: 0.4297\nEpoch 192/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0738 - mae: 0.2140 - val_loss: 0.2583 - val_mae: 0.4145\nEpoch 193/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0836 - mae: 0.2220 - val_loss: 0.2826 - val_mae: 0.4264\nEpoch 194/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0606 - mae: 0.1964 - val_loss: 0.2796 - val_mae: 0.4310\nEpoch 195/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0596 - mae: 0.1905 - val_loss: 0.2635 - val_mae: 0.4179\nEpoch 196/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0888 - mae: 0.2315 - val_loss: 0.2821 - val_mae: 0.4266\nEpoch 197/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0836 - mae: 0.2303 - val_loss: 0.3012 - val_mae: 0.4368\nEpoch 198/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0820 - mae: 0.2274 - val_loss: 0.2843 - val_mae: 0.4214\nEpoch 199/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0779 - mae: 0.2233 - val_loss: 0.2785 - val_mae: 0.4232\nEpoch 200/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1012 - mae: 0.2310 - val_loss: 0.2989 - val_mae: 0.4512\nEpoch 201/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0764 - mae: 0.2182 - val_loss: 0.2743 - val_mae: 0.4206\nEpoch 202/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0788 - mae: 0.2206 - val_loss: 0.2672 - val_mae: 0.4198\nEpoch 203/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0718 - mae: 0.2160 - val_loss: 0.3018 - val_mae: 0.4388\nEpoch 204/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0819 - mae: 0.2241 - val_loss: 0.2658 - val_mae: 0.4155\nEpoch 205/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0619 - mae: 0.1952 - val_loss: 0.2685 - val_mae: 0.4199\nEpoch 206/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0688 - mae: 0.2034 - val_loss: 0.2922 - val_mae: 0.4228\nEpoch 207/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0913 - mae: 0.2373 - val_loss: 0.3346 - val_mae: 0.4688\nEpoch 208/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0795 - mae: 0.2259 - val_loss: 0.3051 - val_mae: 0.4420\nEpoch 209/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0621 - mae: 0.1881 - val_loss: 0.2785 - val_mae: 0.4260\nEpoch 210/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0733 - mae: 0.2231 - val_loss: 0.2779 - val_mae: 0.4231\nEpoch 211/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0748 - mae: 0.2130 - val_loss: 0.2364 - val_mae: 0.3946\nEpoch 212/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0696 - mae: 0.2058 - val_loss: 0.2461 - val_mae: 0.3917\nEpoch 213/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0714 - mae: 0.2129 - val_loss: 0.2364 - val_mae: 0.3907\nEpoch 214/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0745 - mae: 0.2114 - val_loss: 0.2425 - val_mae: 0.4014\nEpoch 215/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0676 - mae: 0.2010 - val_loss: 0.2730 - val_mae: 0.4157\nEpoch 216/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0695 - mae: 0.2065 - val_loss: 0.2566 - val_mae: 0.4112\nEpoch 217/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0567 - mae: 0.1866 - val_loss: 0.2696 - val_mae: 0.4128\nEpoch 218/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0618 - mae: 0.1921 - val_loss: 0.2708 - val_mae: 0.4151\nEpoch 219/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0635 - mae: 0.2046 - val_loss: 0.2663 - val_mae: 0.4124\nEpoch 220/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0758 - mae: 0.2046 - val_loss: 0.2653 - val_mae: 0.4120\nEpoch 221/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0714 - mae: 0.2123 - val_loss: 0.2815 - val_mae: 0.4183\nEpoch 222/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0553 - mae: 0.1910 - val_loss: 0.2848 - val_mae: 0.4355\nEpoch 223/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0669 - mae: 0.2011 - val_loss: 0.2892 - val_mae: 0.4401\nEpoch 224/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0654 - mae: 0.2003 - val_loss: 0.2608 - val_mae: 0.4198\nEpoch 225/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0727 - mae: 0.2153 - val_loss: 0.2489 - val_mae: 0.4056\nEpoch 226/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0700 - mae: 0.1940 - val_loss: 0.2586 - val_mae: 0.4111\nEpoch 227/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0652 - mae: 0.2027 - val_loss: 0.2534 - val_mae: 0.3996\nEpoch 228/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0689 - mae: 0.2077 - val_loss: 0.2654 - val_mae: 0.4084\nEpoch 229/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0783 - mae: 0.2222 - val_loss: 0.2624 - val_mae: 0.4010\nEpoch 230/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0655 - mae: 0.1914 - val_loss: 0.2548 - val_mae: 0.4081\nEpoch 231/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1189 - mae: 0.2596 - val_loss: 0.2657 - val_mae: 0.4098\nEpoch 232/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0600 - mae: 0.1993 - val_loss: 0.2699 - val_mae: 0.4228\nEpoch 233/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0646 - mae: 0.2016 - val_loss: 0.2611 - val_mae: 0.4085\nEpoch 234/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0769 - mae: 0.2115 - val_loss: 0.2487 - val_mae: 0.4007\nEpoch 235/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0720 - mae: 0.2080 - val_loss: 0.2725 - val_mae: 0.4189\nEpoch 236/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0726 - mae: 0.2057 - val_loss: 0.2525 - val_mae: 0.3921\nEpoch 237/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0697 - mae: 0.2070 - val_loss: 0.2593 - val_mae: 0.4121\nEpoch 238/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0659 - mae: 0.2071 - val_loss: 0.2380 - val_mae: 0.3846\nEpoch 239/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0771 - mae: 0.2133 - val_loss: 0.2571 - val_mae: 0.4109\nEpoch 240/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0711 - mae: 0.2126 - val_loss: 0.2532 - val_mae: 0.4110\nEpoch 241/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0695 - mae: 0.2118 - val_loss: 0.2557 - val_mae: 0.4045\nEpoch 242/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0721 - mae: 0.2214 - val_loss: 0.2497 - val_mae: 0.3991\nEpoch 243/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0586 - mae: 0.1919 - val_loss: 0.2526 - val_mae: 0.4043\nEpoch 244/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0577 - mae: 0.1858 - val_loss: 0.2501 - val_mae: 0.3952\nEpoch 245/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0577 - mae: 0.1877 - val_loss: 0.2432 - val_mae: 0.3897\nEpoch 246/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0569 - mae: 0.1948 - val_loss: 0.2366 - val_mae: 0.3784\nEpoch 247/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0596 - mae: 0.1905 - val_loss: 0.2292 - val_mae: 0.3751\nEpoch 248/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0880 - mae: 0.2340 - val_loss: 0.2304 - val_mae: 0.3815\nEpoch 249/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0569 - mae: 0.1913 - val_loss: 0.2258 - val_mae: 0.3803\nEpoch 250/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0626 - mae: 0.1909 - val_loss: 0.2240 - val_mae: 0.3792\nEpoch 251/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0614 - mae: 0.1929 - val_loss: 0.2351 - val_mae: 0.3895\nEpoch 252/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0621 - mae: 0.1947 - val_loss: 0.2776 - val_mae: 0.4352\nEpoch 253/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0663 - mae: 0.2040 - val_loss: 0.2480 - val_mae: 0.4043\nEpoch 254/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0553 - mae: 0.1802 - val_loss: 0.2604 - val_mae: 0.4114\nEpoch 255/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0633 - mae: 0.2051 - val_loss: 0.2720 - val_mae: 0.4227\nEpoch 256/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0534 - mae: 0.1799 - val_loss: 0.2697 - val_mae: 0.4170\nEpoch 257/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0612 - mae: 0.1917 - val_loss: 0.2681 - val_mae: 0.4149\nEpoch 258/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0494 - mae: 0.1701 - val_loss: 0.2700 - val_mae: 0.4110\nEpoch 259/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0507 - mae: 0.1710 - val_loss: 0.2752 - val_mae: 0.4013\nEpoch 260/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0575 - mae: 0.1892 - val_loss: 0.2661 - val_mae: 0.3984\nEpoch 261/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0570 - mae: 0.1933 - val_loss: 0.2667 - val_mae: 0.4031\nEpoch 262/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0632 - mae: 0.1937 - val_loss: 0.2711 - val_mae: 0.4292\nEpoch 263/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0650 - mae: 0.1953 - val_loss: 0.2722 - val_mae: 0.4230\nEpoch 264/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0666 - mae: 0.2063 - val_loss: 0.2844 - val_mae: 0.4313\nEpoch 265/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0661 - mae: 0.2063 - val_loss: 0.2637 - val_mae: 0.4071\nEpoch 266/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0603 - mae: 0.1978 - val_loss: 0.2713 - val_mae: 0.4187\nEpoch 267/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0511 - mae: 0.1814 - val_loss: 0.2709 - val_mae: 0.4039\nEpoch 268/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0474 - mae: 0.1759 - val_loss: 0.2352 - val_mae: 0.3949\nEpoch 269/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0677 - mae: 0.2012 - val_loss: 0.2534 - val_mae: 0.3966\nEpoch 270/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0567 - mae: 0.1937 - val_loss: 0.2434 - val_mae: 0.3915\nEpoch 271/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0569 - mae: 0.1875 - val_loss: 0.2701 - val_mae: 0.4107\nEpoch 272/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0694 - mae: 0.2055 - val_loss: 0.2633 - val_mae: 0.4115\nEpoch 273/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0612 - mae: 0.1915 - val_loss: 0.2587 - val_mae: 0.4029\nEpoch 274/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0673 - mae: 0.1988 - val_loss: 0.2582 - val_mae: 0.4110\nEpoch 275/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0582 - mae: 0.1947 - val_loss: 0.2736 - val_mae: 0.4140\nEpoch 276/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0548 - mae: 0.1843 - val_loss: 0.2500 - val_mae: 0.3990\nEpoch 277/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0532 - mae: 0.1832 - val_loss: 0.2746 - val_mae: 0.4133\nEpoch 278/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0510 - mae: 0.1699 - val_loss: 0.2542 - val_mae: 0.4008\nEpoch 279/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0621 - mae: 0.1880 - val_loss: 0.2667 - val_mae: 0.4064\nEpoch 280/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0539 - mae: 0.1843 - val_loss: 0.2665 - val_mae: 0.3990\nEpoch 281/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0589 - mae: 0.1925 - val_loss: 0.2582 - val_mae: 0.4049\nEpoch 282/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0482 - mae: 0.1718 - val_loss: 0.2720 - val_mae: 0.4124\nEpoch 283/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0697 - mae: 0.2080 - val_loss: 0.2431 - val_mae: 0.3782\nEpoch 284/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0584 - mae: 0.1873 - val_loss: 0.2420 - val_mae: 0.3798\nEpoch 285/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0549 - mae: 0.1824 - val_loss: 0.2432 - val_mae: 0.3876\nEpoch 286/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0720 - mae: 0.2097 - val_loss: 0.2291 - val_mae: 0.3720\nEpoch 287/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0581 - mae: 0.1890 - val_loss: 0.2709 - val_mae: 0.3891\nEpoch 288/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0559 - mae: 0.1906 - val_loss: 0.2574 - val_mae: 0.3848\nEpoch 289/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0632 - mae: 0.1970 - val_loss: 0.2469 - val_mae: 0.3795\nEpoch 290/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0515 - mae: 0.1727 - val_loss: 0.2529 - val_mae: 0.3866\nEpoch 291/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0505 - mae: 0.1799 - val_loss: 0.2488 - val_mae: 0.4086\nEpoch 292/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0601 - mae: 0.1963 - val_loss: 0.2464 - val_mae: 0.3804\nEpoch 293/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0543 - mae: 0.1753 - val_loss: 0.2474 - val_mae: 0.3987\nEpoch 294/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0522 - mae: 0.1832 - val_loss: 0.2301 - val_mae: 0.3811\nEpoch 295/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0382 - mae: 0.1549 - val_loss: 0.2348 - val_mae: 0.3929\nEpoch 296/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0595 - mae: 0.1822 - val_loss: 0.2325 - val_mae: 0.3775\nEpoch 297/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0460 - mae: 0.1707 - val_loss: 0.2479 - val_mae: 0.3886\nEpoch 298/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0579 - mae: 0.1888 - val_loss: 0.2383 - val_mae: 0.3935\nEpoch 299/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0597 - mae: 0.1865 - val_loss: 0.2416 - val_mae: 0.3760\nEpoch 300/300\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0503 - mae: 0.1751 - val_loss: 0.2233 - val_mae: 0.3746\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n\n=== TRAIN METRICS ===\nRMSE: 0.2167\nMAE : 0.1892\nR²  : 0.9207\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n\n=== TEST METRICS ===\nRMSE: 0.4726\nMAE : 0.3746\nR²  : 0.6050\n\nModel saved at: /kaggle/working/whisper_mpnet_fusion_model.keras\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# MAIN CODE HERE","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\ndef load_and_align_data(whisper_path, mpnet_path, label_path):\n    whisper_df = pd.read_csv(whisper_path)\n    mpnet_df   = pd.read_csv(mpnet_path)\n    label_df   = pd.read_csv(label_path)\n\n    whisper_df.rename(columns={whisper_df.columns[0]: \"filename\"}, inplace=True)\n    mpnet_df.rename(columns={mpnet_df.columns[0]: \"filename\"}, inplace=True)\n    label_df.rename(columns={label_df.columns[0]: \"filename\"}, inplace=True)\n\n    whisper_df[\"filename\"] = whisper_df[\"filename\"].str.replace(\n        \".wav\", \"\", regex=False\n    )\n\n    df = (\n        whisper_df\n        .merge(mpnet_df, on=\"filename\", how=\"inner\")\n        .merge(label_df, on=\"filename\", how=\"inner\")\n    )\n\n    return df\n\n\ndef build_whisper_branch_no_cnn(input_dim):\n    inp = tf.keras.layers.Input(shape=(input_dim,), name=\"whisper_input\")\n    x = tf.keras.layers.Dense(256, activation=\"relu\")(inp)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n    return inp, x\n\n\ndef build_mpnet_branch_no_cnn(input_dim):\n    inp = tf.keras.layers.Input(shape=(input_dim,), name=\"mpnet_input\")\n    x = tf.keras.layers.Dense(256, activation=\"relu\")(inp)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n    return inp, x\n\ndef build_whisper_branch_cnn(input_dim):\n    inp = tf.keras.layers.Input(shape=(input_dim,), name=\"whisper_input\")\n    x = tf.keras.layers.Reshape((input_dim, 1))(inp)\n\n    # Conv Block 1\n    x = tf.keras.layers.Conv1D(\n        filters=64,\n        kernel_size=3,\n        activation=\"relu\",\n        padding=\"same\"\n    )(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n\n    # # Conv Block 2\n    # x = tf.keras.layers.Conv1D(\n    #     filters=128,\n    #     kernel_size=3,\n    #     activation=\"relu\",\n    #     padding=\"same\"\n    # )(x)\n    # x = tf.keras.layers.BatchNormalization()(x)\n    # x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n\n    x = tf.keras.layers.Flatten()(x)\n\n    #x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n\n    return inp, x\n\n\ndef build_mpnet_branch_cnn(input_dim):\n    inp = tf.keras.layers.Input(shape=(input_dim,), name=\"mpnet_input\")\n\n    x = tf.keras.layers.Reshape((input_dim, 1))(inp)\n\n    # Conv Block 1\n    x = tf.keras.layers.Conv1D(\n        filters=64,\n        kernel_size=3,\n        activation=\"relu\",\n        padding=\"same\"\n    )(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n\n    x = tf.keras.layers.Flatten()(x)\n\n    x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n    x = tf.keras.layers.Dense(8, activation=\"relu\")(x)\n\n    return inp, x\n\n\n\ndef build_fusion_model(whisper_dim, mpnet_dim):\n    w_inp, w_feat = build_whisper_branch_cnn(whisper_dim)\n    m_inp, m_feat = build_mpnet_branch_cnn(mpnet_dim)\n\n    fused = tf.keras.layers.Concatenate()([w_feat, m_feat])\n    fused = tf.keras.layers.Dense(64, activation=\"relu\")(fused)\n    fused = tf.keras.layers.Dense(8, activation=\"relu\")(fused)\n\n    output = tf.keras.layers.Dense(1)(fused)\n\n    model = tf.keras.Model(\n        inputs=[w_inp, m_inp],\n        outputs=output\n    )\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-3),\n        loss=\"mse\",\n        metrics=[\"mae\"]\n    )\n\n    return model\n\n\ndef tolerance_accuracy(y_true, y_pred, tol=0.5):\n    return np.mean(np.abs(y_true - y_pred) <= tol)\n\n\ndef evaluate_regression(model, Xw, Xm, y_true, split=\"\"):\n    y_pred = model.predict(\n        {\"whisper_input\": Xw, \"mpnet_input\": Xm},\n        verbose=0\n    ).squeeze()\n\n    y_pred = np.clip(y_pred, 0.0, 5.0)\n\n    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n    mae  = np.mean(np.abs(y_true - y_pred))\n    r2   = r2_score(y_true, y_pred)\n    acc  = tolerance_accuracy(y_true, y_pred)\n\n    print(f\"\\n=== {split} METRICS ===\")\n    print(f\"RMSE                : {rmse:.4f}\")\n    print(f\"MAE                 : {mae:.4f}\")\n    print(f\"R²                  : {r2:.4f}\")\n    print(f\"Accuracy (±0.5)     : {acc * 100:.2f}%\")\n\n    return y_pred\n\n\nWHISPER_EMB = \"/kaggle/working/audio_whisper_train_embeddings.csv\"\nMPNET_EMB   = \"/kaggle/working/deberta_large_embeddings.csv\"\nLABELS      = \"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/csvs/train.csv\"\n\ndf = load_and_align_data(WHISPER_EMB, MPNET_EMB, LABELS)\nprint(\"Total aligned samples:\", len(df))\n\nX_whisper = df.iloc[:, 1:513].values.astype(np.float32)    # 512-d\nX_mpnet   = df.iloc[:, 513:-1].values.astype(np.float32)  # 1024-d\ny         = df.iloc[:, -1].values.astype(np.float32)\n\nXw_tr, Xw_te, Xm_tr, Xm_te, y_tr, y_te = train_test_split(\n    X_whisper,\n    X_mpnet,\n    y,\n    test_size=0.2,\n    random_state=42\n)\n\nmodel = build_fusion_model(\n    whisper_dim=Xw_tr.shape[1],\n    mpnet_dim=Xm_tr.shape[1]\n)\n\nmodel.summary()\n\nBEST_MODEL_PATH = \"/kaggle/working/best_whisper_doberta_fusion_model.keras\"\n\ncheckpoint_cb = ModelCheckpoint(\n    filepath=BEST_MODEL_PATH,\n    monitor=\"val_loss\",\n    save_best_only=True,\n    mode=\"min\",\n    verbose=1\n)\n\nearly_stop_cb = EarlyStopping(\n    monitor=\"val_loss\",\n    patience=50,\n    restore_best_weights=True,\n    verbose=1\n)\n\n\nhistory = model.fit(\n    {\"whisper_input\": Xw_tr, \"mpnet_input\": Xm_tr},\n    y_tr,\n    validation_data=(\n        {\"whisper_input\": Xw_te, \"mpnet_input\": Xm_te},\n        y_te\n    ),\n    epochs=200,\n    batch_size=32,\n    callbacks=[checkpoint_cb, early_stop_cb],\n    verbose=1\n)\n\n\nbest_model = tf.keras.models.load_model(BEST_MODEL_PATH)\nprint(\"\\nLoaded best model from:\", BEST_MODEL_PATH)\n\n\n_ = evaluate_regression(best_model, Xw_tr, Xm_tr, y_tr, \"TRAIN\")\n_ = evaluate_regression(best_model, Xw_te, Xm_te, y_te, \"TEST\")\n\n\nFINAL_MODEL_PATH = \"/kaggle/working/final_best_whisper_mpnet_fusion_model.keras\"\nbest_model.save(FINAL_MODEL_PATH)\n\nprint(\"\\nFinal best model saved at:\", FINAL_MODEL_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:25:23.796468Z","iopub.execute_input":"2025-12-16T11:25:23.796762Z","iopub.status.idle":"2025-12-16T11:26:23.266496Z","shell.execute_reply.started":"2025-12-16T11:25:23.796741Z","shell.execute_reply":"2025-12-16T11:26:23.265766Z"}},"outputs":[{"name":"stdout","text":"Total aligned samples: 409\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_248\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_248\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ mpnet_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ whisper_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ mpnet_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ whisper_input[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ reshape_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ reshape_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv1d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_29    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_28    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_29… │\n│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_28… │\n│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_105 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │  \u001b[38;5;34m2,097,216\u001b[0m │ flatten_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_104 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m2,097,280\u001b[0m │ flatten_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_106 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m520\u001b[0m │ dense_105[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m136\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_104[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_106[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_107 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,768\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_108 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m520\u001b[0m │ dense_107[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_109 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m9\u001b[0m │ dense_108[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ mpnet_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ whisper_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mpnet_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ whisper_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ reshape_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ reshape_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_29    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_28    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_29… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_28… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,216</span> │ flatten_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,280</span> │ flatten_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ dense_105[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_104[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_106[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,768</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ dense_107[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ dense_108[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,205,337\u001b[0m (16.04 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,205,337</span> (16.04 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,205,081\u001b[0m (16.04 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,205,081</span> (16.04 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/200\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 73.5838 - mae: 5.4813\nEpoch 1: val_loss improved from inf to 8.04823, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 585ms/step - loss: 71.8685 - mae: 5.4023 - val_loss: 8.0482 - val_mae: 2.7339\nEpoch 2/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1392 - mae: 0.8176\nEpoch 2: val_loss improved from 8.04823 to 7.64305, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 1.0972 - mae: 0.8073 - val_loss: 7.6431 - val_mae: 2.6604\nEpoch 3/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7556 - mae: 0.6822\nEpoch 3: val_loss improved from 7.64305 to 7.47304, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.7621 - mae: 0.6816 - val_loss: 7.4730 - val_mae: 2.6319\nEpoch 4/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5574 - mae: 0.6119\nEpoch 4: val_loss did not improve from 7.47304\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5416 - mae: 0.5992 - val_loss: 7.5918 - val_mae: 2.6579\nEpoch 5/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4124 - mae: 0.5175\nEpoch 5: val_loss did not improve from 7.47304\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4064 - mae: 0.5140 - val_loss: 7.7922 - val_mae: 2.6978\nEpoch 6/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5162 - mae: 0.5756\nEpoch 6: val_loss improved from 7.47304 to 7.39645, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5066 - mae: 0.5693 - val_loss: 7.3964 - val_mae: 2.6248\nEpoch 7/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4009 - mae: 0.5138\nEpoch 7: val_loss improved from 7.39645 to 7.21785, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3903 - mae: 0.5055 - val_loss: 7.2179 - val_mae: 2.5912\nEpoch 8/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3348 - mae: 0.4725\nEpoch 8: val_loss did not improve from 7.21785\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3211 - mae: 0.4617 - val_loss: 7.4436 - val_mae: 2.6351\nEpoch 9/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2447 - mae: 0.3915\nEpoch 9: val_loss did not improve from 7.21785\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2426 - mae: 0.3909 - val_loss: 7.3739 - val_mae: 2.6220\nEpoch 10/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2114 - mae: 0.3682\nEpoch 10: val_loss improved from 7.21785 to 7.15714, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2169 - mae: 0.3727 - val_loss: 7.1571 - val_mae: 2.5808\nEpoch 11/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1883 - mae: 0.3487\nEpoch 11: val_loss improved from 7.15714 to 7.03595, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1951 - mae: 0.3544 - val_loss: 7.0359 - val_mae: 2.5578\nEpoch 12/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2139 - mae: 0.3630\nEpoch 12: val_loss did not improve from 7.03595\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2134 - mae: 0.3626 - val_loss: 7.1789 - val_mae: 2.5860\nEpoch 13/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1641 - mae: 0.3281\nEpoch 13: val_loss did not improve from 7.03595\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1646 - mae: 0.3272 - val_loss: 7.0417 - val_mae: 2.5595\nEpoch 14/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1430 - mae: 0.2950\nEpoch 14: val_loss improved from 7.03595 to 7.02063, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1435 - mae: 0.2963 - val_loss: 7.0206 - val_mae: 2.5559\nEpoch 15/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1324 - mae: 0.2800\nEpoch 15: val_loss improved from 7.02063 to 6.85172, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1336 - mae: 0.2821 - val_loss: 6.8517 - val_mae: 2.5233\nEpoch 16/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1250 - mae: 0.2847\nEpoch 16: val_loss improved from 6.85172 to 6.74452, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1269 - mae: 0.2865 - val_loss: 6.7445 - val_mae: 2.5024\nEpoch 17/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1352 - mae: 0.2944\nEpoch 17: val_loss improved from 6.74452 to 6.71740, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1345 - mae: 0.2924 - val_loss: 6.7174 - val_mae: 2.4979\nEpoch 18/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1131 - mae: 0.2682\nEpoch 18: val_loss improved from 6.71740 to 6.64258, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1148 - mae: 0.2691 - val_loss: 6.6426 - val_mae: 2.4832\nEpoch 19/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1092 - mae: 0.2655\nEpoch 19: val_loss improved from 6.64258 to 6.62499, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1090 - mae: 0.2644 - val_loss: 6.6250 - val_mae: 2.4803\nEpoch 20/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1031 - mae: 0.2537\nEpoch 20: val_loss improved from 6.62499 to 6.54258, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1007 - mae: 0.2513 - val_loss: 6.5426 - val_mae: 2.4644\nEpoch 21/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0850 - mae: 0.2374\nEpoch 21: val_loss improved from 6.54258 to 6.38897, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0867 - mae: 0.2383 - val_loss: 6.3890 - val_mae: 2.4342\nEpoch 22/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0989 - mae: 0.2513\nEpoch 22: val_loss did not improve from 6.38897\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0959 - mae: 0.2459 - val_loss: 6.4303 - val_mae: 2.4437\nEpoch 23/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0779 - mae: 0.2243\nEpoch 23: val_loss did not improve from 6.38897\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0763 - mae: 0.2216 - val_loss: 6.4582 - val_mae: 2.4494\nEpoch 24/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0870 - mae: 0.2301\nEpoch 24: val_loss improved from 6.38897 to 6.37993, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0836 - mae: 0.2266 - val_loss: 6.3799 - val_mae: 2.4338\nEpoch 25/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0705 - mae: 0.2049\nEpoch 25: val_loss improved from 6.37993 to 6.20256, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0699 - mae: 0.2043 - val_loss: 6.2026 - val_mae: 2.3976\nEpoch 26/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0646 - mae: 0.1996\nEpoch 26: val_loss improved from 6.20256 to 6.15568, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0632 - mae: 0.1970 - val_loss: 6.1557 - val_mae: 2.3889\nEpoch 27/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0525 - mae: 0.1737\nEpoch 27: val_loss improved from 6.15568 to 6.10624, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0534 - mae: 0.1760 - val_loss: 6.1062 - val_mae: 2.3792\nEpoch 28/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0537 - mae: 0.1793\nEpoch 28: val_loss improved from 6.10624 to 6.00054, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0539 - mae: 0.1796 - val_loss: 6.0005 - val_mae: 2.3579\nEpoch 29/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0545 - mae: 0.1818\nEpoch 29: val_loss improved from 6.00054 to 5.97850, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0553 - mae: 0.1830 - val_loss: 5.9785 - val_mae: 2.3539\nEpoch 30/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0502 - mae: 0.1769\nEpoch 30: val_loss improved from 5.97850 to 5.93292, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0498 - mae: 0.1762 - val_loss: 5.9329 - val_mae: 2.3447\nEpoch 31/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0488 - mae: 0.1738\nEpoch 31: val_loss improved from 5.93292 to 5.75990, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0487 - mae: 0.1742 - val_loss: 5.7599 - val_mae: 2.3082\nEpoch 32/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0385 - mae: 0.1565\nEpoch 32: val_loss improved from 5.75990 to 5.60076, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0386 - mae: 0.1560 - val_loss: 5.6008 - val_mae: 2.2742\nEpoch 33/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0398 - mae: 0.1527\nEpoch 33: val_loss improved from 5.60076 to 5.53601, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0397 - mae: 0.1530 - val_loss: 5.5360 - val_mae: 2.2609\nEpoch 34/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0389 - mae: 0.1554\nEpoch 34: val_loss did not improve from 5.53601\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0385 - mae: 0.1544 - val_loss: 5.5776 - val_mae: 2.2711\nEpoch 35/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0383 - mae: 0.1488\nEpoch 35: val_loss improved from 5.53601 to 5.49470, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0376 - mae: 0.1478 - val_loss: 5.4947 - val_mae: 2.2542\nEpoch 36/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0261 - mae: 0.1233\nEpoch 36: val_loss improved from 5.49470 to 5.23985, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0268 - mae: 0.1251 - val_loss: 5.2398 - val_mae: 2.1976\nEpoch 37/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0354 - mae: 0.1454\nEpoch 37: val_loss improved from 5.23985 to 5.23573, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0343 - mae: 0.1436 - val_loss: 5.2357 - val_mae: 2.1972\nEpoch 38/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0291 - mae: 0.1305\nEpoch 38: val_loss improved from 5.23573 to 5.16569, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0280 - mae: 0.1283 - val_loss: 5.1657 - val_mae: 2.1821\nEpoch 39/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0245 - mae: 0.1218\nEpoch 39: val_loss improved from 5.16569 to 5.11512, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0255 - mae: 0.1246 - val_loss: 5.1151 - val_mae: 2.1712\nEpoch 40/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0205 - mae: 0.1119\nEpoch 40: val_loss improved from 5.11512 to 4.83230, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0207 - mae: 0.1120 - val_loss: 4.8323 - val_mae: 2.1059\nEpoch 41/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0339 - mae: 0.1449\nEpoch 41: val_loss improved from 4.83230 to 4.79999, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0328 - mae: 0.1424 - val_loss: 4.8000 - val_mae: 2.0990\nEpoch 42/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0304 - mae: 0.1432\nEpoch 42: val_loss did not improve from 4.79999\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0306 - mae: 0.1435 - val_loss: 4.8458 - val_mae: 2.1113\nEpoch 43/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0187 - mae: 0.1046\nEpoch 43: val_loss did not improve from 4.79999\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0198 - mae: 0.1075 - val_loss: 4.9524 - val_mae: 2.1380\nEpoch 44/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0467 - mae: 0.1762\nEpoch 44: val_loss improved from 4.79999 to 4.60651, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0451 - mae: 0.1722 - val_loss: 4.6065 - val_mae: 2.0564\nEpoch 45/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0245 - mae: 0.1291\nEpoch 45: val_loss improved from 4.60651 to 4.34648, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0253 - mae: 0.1303 - val_loss: 4.3465 - val_mae: 1.9936\nEpoch 46/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0286 - mae: 0.1373\nEpoch 46: val_loss did not improve from 4.34648\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0299 - mae: 0.1374 - val_loss: 4.8951 - val_mae: 2.1256\nEpoch 47/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2383 - mae: 0.3596\nEpoch 47: val_loss did not improve from 4.34648\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2399 - mae: 0.3574 - val_loss: 4.6260 - val_mae: 2.0576\nEpoch 48/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1580 - mae: 0.2632\nEpoch 48: val_loss improved from 4.34648 to 3.73883, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1720 - mae: 0.2769 - val_loss: 3.7388 - val_mae: 1.8334\nEpoch 49/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2226 - mae: 0.3614\nEpoch 49: val_loss did not improve from 3.73883\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2214 - mae: 0.3528 - val_loss: 3.7443 - val_mae: 1.8340\nEpoch 50/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1800 - mae: 0.2954\nEpoch 50: val_loss did not improve from 3.73883\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1776 - mae: 0.2892 - val_loss: 3.9938 - val_mae: 1.9046\nEpoch 51/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0984 - mae: 0.1887\nEpoch 51: val_loss did not improve from 3.73883\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1041 - mae: 0.1904 - val_loss: 4.0056 - val_mae: 1.9051\nEpoch 52/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1365 - mae: 0.1811\nEpoch 52: val_loss did not improve from 3.73883\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1297 - mae: 0.1801 - val_loss: 3.9807 - val_mae: 1.9054\nEpoch 53/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0565 - mae: 0.1691\nEpoch 53: val_loss improved from 3.73883 to 3.67283, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0583 - mae: 0.1711 - val_loss: 3.6728 - val_mae: 1.8258\nEpoch 54/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0324 - mae: 0.1374\nEpoch 54: val_loss improved from 3.67283 to 3.44124, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0338 - mae: 0.1403 - val_loss: 3.4412 - val_mae: 1.7606\nEpoch 55/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0332 - mae: 0.1465\nEpoch 55: val_loss improved from 3.44124 to 3.20033, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0317 - mae: 0.1422 - val_loss: 3.2003 - val_mae: 1.6900\nEpoch 56/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0425 - mae: 0.1699\nEpoch 56: val_loss did not improve from 3.20033\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0400 - mae: 0.1638 - val_loss: 3.4201 - val_mae: 1.7565\nEpoch 57/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0237 - mae: 0.1229\nEpoch 57: val_loss did not improve from 3.20033\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0246 - mae: 0.1268 - val_loss: 3.2212 - val_mae: 1.7019\nEpoch 58/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0178 - mae: 0.1094\nEpoch 58: val_loss improved from 3.20033 to 3.04777, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0183 - mae: 0.1105 - val_loss: 3.0478 - val_mae: 1.6501\nEpoch 59/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0203 - mae: 0.1117\nEpoch 59: val_loss improved from 3.04777 to 2.99027, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0197 - mae: 0.1102 - val_loss: 2.9903 - val_mae: 1.6317\nEpoch 60/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.1050\nEpoch 60: val_loss did not improve from 2.99027\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0170 - mae: 0.1058 - val_loss: 3.1178 - val_mae: 1.6725\nEpoch 61/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0167 - mae: 0.1018\nEpoch 61: val_loss improved from 2.99027 to 2.90862, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0165 - mae: 0.1005 - val_loss: 2.9086 - val_mae: 1.6105\nEpoch 62/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0142 - mae: 0.0883\nEpoch 62: val_loss improved from 2.90862 to 2.70702, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0145 - mae: 0.0882 - val_loss: 2.7070 - val_mae: 1.5487\nEpoch 63/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0157 - mae: 0.0885\nEpoch 63: val_loss improved from 2.70702 to 2.60260, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0169 - mae: 0.0918 - val_loss: 2.6026 - val_mae: 1.5155\nEpoch 64/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0236 - mae: 0.1007\nEpoch 64: val_loss improved from 2.60260 to 2.58760, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0229 - mae: 0.0995 - val_loss: 2.5876 - val_mae: 1.5121\nEpoch 65/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0150 - mae: 0.0821\nEpoch 65: val_loss improved from 2.58760 to 2.45293, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0147 - mae: 0.0812 - val_loss: 2.4529 - val_mae: 1.4674\nEpoch 66/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0128 - mae: 0.0813\nEpoch 66: val_loss improved from 2.45293 to 2.34201, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0135 - mae: 0.0812 - val_loss: 2.3420 - val_mae: 1.4312\nEpoch 67/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0098 - mae: 0.0724\nEpoch 67: val_loss improved from 2.34201 to 2.33084, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0102 - mae: 0.0734 - val_loss: 2.3308 - val_mae: 1.4292\nEpoch 68/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0068 - mae: 0.0630\nEpoch 68: val_loss improved from 2.33084 to 2.27579, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0071 - mae: 0.0638 - val_loss: 2.2758 - val_mae: 1.4104\nEpoch 69/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0086 - mae: 0.0675\nEpoch 69: val_loss improved from 2.27579 to 2.01268, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0082 - mae: 0.0667 - val_loss: 2.0127 - val_mae: 1.3143\nEpoch 70/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0124 - mae: 0.0845\nEpoch 70: val_loss did not improve from 2.01268\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0119 - mae: 0.0829 - val_loss: 2.1216 - val_mae: 1.3571\nEpoch 71/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0113 - mae: 0.0798\nEpoch 71: val_loss improved from 2.01268 to 1.88439, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0110 - mae: 0.0794 - val_loss: 1.8844 - val_mae: 1.2694\nEpoch 72/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0125 - mae: 0.0836\nEpoch 72: val_loss improved from 1.88439 to 1.83873, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0134 - mae: 0.0865 - val_loss: 1.8387 - val_mae: 1.2488\nEpoch 73/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0127 - mae: 0.0859\nEpoch 73: val_loss did not improve from 1.83873\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0134 - mae: 0.0887 - val_loss: 1.9095 - val_mae: 1.2801\nEpoch 74/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0114 - mae: 0.0817\nEpoch 74: val_loss improved from 1.83873 to 1.67089, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0109 - mae: 0.0789 - val_loss: 1.6709 - val_mae: 1.1880\nEpoch 75/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0044 - mae: 0.0516\nEpoch 75: val_loss improved from 1.67089 to 1.64526, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0045 - mae: 0.0514 - val_loss: 1.6453 - val_mae: 1.1771\nEpoch 76/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0035 - mae: 0.0439\nEpoch 76: val_loss improved from 1.64526 to 1.52092, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0035 - mae: 0.0441 - val_loss: 1.5209 - val_mae: 1.1245\nEpoch 77/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - mae: 0.0528\nEpoch 77: val_loss improved from 1.52092 to 1.47807, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0049 - mae: 0.0543 - val_loss: 1.4781 - val_mae: 1.1083\nEpoch 78/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0036 - mae: 0.0461\nEpoch 78: val_loss improved from 1.47807 to 1.35358, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0036 - mae: 0.0461 - val_loss: 1.3536 - val_mae: 1.0563\nEpoch 79/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0040 - mae: 0.0498\nEpoch 79: val_loss did not improve from 1.35358\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 1.4605 - val_mae: 1.1030\nEpoch 80/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0082 - mae: 0.0758\nEpoch 80: val_loss improved from 1.35358 to 1.20792, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0079 - mae: 0.0741 - val_loss: 1.2079 - val_mae: 0.9883\nEpoch 81/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - mae: 0.0579\nEpoch 81: val_loss did not improve from 1.20792\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0051 - mae: 0.0571 - val_loss: 1.2430 - val_mae: 1.0087\nEpoch 82/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0037 - mae: 0.0479\nEpoch 82: val_loss did not improve from 1.20792\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 1.5105 - val_mae: 1.1283\nEpoch 83/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0396 - mae: 0.1691\nEpoch 83: val_loss improved from 1.20792 to 0.95115, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0378 - mae: 0.1639 - val_loss: 0.9512 - val_mae: 0.8652\nEpoch 84/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0193 - mae: 0.1098\nEpoch 84: val_loss did not improve from 0.95115\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0187 - mae: 0.1087 - val_loss: 1.2494 - val_mae: 1.0173\nEpoch 85/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0234 - mae: 0.1320\nEpoch 85: val_loss did not improve from 0.95115\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0219 - mae: 0.1273 - val_loss: 0.9682 - val_mae: 0.8735\nEpoch 86/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0103 - mae: 0.0778\nEpoch 86: val_loss improved from 0.95115 to 0.82588, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0107 - mae: 0.0797 - val_loss: 0.8259 - val_mae: 0.7992\nEpoch 87/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0128 - mae: 0.0933\nEpoch 87: val_loss did not improve from 0.82588\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0126 - mae: 0.0923 - val_loss: 1.0293 - val_mae: 0.9124\nEpoch 88/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0130 - mae: 0.0939\nEpoch 88: val_loss improved from 0.82588 to 0.76869, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0122 - mae: 0.0902 - val_loss: 0.7687 - val_mae: 0.7705\nEpoch 89/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0074 - mae: 0.0684\nEpoch 89: val_loss did not improve from 0.76869\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0071 - mae: 0.0666 - val_loss: 0.9571 - val_mae: 0.8792\nEpoch 90/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0135 - mae: 0.1004\nEpoch 90: val_loss improved from 0.76869 to 0.74864, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0128 - mae: 0.0970 - val_loss: 0.7486 - val_mae: 0.7618\nEpoch 91/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0628\nEpoch 91: val_loss improved from 0.74864 to 0.65087, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0062 - mae: 0.0629 - val_loss: 0.6509 - val_mae: 0.7032\nEpoch 92/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0078 - mae: 0.0734\nEpoch 92: val_loss did not improve from 0.65087\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0079 - mae: 0.0737 - val_loss: 0.8754 - val_mae: 0.8368\nEpoch 93/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.1175\nEpoch 93: val_loss improved from 0.65087 to 0.58301, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0161 - mae: 0.1149 - val_loss: 0.5830 - val_mae: 0.6622\nEpoch 94/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0074 - mae: 0.0710\nEpoch 94: val_loss did not improve from 0.58301\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0070 - mae: 0.0690 - val_loss: 0.6465 - val_mae: 0.7036\nEpoch 95/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0030 - mae: 0.0417\nEpoch 95: val_loss improved from 0.58301 to 0.56611, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0029 - mae: 0.0416 - val_loss: 0.5661 - val_mae: 0.6484\nEpoch 96/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0033 - mae: 0.0454\nEpoch 96: val_loss improved from 0.56611 to 0.55704, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 0.5570 - val_mae: 0.6454\nEpoch 97/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0028 - mae: 0.0405\nEpoch 97: val_loss did not improve from 0.55704\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0432 - val_loss: 0.5996 - val_mae: 0.6761\nEpoch 98/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0061 - mae: 0.0671\nEpoch 98: val_loss improved from 0.55704 to 0.40663, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0063 - mae: 0.0686 - val_loss: 0.4066 - val_mae: 0.5335\nEpoch 99/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0203 - mae: 0.1335\nEpoch 99: val_loss did not improve from 0.40663\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0191 - mae: 0.1287 - val_loss: 0.6243 - val_mae: 0.6919\nEpoch 100/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0160 - mae: 0.1161\nEpoch 100: val_loss improved from 0.40663 to 0.38445, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0152 - mae: 0.1123 - val_loss: 0.3844 - val_mae: 0.5145\nEpoch 101/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0105 - mae: 0.0888\nEpoch 101: val_loss did not improve from 0.38445\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0100 - mae: 0.0861 - val_loss: 0.4080 - val_mae: 0.5354\nEpoch 102/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0038 - mae: 0.0492\nEpoch 102: val_loss did not improve from 0.38445\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - mae: 0.0486 - val_loss: 0.4397 - val_mae: 0.5595\nEpoch 103/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0026 - mae: 0.0393\nEpoch 103: val_loss did not improve from 0.38445\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0390 - val_loss: 0.4576 - val_mae: 0.5753\nEpoch 104/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0036 - mae: 0.0404\nEpoch 104: val_loss did not improve from 0.38445\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0393 - val_loss: 0.4278 - val_mae: 0.5505\nEpoch 105/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0032 - mae: 0.0438\nEpoch 105: val_loss improved from 0.38445 to 0.36371, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0031 - mae: 0.0431 - val_loss: 0.3637 - val_mae: 0.4978\nEpoch 106/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0400\nEpoch 106: val_loss did not improve from 0.36371\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0401 - val_loss: 0.3658 - val_mae: 0.4977\nEpoch 107/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0296\nEpoch 107: val_loss did not improve from 0.36371\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.3666 - val_mae: 0.5012\nEpoch 108/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0265\nEpoch 108: val_loss did not improve from 0.36371\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0011 - mae: 0.0266 - val_loss: 0.3640 - val_mae: 0.4978\nEpoch 109/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0282\nEpoch 109: val_loss improved from 0.36371 to 0.33315, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0013 - mae: 0.0291 - val_loss: 0.3331 - val_mae: 0.4713\nEpoch 110/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0361    \nEpoch 110: val_loss did not improve from 0.33315\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0026 - mae: 0.0389 - val_loss: 0.3417 - val_mae: 0.4796\nEpoch 111/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0041 - mae: 0.0519\nEpoch 111: val_loss improved from 0.33315 to 0.27792, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0045 - mae: 0.0554 - val_loss: 0.2779 - val_mae: 0.4253\nEpoch 112/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0101 - mae: 0.0893\nEpoch 112: val_loss did not improve from 0.27792\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0106 - mae: 0.0912 - val_loss: 0.3288 - val_mae: 0.4671\nEpoch 113/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0083 - mae: 0.0755\nEpoch 113: val_loss did not improve from 0.27792\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0086 - mae: 0.0766 - val_loss: 0.3680 - val_mae: 0.5046\nEpoch 114/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0146 - mae: 0.1038\nEpoch 114: val_loss improved from 0.27792 to 0.24123, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0146 - mae: 0.1041 - val_loss: 0.2412 - val_mae: 0.3988\nEpoch 115/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0239 - mae: 0.1022\nEpoch 115: val_loss improved from 0.24123 to 0.23859, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0223 - mae: 0.1002 - val_loss: 0.2386 - val_mae: 0.3954\nEpoch 116/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0198 - mae: 0.1059\nEpoch 116: val_loss did not improve from 0.23859\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0204 - mae: 0.1054 - val_loss: 0.2970 - val_mae: 0.4427\nEpoch 117/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0126 - mae: 0.0771\nEpoch 117: val_loss did not improve from 0.23859\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0143 - mae: 0.0801 - val_loss: 0.2627 - val_mae: 0.4156\nEpoch 118/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0122 - mae: 0.0631\nEpoch 118: val_loss improved from 0.23859 to 0.22877, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0146 - mae: 0.0657 - val_loss: 0.2288 - val_mae: 0.3818\nEpoch 119/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0157 - mae: 0.0948\nEpoch 119: val_loss did not improve from 0.22877\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0162 - mae: 0.0936 - val_loss: 0.2367 - val_mae: 0.3953\nEpoch 120/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0131 - mae: 0.0739\nEpoch 120: val_loss did not improve from 0.22877\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0128 - mae: 0.0726 - val_loss: 0.2363 - val_mae: 0.3890\nEpoch 121/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0070 - mae: 0.0613\nEpoch 121: val_loss did not improve from 0.22877\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0067 - mae: 0.0600 - val_loss: 0.2730 - val_mae: 0.4262\nEpoch 122/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0038 - mae: 0.0459\nEpoch 122: val_loss did not improve from 0.22877\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0040 - mae: 0.0474 - val_loss: 0.2432 - val_mae: 0.3986\nEpoch 123/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0022 - mae: 0.0371\nEpoch 123: val_loss improved from 0.22877 to 0.22414, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0024 - mae: 0.0380 - val_loss: 0.2241 - val_mae: 0.3752\nEpoch 124/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0077 - mae: 0.0777\nEpoch 124: val_loss did not improve from 0.22414\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0076 - mae: 0.0761 - val_loss: 0.2649 - val_mae: 0.4198\nEpoch 125/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0034 - mae: 0.0463\nEpoch 125: val_loss did not improve from 0.22414\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0443 - val_loss: 0.2394 - val_mae: 0.3946\nEpoch 126/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0290\nEpoch 126: val_loss did not improve from 0.22414\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.2348 - val_mae: 0.3903\nEpoch 127/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0296\nEpoch 127: val_loss did not improve from 0.22414\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.2407 - val_mae: 0.3933\nEpoch 128/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0289    \nEpoch 128: val_loss did not improve from 0.22414\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.2261 - val_mae: 0.3805\nEpoch 129/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0403\nEpoch 129: val_loss did not improve from 0.22414\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0418 - val_loss: 0.2528 - val_mae: 0.4077\nEpoch 130/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - mae: 0.0630\nEpoch 130: val_loss improved from 0.22414 to 0.21213, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0052 - mae: 0.0626 - val_loss: 0.2121 - val_mae: 0.3587\nEpoch 131/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0092 - mae: 0.0860\nEpoch 131: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0087 - mae: 0.0832 - val_loss: 0.2354 - val_mae: 0.3837\nEpoch 132/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0400\nEpoch 132: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0419 - val_loss: 0.2485 - val_mae: 0.4028\nEpoch 133/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0078 - mae: 0.0754\nEpoch 133: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0078 - mae: 0.0744 - val_loss: 0.2133 - val_mae: 0.3606\nEpoch 134/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0041 - mae: 0.0471\nEpoch 134: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0465 - val_loss: 0.2303 - val_mae: 0.3864\nEpoch 135/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0035 - mae: 0.0424\nEpoch 135: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 0.2170 - val_mae: 0.3597\nEpoch 136/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0033 - mae: 0.0463\nEpoch 136: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0455 - val_loss: 0.2143 - val_mae: 0.3569\nEpoch 137/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0102 - mae: 0.0864\nEpoch 137: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0099 - mae: 0.0847 - val_loss: 0.2385 - val_mae: 0.3925\nEpoch 138/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0055 - mae: 0.0634\nEpoch 138: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0053 - mae: 0.0618 - val_loss: 0.2721 - val_mae: 0.4259\nEpoch 139/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0136 - mae: 0.1015\nEpoch 139: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0140 - mae: 0.1019 - val_loss: 0.2200 - val_mae: 0.3657\nEpoch 140/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0115 - mae: 0.0873\nEpoch 140: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0109 - mae: 0.0826 - val_loss: 0.2306 - val_mae: 0.3792\nEpoch 141/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - mae: 0.0484\nEpoch 141: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0047 - mae: 0.0482 - val_loss: 0.2324 - val_mae: 0.3866\nEpoch 142/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0584\nEpoch 142: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - mae: 0.0577 - val_loss: 0.2379 - val_mae: 0.3845\nEpoch 143/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0096 - mae: 0.0672\nEpoch 143: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0089 - mae: 0.0656 - val_loss: 0.2341 - val_mae: 0.3812\nEpoch 144/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0075 - mae: 0.0499\nEpoch 144: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0096 - mae: 0.0555 - val_loss: 0.2211 - val_mae: 0.3579\nEpoch 145/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0213 - mae: 0.0868\nEpoch 145: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0202 - mae: 0.0822 - val_loss: 0.2125 - val_mae: 0.3592\nEpoch 146/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0150 - mae: 0.0812\nEpoch 146: val_loss did not improve from 0.21213\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0156 - mae: 0.0812 - val_loss: 0.2269 - val_mae: 0.3739\nEpoch 147/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0079 - mae: 0.0571\nEpoch 147: val_loss improved from 0.21213 to 0.21073, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0096 - mae: 0.0590 - val_loss: 0.2107 - val_mae: 0.3537\nEpoch 148/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0268 - mae: 0.1083\nEpoch 148: val_loss did not improve from 0.21073\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0256 - mae: 0.1051 - val_loss: 0.2350 - val_mae: 0.3667\nEpoch 149/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0444 - mae: 0.1890\nEpoch 149: val_loss did not improve from 0.21073\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0407 - mae: 0.1794 - val_loss: 0.2432 - val_mae: 0.3970\nEpoch 150/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0230 - mae: 0.1252\nEpoch 150: val_loss did not improve from 0.21073\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0230 - mae: 0.1244 - val_loss: 0.2248 - val_mae: 0.3794\nEpoch 151/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0111 - mae: 0.0839\nEpoch 151: val_loss improved from 0.21073 to 0.20704, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0113 - mae: 0.0848 - val_loss: 0.2070 - val_mae: 0.3550\nEpoch 152/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0075 - mae: 0.0677\nEpoch 152: val_loss did not improve from 0.20704\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0079 - mae: 0.0689 - val_loss: 0.2794 - val_mae: 0.4362\nEpoch 153/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0257 - mae: 0.1345\nEpoch 153: val_loss did not improve from 0.20704\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0249 - mae: 0.1305 - val_loss: 0.2151 - val_mae: 0.3603\nEpoch 154/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0077 - mae: 0.0638\nEpoch 154: val_loss did not improve from 0.20704\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0078 - mae: 0.0629 - val_loss: 0.2830 - val_mae: 0.4311\nEpoch 155/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0545 - mae: 0.1843\nEpoch 155: val_loss did not improve from 0.20704\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0604 - mae: 0.1808 - val_loss: 0.2377 - val_mae: 0.3966\nEpoch 156/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0484 - mae: 0.1714\nEpoch 156: val_loss did not improve from 0.20704\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0472 - mae: 0.1669 - val_loss: 0.2575 - val_mae: 0.3766\nEpoch 157/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0493 - mae: 0.1577\nEpoch 157: val_loss did not improve from 0.20704\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0491 - mae: 0.1566 - val_loss: 0.2677 - val_mae: 0.4007\nEpoch 158/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0422 - mae: 0.1525\nEpoch 158: val_loss did not improve from 0.20704\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0434 - mae: 0.1542 - val_loss: 0.2407 - val_mae: 0.4039\nEpoch 159/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0405 - mae: 0.1658\nEpoch 159: val_loss did not improve from 0.20704\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0427 - mae: 0.1701 - val_loss: 0.2665 - val_mae: 0.3943\nEpoch 160/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0736 - mae: 0.2269\nEpoch 160: val_loss did not improve from 0.20704\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0693 - mae: 0.2180 - val_loss: 0.4221 - val_mae: 0.5442\nEpoch 161/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1247 - mae: 0.2945\nEpoch 161: val_loss did not improve from 0.20704\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1195 - mae: 0.2857 - val_loss: 0.2291 - val_mae: 0.3646\nEpoch 162/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0549 - mae: 0.1937\nEpoch 162: val_loss improved from 0.20704 to 0.19952, saving model to /kaggle/working/best_whisper_doberta_fusion_model.keras\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0537 - mae: 0.1892 - val_loss: 0.1995 - val_mae: 0.3397\nEpoch 163/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0346 - mae: 0.1372\nEpoch 163: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0329 - mae: 0.1340 - val_loss: 0.2738 - val_mae: 0.4251\nEpoch 164/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0327 - mae: 0.1403\nEpoch 164: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0310 - mae: 0.1369 - val_loss: 0.2156 - val_mae: 0.3473\nEpoch 165/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0345 - mae: 0.1055\nEpoch 165: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0312 - mae: 0.1015 - val_loss: 0.2903 - val_mae: 0.4355\nEpoch 166/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0602 - mae: 0.1734\nEpoch 166: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0544 - mae: 0.1667 - val_loss: 0.2407 - val_mae: 0.3688\nEpoch 167/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0466 - mae: 0.1847\nEpoch 167: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0443 - mae: 0.1791 - val_loss: 0.2464 - val_mae: 0.3916\nEpoch 168/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.1086\nEpoch 168: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0168 - mae: 0.1086 - val_loss: 0.2054 - val_mae: 0.3445\nEpoch 169/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0165 - mae: 0.1096\nEpoch 169: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0168 - mae: 0.1102 - val_loss: 0.2594 - val_mae: 0.4129\nEpoch 170/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0325 - mae: 0.1556\nEpoch 170: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0309 - mae: 0.1503 - val_loss: 0.2200 - val_mae: 0.3531\nEpoch 171/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0241 - mae: 0.1345\nEpoch 171: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0242 - mae: 0.1342 - val_loss: 0.2560 - val_mae: 0.4070\nEpoch 172/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0225 - mae: 0.1253\nEpoch 172: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0208 - mae: 0.1194 - val_loss: 0.2393 - val_mae: 0.3882\nEpoch 173/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0119 - mae: 0.0882\nEpoch 173: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0854 - val_loss: 0.2151 - val_mae: 0.3466\nEpoch 174/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0152 - mae: 0.1020\nEpoch 174: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0141 - mae: 0.0972 - val_loss: 0.2133 - val_mae: 0.3543\nEpoch 175/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0099 - mae: 0.0700\nEpoch 175: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0100 - mae: 0.0700 - val_loss: 0.2430 - val_mae: 0.3935\nEpoch 176/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0193 - mae: 0.1103\nEpoch 176: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0184 - mae: 0.1089 - val_loss: 0.2183 - val_mae: 0.3637\nEpoch 177/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0543\nEpoch 177: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0076 - mae: 0.0562 - val_loss: 0.2096 - val_mae: 0.3513\nEpoch 178/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0056 - mae: 0.0548\nEpoch 178: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0547 - val_loss: 0.2406 - val_mae: 0.3915\nEpoch 179/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0105 - mae: 0.0855\nEpoch 179: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0103 - mae: 0.0839 - val_loss: 0.2098 - val_mae: 0.3462\nEpoch 180/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0080 - mae: 0.0750\nEpoch 180: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0080 - mae: 0.0737 - val_loss: 0.2277 - val_mae: 0.3767\nEpoch 181/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0070 - mae: 0.0702\nEpoch 181: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0068 - mae: 0.0685 - val_loss: 0.2080 - val_mae: 0.3437\nEpoch 182/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0051 - mae: 0.0591\nEpoch 182: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0580 - val_loss: 0.2141 - val_mae: 0.3626\nEpoch 183/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - mae: 0.0493\nEpoch 183: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0044 - mae: 0.0477 - val_loss: 0.2171 - val_mae: 0.3612\nEpoch 184/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0364\nEpoch 184: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.2118 - val_mae: 0.3565\nEpoch 185/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0263    \nEpoch 185: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.2184 - val_mae: 0.3659\nEpoch 186/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0022 - mae: 0.0387\nEpoch 186: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0021 - mae: 0.0373 - val_loss: 0.2141 - val_mae: 0.3571\nEpoch 187/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.9110e-04 - mae: 0.0243\nEpoch 187: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0012 - mae: 0.0263 - val_loss: 0.2075 - val_mae: 0.3456\nEpoch 188/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0029 - mae: 0.0460\nEpoch 188: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.2308 - val_mae: 0.3826\nEpoch 189/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0075 - mae: 0.0737\nEpoch 189: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0071 - mae: 0.0708 - val_loss: 0.2140 - val_mae: 0.3476\nEpoch 190/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0101 - mae: 0.0874\nEpoch 190: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0098 - mae: 0.0853 - val_loss: 0.2216 - val_mae: 0.3702\nEpoch 191/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0036 - mae: 0.0484\nEpoch 191: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0477 - val_loss: 0.2081 - val_mae: 0.3447\nEpoch 192/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0068 - mae: 0.0731\nEpoch 192: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0731 - val_loss: 0.2174 - val_mae: 0.3647\nEpoch 193/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0058 - mae: 0.0657\nEpoch 193: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0058 - mae: 0.0655 - val_loss: 0.2078 - val_mae: 0.3393\nEpoch 194/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0113 - mae: 0.0989\nEpoch 194: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0111 - mae: 0.0973 - val_loss: 0.2131 - val_mae: 0.3589\nEpoch 195/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0043 - mae: 0.0554\nEpoch 195: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0042 - mae: 0.0549 - val_loss: 0.2076 - val_mae: 0.3478\nEpoch 196/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0029 - mae: 0.0420\nEpoch 196: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0029 - mae: 0.0425 - val_loss: 0.2167 - val_mae: 0.3630\nEpoch 197/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0396\nEpoch 197: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0024 - mae: 0.0396 - val_loss: 0.2243 - val_mae: 0.3709\nEpoch 198/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0573\nEpoch 198: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0044 - mae: 0.0548 - val_loss: 0.2047 - val_mae: 0.3423\nEpoch 199/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0032 - mae: 0.0472\nEpoch 199: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0030 - mae: 0.0452 - val_loss: 0.2178 - val_mae: 0.3634\nEpoch 200/200\n\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0032 - mae: 0.0461\nEpoch 200: val_loss did not improve from 0.19952\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0032 - mae: 0.0456 - val_loss: 0.2102 - val_mae: 0.3475\nRestoring model weights from the end of the best epoch: 162.\n\nLoaded best model from: /kaggle/working/best_whisper_doberta_fusion_model.keras\n\n=== TRAIN METRICS ===\nRMSE                : 0.1818\nMAE                 : 0.1300\nR²                  : 0.9442\nAccuracy (±0.5)     : 98.47%\n\n=== TEST METRICS ===\nRMSE                : 0.4458\nMAE                 : 0.3355\nR²                  : 0.6485\nAccuracy (±0.5)     : 75.61%\n\nFinal best model saved at: /kaggle/working/final_best_whisper_mpnet_fusion_model.keras\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\n\nTEST_META_PATH = \"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/csvs/test.csv\"\n\nWHISPER_TEST_EMB = \"/kaggle/working/audio_whisper_test_embeddings.csv\"\nDEBERTA_TEST_EMB = \"/kaggle/working/deberta_large_embeddings_test.csv\"\n\nFUSION_MODEL_PATH = \"/kaggle/working/final_best_whisper_mpnet_fusion_model.keras\"\nSUBMISSION_PATH = \"/kaggle/working/submission.csv\"\n\n\ntest_meta_df = pd.read_csv(TEST_META_PATH)\nwhisper_df = pd.read_csv(WHISPER_TEST_EMB)\ndeberta_df = pd.read_csv(DEBERTA_TEST_EMB)\n\ntest_meta_df.rename(columns={test_meta_df.columns[0]: \"filename\"}, inplace=True)\nwhisper_df.rename(columns={whisper_df.columns[0]: \"filename\"}, inplace=True)\ndeberta_df.rename(columns={deberta_df.columns[0]: \"filename\"}, inplace=True)\n\ntest_meta_df[\"filename\"] = test_meta_df[\"filename\"].astype(str)\nwhisper_df[\"filename\"] = whisper_df[\"filename\"].astype(str)\ndeberta_df[\"filename\"] = deberta_df[\"filename\"].astype(str)\n\nwhisper_df[\"filename\"] = whisper_df[\"filename\"].str.replace(\n    \".wav\", \"\", regex=False\n)\n\n\ntest_df = (\n    test_meta_df\n    .merge(whisper_df, on=\"filename\", how=\"inner\")\n    .merge(deberta_df, on=\"filename\", how=\"inner\")\n)\n\nprint(\"Total aligned test samples:\", len(test_df))\nprint(test_df.head())\n\nX_whisper_test = test_df.iloc[:, 1:513].values.astype(np.float32)\n\nX_deberta_test = test_df.iloc[:, 513:].values.astype(np.float32)\n\nprint(\"Whisper test shape :\", X_whisper_test.shape)\nprint(\"DeBERTa test shape :\", X_deberta_test.shape)\n\n\nfusion_model = tf.keras.models.load_model(FUSION_MODEL_PATH)\nprint(\"Loaded fusion model from:\", FUSION_MODEL_PATH)\n\ny_test_pred = fusion_model.predict(\n    {\n        \"whisper_input\": X_whisper_test,\n        \"mpnet_input\": X_deberta_test\n    },\n    verbose=1\n).squeeze()\n\ny_test_pred = np.clip(y_test_pred, 0.0, 5.0)\n\ny_test_pred = np.round(y_test_pred * 2) / 2\n\nsubmission_df = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": y_test_pred\n})\n\nsubmission_df.to_csv(SUBMISSION_PATH, index=False)\n\nprint(\"Submission saved at:\", SUBMISSION_PATH)\nsubmission_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:48:32.310619Z","iopub.execute_input":"2025-12-16T11:48:32.310898Z","iopub.status.idle":"2025-12-16T11:48:33.432723Z","shell.execute_reply.started":"2025-12-16T11:48:32.310880Z","shell.execute_reply":"2025-12-16T11:48:33.432082Z"}},"outputs":[{"name":"stdout","text":"Total aligned test samples: 197\n    filename         0         1         2         3         4         5  \\\n0  audio_141 -0.090601 -0.494616 -0.142851 -0.164760  0.259085  0.244506   \n1  audio_114  0.006982 -0.009547  0.069612 -0.146992 -0.206328  0.392823   \n2   audio_17 -0.057944  0.019045 -0.017720  0.042755 -0.006069  0.009745   \n3   audio_76  0.174044 -0.028993 -0.065615  0.139336 -0.011715 -0.143123   \n4  audio_156 -0.051893 -0.351710 -0.011548 -0.003263  0.081606  0.067437   \n\n          6         7         8  ...     e1014     e1015     e1016     e1017  \\\n0 -0.364304  0.028873  0.068138  ...  0.000471 -0.426584  0.532851  0.185651   \n1 -0.121439 -0.258225  0.137687  ...  0.076440 -0.126993  0.037520  0.398466   \n2 -0.149774 -0.358314  0.498129  ... -0.350288 -0.345638  0.217359  0.514474   \n3 -0.110890 -0.053824  0.393943  ... -0.173768 -0.363479  0.276646  0.292233   \n4 -0.270160 -0.129895  0.272256  ... -0.307831 -0.081907  0.108643  0.190455   \n\n      e1018     e1019     e1020     e1021     e1022     e1023  \n0 -0.325133 -0.597734 -0.167319  0.035787 -1.089549 -0.131467  \n1 -0.376767 -0.067966  0.004974  0.032921 -0.155951  0.187089  \n2 -0.160688 -0.205467  0.012607  0.061503 -0.750322  0.152489  \n3 -0.002478 -0.072302  0.167044 -0.035520 -0.045989  0.074686  \n4 -0.518719 -0.210445 -0.232458  0.254069 -1.089615 -0.389325  \n\n[5 rows x 1537 columns]\nWhisper test shape : (197, 512)\nDeBERTa test shape : (197, 1024)\nLoaded fusion model from: /kaggle/working/final_best_whisper_mpnet_fusion_model.keras\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step\nSubmission saved at: /kaggle/working/submission.csv\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"    filename  label\n0  audio_141    2.5\n1  audio_114    5.0\n2   audio_17    3.5\n3   audio_76    5.0\n4  audio_156    3.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_141</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_114</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_17</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_76</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_156</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\n\ntf.keras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n\ndef load_and_align_data(whisper_path, mpnet_path, label_path):\n    whisper_df = pd.read_csv(whisper_path)\n    mpnet_df   = pd.read_csv(mpnet_path)\n    label_df   = pd.read_csv(label_path)\n\n    whisper_df.rename(columns={whisper_df.columns[0]: \"filename\"}, inplace=True)\n    mpnet_df.rename(columns={mpnet_df.columns[0]: \"filename\"}, inplace=True)\n    label_df.rename(columns={label_df.columns[0]: \"filename\"}, inplace=True)\n\n    whisper_df[\"filename\"] = whisper_df[\"filename\"].str.replace(\".wav\", \"\", regex=False)\n\n    df = (\n        whisper_df\n        .merge(mpnet_df, on=\"filename\", how=\"inner\")\n        .merge(label_df, on=\"filename\", how=\"inner\")\n    )\n\n    return df\n\n\ndef build_whisper_branch(input_dim):\n    inp = tf.keras.layers.Input(shape=(input_dim,), name=\"whisper_input\")\n\n    x = tf.keras.layers.Dense(512, activation=\"relu\")(inp)\n    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n    x = tf.keras.layers.Dense(8, activation=\"relu\")(x)\n\n    return inp, x\n\n\ndef build_mpnet_branch(input_dim):\n    inp = tf.keras.layers.Input(shape=(input_dim,), name=\"mpnet_input\")\n\n    x = tf.keras.layers.Dense(256, activation=\"relu\")(inp)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n\n    return inp, x\n\n\ndef build_fusion_model(whisper_dim, mpnet_dim):\n    w_inp, w_feat = build_whisper_branch(whisper_dim)\n    m_inp, m_feat = build_mpnet_branch(mpnet_dim)\n\n    w_seq = tf.keras.layers.Reshape((1, 8))(w_feat)  # Query\n    m_seq = tf.keras.layers.Reshape((1, 128))(m_feat)  # Key / Value\n\n    attn = tf.keras.layers.MultiHeadAttention(\n        num_heads=12,\n        key_dim=32,\n        name=\"audio_to_text_attention\"\n    )(query=w_seq, value=m_seq, key=m_seq)\n\n    attn = tf.keras.layers.Add()([w_seq, attn])\n    attn = tf.keras.layers.LayerNormalization()(attn)\n\n    attn = tf.keras.layers.Flatten()(attn)\n\n    fused = tf.keras.layers.Concatenate()([attn, m_feat])\n\n    fused = tf.keras.layers.Dense(128, activation=\"relu\")(fused)\n    fused = tf.keras.layers.BatchNormalization()(fused)\n    fused = tf.keras.layers.Dropout(0.1)(fused)\n\n    fused = tf.keras.layers.Dense(64, activation=\"relu\")(fused)\n    fused = tf.keras.layers.Dense(8, activation=\"relu\")(fused)\n\n    output = tf.keras.layers.Dense(1)(fused)\n\n    model = tf.keras.Model(\n        inputs=[w_inp, m_inp],\n        outputs=output\n    )\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-3),\n        loss=\"mse\",\n        metrics=[\"mae\"]\n    )\n\n    return model\n\nWHISPER_EMB = \"/kaggle/working/audio_whisper_train_embeddings.csv\"\nMPNET_EMB   = \"/kaggle/working/audio_sbert_mpnet_embeddings.csv\"\nLABELS     = \"/kaggle/input/shl-intern-hiring-assessment-2025/dataset/csvs/train.csv\"\n\ndf = load_and_align_data(WHISPER_EMB, MPNET_EMB, LABELS)\nprint(\"Total aligned samples:\", len(df))\n\nX_whisper = df.iloc[:, 1:513].values.astype(np.float32)   # 512-d\nX_mpnet   = df.iloc[:, 513:-1].values.astype(np.float32) # 768-d\ny         = df.iloc[:, -1].values.astype(np.float32)\n\nXw_tr, Xw_te, Xm_tr, Xm_te, y_tr, y_te = train_test_split(\n    X_whisper, X_mpnet, y,\n    test_size=0.2,\n    random_state=42\n)\n\n\nmodel = build_fusion_model(\n    whisper_dim=Xw_tr.shape[1],\n    mpnet_dim=Xm_tr.shape[1]\n)\n\nmodel.summary()\n\nhistory = model.fit(\n    {\"whisper_input\": Xw_tr, \"mpnet_input\": Xm_tr},\n    y_tr,\n    validation_data=(\n        {\"whisper_input\": Xw_te, \"mpnet_input\": Xm_te},\n        y_te\n    ),\n    epochs=100,\n    batch_size=32,\n    verbose=1\n)\n\n\ndef evaluate_regression(model, Xw, Xm, y_true, split):\n    y_pred = model.predict(\n        {\"whisper_input\": Xw, \"mpnet_input\": Xm}\n    ).squeeze()\n\n    y_pred = np.clip(y_pred, 0.0, 5.0)\n\n    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n    mae  = np.mean(np.abs(y_true - y_pred))\n    r2   = r2_score(y_true, y_pred)\n\n    print(f\"\\n=== {split} METRICS ===\")\n    print(f\"RMSE: {rmse:.4f}\")\n    print(f\"MAE : {mae:.4f}\")\n    print(f\"R²  : {r2:.4f}\")\n\n    return y_pred\n\n\n_ = evaluate_regression(model, Xw_tr, Xm_tr, y_tr, \"TRAIN\")\n_ = evaluate_regression(model, Xw_te, Xm_te, y_te, \"TEST\")\n\n\nMODEL_PATH = \"/kaggle/working/whisper_mpnet_attention_fusion_model.keras\"\nmodel.save(MODEL_PATH)\n\nprint(\"\\nModel saved at:\", MODEL_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:40:47.911818Z","iopub.execute_input":"2025-12-16T08:40:47.912403Z","iopub.status.idle":"2025-12-16T08:41:15.012293Z","shell.execute_reply.started":"2025-12-16T08:40:47.912379Z","shell.execute_reply":"2025-12-16T08:41:15.011325Z"}},"outputs":[{"name":"stdout","text":"Total aligned samples: 409\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ whisper_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ whisper_input[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ mpnet_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m196,864\u001b[0m │ mpnet_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m520\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ audio_to_text_atte… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │    \u001b[38;5;34m105,608\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│                     │                   │            │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│                     │                   │            │ audio_to_text_at… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │         \u001b[38;5;34m16\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m136\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m17,536\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m520\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m9\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ whisper_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ whisper_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ mpnet_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ mpnet_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ audio_to_text_atte… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">105,608</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │            │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │            │ audio_to_text_at… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,536</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m774,193\u001b[0m (2.95 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">774,193</span> (2.95 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m773,425\u001b[0m (2.95 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">773,425</span> (2.95 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 406ms/step - loss: 9.7843 - mae: 2.9577 - val_loss: 8.3249 - val_mae: 2.7854\nEpoch 2/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5202 - mae: 1.8928 - val_loss: 6.9017 - val_mae: 2.5163\nEpoch 3/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0090 - mae: 1.1631 - val_loss: 5.7182 - val_mae: 2.2685\nEpoch 4/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9327 - mae: 0.7438 - val_loss: 5.0622 - val_mae: 2.1192\nEpoch 5/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6193 - mae: 0.6182 - val_loss: 4.7429 - val_mae: 2.0417\nEpoch 6/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4115 - mae: 0.5023 - val_loss: 4.3938 - val_mae: 1.9539\nEpoch 7/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4410 - mae: 0.5053 - val_loss: 4.1255 - val_mae: 1.8842\nEpoch 8/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4211 - mae: 0.4905 - val_loss: 3.8083 - val_mae: 1.7992\nEpoch 9/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4117 - mae: 0.5024 - val_loss: 3.4215 - val_mae: 1.6891\nEpoch 10/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2864 - mae: 0.4199 - val_loss: 3.1604 - val_mae: 1.6119\nEpoch 11/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2681 - mae: 0.4007 - val_loss: 2.9038 - val_mae: 1.5320\nEpoch 12/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2453 - mae: 0.3857 - val_loss: 2.6241 - val_mae: 1.4390\nEpoch 13/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2483 - mae: 0.3928 - val_loss: 2.3488 - val_mae: 1.3409\nEpoch 14/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3009 - mae: 0.4370 - val_loss: 2.2448 - val_mae: 1.3033\nEpoch 15/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2578 - mae: 0.4063 - val_loss: 2.1170 - val_mae: 1.2540\nEpoch 16/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2691 - mae: 0.4007 - val_loss: 1.9419 - val_mae: 1.1841\nEpoch 17/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2090 - mae: 0.3654 - val_loss: 1.8264 - val_mae: 1.1370\nEpoch 18/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1819 - mae: 0.3276 - val_loss: 1.6664 - val_mae: 1.0674\nEpoch 19/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2063 - mae: 0.3532 - val_loss: 1.4857 - val_mae: 0.9842\nEpoch 20/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1907 - mae: 0.3540 - val_loss: 1.3593 - val_mae: 0.9236\nEpoch 21/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2044 - mae: 0.3500 - val_loss: 1.2148 - val_mae: 0.8598\nEpoch 22/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1678 - mae: 0.3168 - val_loss: 1.0903 - val_mae: 0.8104\nEpoch 23/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2339 - mae: 0.3756 - val_loss: 0.9473 - val_mae: 0.7525\nEpoch 24/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1659 - mae: 0.3263 - val_loss: 0.8795 - val_mae: 0.7205\nEpoch 25/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1598 - mae: 0.3187 - val_loss: 0.8619 - val_mae: 0.7112\nEpoch 26/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1558 - mae: 0.3184 - val_loss: 0.9306 - val_mae: 0.7417\nEpoch 27/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1584 - mae: 0.3120 - val_loss: 0.9237 - val_mae: 0.7365\nEpoch 28/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1718 - mae: 0.3230 - val_loss: 0.8707 - val_mae: 0.7092\nEpoch 29/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1633 - mae: 0.3147 - val_loss: 0.8220 - val_mae: 0.6893\nEpoch 30/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1654 - mae: 0.3126 - val_loss: 0.8257 - val_mae: 0.6932\nEpoch 31/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1596 - mae: 0.3116 - val_loss: 0.8321 - val_mae: 0.6971\nEpoch 32/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1421 - mae: 0.2893 - val_loss: 0.8466 - val_mae: 0.7020\nEpoch 33/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1849 - mae: 0.3111 - val_loss: 0.7863 - val_mae: 0.6775\nEpoch 34/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1500 - mae: 0.3047 - val_loss: 0.7352 - val_mae: 0.6512\nEpoch 35/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1342 - mae: 0.2842 - val_loss: 0.7003 - val_mae: 0.6360\nEpoch 36/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1583 - mae: 0.2938 - val_loss: 0.6791 - val_mae: 0.6254\nEpoch 37/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1383 - mae: 0.3036 - val_loss: 0.6571 - val_mae: 0.6207\nEpoch 38/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1385 - mae: 0.2961 - val_loss: 0.6896 - val_mae: 0.6362\nEpoch 39/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1329 - mae: 0.2723 - val_loss: 0.6321 - val_mae: 0.6104\nEpoch 40/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1336 - mae: 0.2940 - val_loss: 0.6885 - val_mae: 0.6378\nEpoch 41/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1249 - mae: 0.2798 - val_loss: 0.6628 - val_mae: 0.6235\nEpoch 42/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1069 - mae: 0.2547 - val_loss: 0.6158 - val_mae: 0.5981\nEpoch 43/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1081 - mae: 0.2541 - val_loss: 0.6229 - val_mae: 0.6073\nEpoch 44/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1235 - mae: 0.2704 - val_loss: 0.6022 - val_mae: 0.6075\nEpoch 45/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1495 - mae: 0.2830 - val_loss: 0.6055 - val_mae: 0.6081\nEpoch 46/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1083 - mae: 0.2527 - val_loss: 0.5877 - val_mae: 0.6061\nEpoch 47/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1157 - mae: 0.2549 - val_loss: 0.5758 - val_mae: 0.5878\nEpoch 48/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1181 - mae: 0.2613 - val_loss: 0.5398 - val_mae: 0.5692\nEpoch 49/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1129 - mae: 0.2621 - val_loss: 0.5378 - val_mae: 0.5669\nEpoch 50/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1081 - mae: 0.2630 - val_loss: 0.4969 - val_mae: 0.5545\nEpoch 51/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0891 - mae: 0.2283 - val_loss: 0.5129 - val_mae: 0.5660\nEpoch 52/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1149 - mae: 0.2651 - val_loss: 0.4857 - val_mae: 0.5503\nEpoch 53/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1175 - mae: 0.2703 - val_loss: 0.4646 - val_mae: 0.5261\nEpoch 54/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0988 - mae: 0.2516 - val_loss: 0.4378 - val_mae: 0.5194\nEpoch 55/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0937 - mae: 0.2381 - val_loss: 0.4488 - val_mae: 0.5317\nEpoch 56/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0922 - mae: 0.2386 - val_loss: 0.4430 - val_mae: 0.5357\nEpoch 57/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1037 - mae: 0.2302 - val_loss: 0.4407 - val_mae: 0.5227\nEpoch 58/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0941 - mae: 0.2370 - val_loss: 0.4302 - val_mae: 0.5263\nEpoch 59/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0950 - mae: 0.2434 - val_loss: 0.4584 - val_mae: 0.5268\nEpoch 60/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0969 - mae: 0.2427 - val_loss: 0.4230 - val_mae: 0.5235\nEpoch 61/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1110 - mae: 0.2618 - val_loss: 0.4844 - val_mae: 0.5384\nEpoch 62/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1023 - mae: 0.2414 - val_loss: 0.4081 - val_mae: 0.5047\nEpoch 63/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1048 - mae: 0.2384 - val_loss: 0.4218 - val_mae: 0.5195\nEpoch 64/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1014 - mae: 0.2519 - val_loss: 0.3894 - val_mae: 0.5003\nEpoch 65/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0850 - mae: 0.2335 - val_loss: 0.4032 - val_mae: 0.5014\nEpoch 66/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0890 - mae: 0.2387 - val_loss: 0.3842 - val_mae: 0.4988\nEpoch 67/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0937 - mae: 0.2381 - val_loss: 0.3851 - val_mae: 0.4937\nEpoch 68/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0779 - mae: 0.2158 - val_loss: 0.4208 - val_mae: 0.5157\nEpoch 69/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0832 - mae: 0.2198 - val_loss: 0.3906 - val_mae: 0.4965\nEpoch 70/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0785 - mae: 0.2186 - val_loss: 0.3684 - val_mae: 0.4779\nEpoch 71/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0929 - mae: 0.2402 - val_loss: 0.3519 - val_mae: 0.4748\nEpoch 72/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0677 - mae: 0.2023 - val_loss: 0.3700 - val_mae: 0.4835\nEpoch 73/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0769 - mae: 0.2179 - val_loss: 0.3640 - val_mae: 0.4727\nEpoch 74/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0707 - mae: 0.2053 - val_loss: 0.3692 - val_mae: 0.4695\nEpoch 75/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0790 - mae: 0.2149 - val_loss: 0.3623 - val_mae: 0.4738\nEpoch 76/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0773 - mae: 0.2188 - val_loss: 0.3641 - val_mae: 0.4804\nEpoch 77/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0806 - mae: 0.2163 - val_loss: 0.4106 - val_mae: 0.5119\nEpoch 78/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0860 - mae: 0.2234 - val_loss: 0.3749 - val_mae: 0.4949\nEpoch 79/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0774 - mae: 0.2218 - val_loss: 0.4015 - val_mae: 0.5054\nEpoch 80/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0757 - mae: 0.2127 - val_loss: 0.3674 - val_mae: 0.4867\nEpoch 81/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0787 - mae: 0.2134 - val_loss: 0.3477 - val_mae: 0.4740\nEpoch 82/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0668 - mae: 0.1955 - val_loss: 0.3502 - val_mae: 0.4713\nEpoch 83/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0748 - mae: 0.2111 - val_loss: 0.3528 - val_mae: 0.4790\nEpoch 84/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0642 - mae: 0.1942 - val_loss: 0.3785 - val_mae: 0.4961\nEpoch 85/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0835 - mae: 0.2185 - val_loss: 0.3717 - val_mae: 0.4949\nEpoch 86/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0660 - mae: 0.1945 - val_loss: 0.3493 - val_mae: 0.4689\nEpoch 87/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0694 - mae: 0.1959 - val_loss: 0.3552 - val_mae: 0.4765\nEpoch 88/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0622 - mae: 0.1997 - val_loss: 0.3404 - val_mae: 0.4603\nEpoch 89/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0827 - mae: 0.2216 - val_loss: 0.3508 - val_mae: 0.4687\nEpoch 90/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0767 - mae: 0.2169 - val_loss: 0.3848 - val_mae: 0.4920\nEpoch 91/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0664 - mae: 0.2061 - val_loss: 0.3597 - val_mae: 0.4765\nEpoch 92/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0636 - mae: 0.1954 - val_loss: 0.4075 - val_mae: 0.5139\nEpoch 93/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0648 - mae: 0.2007 - val_loss: 0.3652 - val_mae: 0.4834\nEpoch 94/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0534 - mae: 0.1791 - val_loss: 0.3628 - val_mae: 0.4837\nEpoch 95/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0574 - mae: 0.1909 - val_loss: 0.3725 - val_mae: 0.4938\nEpoch 96/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0633 - mae: 0.1997 - val_loss: 0.3768 - val_mae: 0.4898\nEpoch 97/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0641 - mae: 0.1996 - val_loss: 0.3698 - val_mae: 0.4888\nEpoch 98/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0596 - mae: 0.1936 - val_loss: 0.3186 - val_mae: 0.4601\nEpoch 99/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0786 - mae: 0.2198 - val_loss: 0.3642 - val_mae: 0.4772\nEpoch 100/100\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0542 - mae: 0.1830 - val_loss: 0.3604 - val_mae: 0.4704\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n\n=== TRAIN METRICS ===\nRMSE: 0.1923\nMAE : 0.1478\nR²  : 0.9375\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n\n=== TEST METRICS ===\nRMSE: 0.6003\nMAE : 0.4704\nR²  : 0.3626\n\nModel saved at: /kaggle/working/whisper_mpnet_attention_fusion_model.keras\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}